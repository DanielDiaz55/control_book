[
["index.html", "Control Estadístico de la Calidad Prólogo", " Control Estadístico de la Calidad Miguel Flores Sánchez (miguel.flores@epn.edu.ec) 2019-09-18 Prólogo Este libro ha sido escrito en R-Markdown empleando el paquete bookdown y está disponible en el repositorio Github: rubenfcasal/simbook. Para generar el libro (compilar) puede ser recomendable instalar la última versión de RStudio y la versión de desarrollo de bookdown disponible en Github: devtools::install_github(&quot;rstudio/bookdown&quot;) Este obra está bajo una licencia de Creative Commons Reconocimiento-NoComercial-SinObraDerivada 4.0 Internacional (esperamos poder liberarlo bajo una licencia menos restrictiva más adelante…). "],
["control-estadistico-de-la-calidad.html", "Capítulo 1 Control Estadistico de la Calidad 1.1 CEC y seis Sigma: Alternativas en R 1.2 Etapa DEFINIR 1.3 Epata ANALIZAR: ANOVA 1.4 Etapa MEDIR 1.5 Etapa CONTROL: 1.6 Etapa ANALIZAR: Analisis de capacidad 1.7 Etapa CONTROLAR y ANALIZAR 1.8 Introducción al diseño de experimentos con R", " Capítulo 1 Control Estadistico de la Calidad 1.1 CEC y seis Sigma: Alternativas en R La calidad se ha convertido en uno de los factores de decisión del consumidor más importantes en la selección de productos y servicios competidores. Esto se ha extendido, independientemente de si el consumidor es un individuo, una organización industrial, una tienda minorista, una institución financiera, o un programa de defensa militar. Consencuentemente, entender y mejorar la calidad es un factor clave para el éxito comercial, el crecimiento y la mejora de la competitividad. Se define calidad como adecuación para uso (calidad de diseño y calidad de conformidad). Ésta es inversamente proporcional a la variabilidad y el objetivo principal es intentar reducir la variabilidad en procesos y productos a través de la mejora de calidad. Este concepto se relaciona con una o más características deseables que debería poseer un producto o servicio. Es uno de los factores de decisión más importantes y por lo tanto entender y mejorar la calidad es un factor clave que lleva al éxito en los negocios, al crecimiento y a una posición competitiva fortalecida. Control estadístico de procesos Para diseñar los gráficos de control propuestos en la presente tesis, se hace uso de la aplicación de técnicas pertenecientes al control estadístico de la calidad (CEC) el cual se define como el uso de herramientas basadas en la estadística y técnicas principalmente diseñadas para la administración y mejora de procesos. Una de las claves cruciales para comprender la medición del rendimiento, y por lo tanto, el control estadístico de procesos es la variación, se distingue entre dos causas de variación dentro de un proceso; aquellas que no pueden ser identificadas y corregidas que se denominan “causas fortuitas o no asignables”, y otras que pueden ser identificadas y se deben al proceso en si, denominadas “causas asignables” Metodología Seis Sigma Seis Sigma es un enfoque revolucionario de gestión que mide y mejora la calidad, ha llegado a ser un método de referencia para satisfacer las necesidades del cliente y al mismo tiempo, lograrlo en niveles próximos a la perfección. [GestioPolis, 2001]. Dicho en pocas palabras, es una metodología de mejora de procesos que busca la reducción de la variación, defectos y otros tipos de errores para así, llegar a un máximo de 3.4 defectos por millón. Este término fue acuñado por Motorola en los años 80 para denominar su iniciativa de reducción radial de defectos en productos. Renació, a medidados de los años 90, con un gran impulso, gracias a la acertividad con la que General Electric la aplicó en su organización (fabricación y servicios) y, sobre todo, por sus resultados económicos espectaculares. La figura muestra una distribución de probabilidad normal como modelo de una característica de calidad con límites de especificación de tres desviaciones estándar en cada lado de la media. [Montgomery, 2007] De acuerdo al gráfico, la probabilidad de producir un producto dentro de estas Figura: Variable normal centrada en µ = T, porcentaje de elementos no conformes segun el criterio Seis Sigma (capacidad de procesos). Se muestran los defectos,por millon (ppm Defective) esperados para cada nivel de calidad del producto o capacidad de proceso. especificaciones es de 0.9973, que corresponde a 2700 partes por millón (ppm). Esto se conoce como rendimiento de calidad Tres Sigma. Sin embargo, supongamos que consiste del ensamblaje de 100 componentes independientes las cuales deben ser no defectuosas para que el producto funcione satisfactoriamente. La probabilidad de que una unidad de producto específica sea no defectuosa es \\[0.9973 × 0.9973 × · · · × 0.9973 = (0.9973)^{100} = 0.7631\\] Esto es, alrededor del 23.7 % de productos elaborados bajo la calidad Tres Sigma serán defectuosos.Tomando en cuenta que muchos productos usados por la sociedad de hoy están compuestos de muchas partes, estos niveles de calidad son inaceptables. En la actualidad, Seis Sigma ha evolucionado desde su aplicación meramente como herramienta de calidad a incluirse dentro de los valores claves de algunas empresas, como parte de su filosofía de actuación. Seguidamente, en la Figura 1, se encuentra los paquetes existentes en R con aplicaciones directas al Control Estadistico de la Calidad (CEC), asi como las herramientas que proporcionan. En esta práctica se relacionarán las herramientas de control estadístico de calidad con la metodología Seis Sigma. Seis Sigma es una metodología de mejora de procesos que persigue la reducción de la variación, los defectos y otros tipos de errores para alcanzar objetivos como aumentar la cuota de mercado, minimizar los costes, incrementar la ganancia, la eficiencia, la imagen de marca, etc. Aun teniendo un claro enfoque empresarial e industrial, sus procedimientos pueden aplicarse a campos como la investigación o la administración pública. En la Figura 2 se muestran las distintas etapas del proceso, su objetivo y la relación entre ellas. Hoy en día, Seis Sigma puede verse como un conjunto de métodos y procedimientos de aplicación de la estadística para la mejora y control de procesos productivos, de servicios o de I+D+I, desde un enfoque de CEC. Por esto último, en esta práctica se ha decidido presentar las diversas técnicas de CEC dentro de las etapas de la metodología Seis Sigma correspondientes. En la Figura 3 se enumeran las técnicas estadísticas de control de calidad susceptibles de aplicarse en cada una de las etapas del procedimiento Seis Sigma. 1.2 Etapa DEFINIR En esta estapa se identifica el problema, se establecen los objetivos y las prioridades para subsanarlo y, finalmente , se lanza el proyecto. En la fase definir se identifican los posible proyectos Seis Sigma que deben ser evaluados por la dirreción para obtimizar los recursos. Habiendo identificado, seleccionado, estandarizado y documentado el proyecto, asi como sus puntos de medición y fuentes de varación, se prepara y selecciona el equipo más adecuado para ejecutarlo, asignándole la prioridad adecuada. El objetivo de la fase DEFINIR es reunir a todas las partes interesadas, captar sus conocimientos y puntos de vista acerca de los procesos involucrados, fijar un objetivo común y definir como contribuye cada parte ( o el papel que cada parte tiene) a la solución del problema (reducción de defectos, coste, consumo eléctrico,…) La contribución de cada parte, los hitos y responsabilidades deben escribirse en lo que se conoce como un Mapa de Procesos 1.2.1 Mapa de Procesos El mapa de procesos es una representación gráfica que identifica todos los procesos que existen en una empresa, laboratorio o proyecto en particular, además de mostrar la interrelación entre ellos. Pasos para construir un mapa de procesos Identificación de las entradas y salidas: Las entradas y salidas del proceso constituyen el mapa de procesos de alto nivel. Las entradas del proceso aparecen identificadas mediante las X mayúsculas dentro del mapa de procesos. Las entradas X suelen relacionarse con las 6 M: Además de las seis M: machines, methods, materials, measurements, mother nature (medio ambiente), y manpower (mano de obra). Aparte de estas últimas, las entradas pueden identificarse con aspectos como la energía, las regulaciones, etc. Las salidas se corresponden con características de producto o servicio. Las características CTQ (variables críticas para la calidad, “Critical To Quality”) de la salida son las Y del proceso. Identificación y listado de los pasos o etapas del proyecto Cuanto más detallada sea la división del proceso, más preciso será el análisis posterior. Hay dos tipos de etapas: las que implican un valor añadido al producto y las que no (como el transporte, el almacenamiento, la inspección, etc.). Identificación de las caracteristicas o salidas de cada etapa Son las y (en minúscula) del mapa de procesos. Pueden ser de un producto en proceso, materiales, datos… o mismo características del producto final, que pueden sufrir cambios de una etapa a otra. Identificar los parámetros correspondientes a cada etapa Los parámetros que afectan al proceso en una etapa determinada se conocen como las x (en minúscula) de cada etapa. Estos parámetros condicionan en el coste, calidad u otros aspectos importantes de las salidas o características del producto. La clasificación de los Parámetros Es necesario evaluar la influencia de los parámetros en las características. Los parámetros pueden pertenecer a los siguientes grupos según su tipo de influencia: N (de ruido): los factores no controlables. C (factores controlables): se pueden modificar durante el proceso. P (de procedimiento): factores controlables a través de un procedimiento estándar. Cr (críticos): los que tienen más influencia en el proceso. 1.2.1.1 Caso Práctico: Ejemplo PIZZA (Ver Práctica 1.- Ejemplo 1: Pizza) 2.2.1 1.2.2 Diagrama de Ishikawa o espina de pescado Los diagramas causa efecto, también llamados diagramas de ISHIKAWA o de espina de pescado, están indicados para asociar multiples causasa a un solo efecto. 1.2.2.1 Caso Práctico: Retrasos en la construcción de obras (Ver Práctica 1.- Ejemplo 2: Ishikawa) 2.2.2 1.2.3 Diagrama de Pareto Una técnica clásica de visualización que se utiliza en la fase DEFINIR y disponible en los paquetes qcc y qualityTools es el diagrama de Pareto. Los diagramas de Pareto son un caso especial de los gráficos de barras que ayudan a separar las pocas causas que son vitales de las muchas que son triviales para un problema o un efecto dado. De esta manera los diagramas de Pareto nos permiten visualizar cuánto contribuye cada causa de un problema específico al efecto estudiado. 1.2.3.1 Caso Práctico: retrasos en la construcción de obras (Ver Práctica 1.- Ejemplo 3: Pareto) 2.2.3 1.3 Epata ANALIZAR: ANOVA 1.3.1 Introducción Planteamiento del problema El análisis de la varianza (ANOVA) es un método estadístico que permite estudiar la relación entre una variable dependiente cuantitativa y una o varias variables independientes cualitativas. Objetivo Determinar si varias (k) muestras de una variable proceden de la misma población o de poblaciones distintas; es decir, contrastar simultáneamente la homogeneidad de las mismas. Conceptos básicos Factores: cada una de las variables independientes, causas de la posible heterogeneidad de las muestras. Niveles del factor: cada uno de los valores posibles del factor. Efectos: medida de la influencia de los factores en la variable dependiente. Error muestral: debido a la aleatoriedad en la selección de las muestras. Clasificación de los modelos Según el número de factores; modelo con un único factor (modelo simple), modelo con varios factores (modelo múltiple) Por la forma de disponer la información: modelo completamente aleatoriazado (se puede recoger la información de forma completamente aleatoria); modelo aleatorizado en bloques. Por el tipo de efectos: modelo de efectos fijos (se fijan a priori los k niveles del factor y el contraste y las conclusiones del mismo se aplican a todos ellos). PROYECTO: Análisis de la varianza de un factor, efectos fijos e información completamente aleatorizada Planteamiento Se trata de estudiar la relación entre: \\(Y\\): variable dependiente (respuesta) cuantitativa \\(A\\): variable independiente o factor cualitativa, cada uno de sus k niveles define un grupo Modelo probabilístico Hipótesis a establecer sobre el modelo: Existen \\(k\\) niveles (grupos) del factor A: \\(i=1, 2, \\dots, k\\); a cada grupo \\(i\\) le corresponde un valor de \\(Y\\) dado por \\(Y_i\\) Homoscedasticidad: \\[Var(Y_i)= \\sigma^2 \\ \\ \\ \\forall i=1, 2, \\dots, k \\] \\(\\epsilon_i \\mapsto N(0,\\sigma^2) \\ \\): \\(Y_i \\mapsto N(\\mu_i,\\sigma)\\) En el modelo (b), \\(\\delta_i \\mapsto N(0,\\sigma_b)\\) Modelo: puede expresarse alternativamente como \\[ \\mu_i= \\mu + \\epsilon_i;\\quad i=1,2,\\dots,k \\] \\[\\mu_i= \\mu + \\delta_i + \\epsilon_i; \\quad i=1,2,\\dots,k;\\quad \\sum_{i=1}^k \\delta_i = 0 \\] Las observaciones de \\(Y\\) se podrian representar como Grupo Observaciones del factor 1 \\(y_{11}\\) \\(y_{11}\\) \\(\\dots\\) \\(y_{1j}\\) \\(\\dots\\) \\(y_{1n}\\) \\(\\dots\\) \\(\\dots\\) i \\(y_{i1}\\) \\(y_{i2}\\) \\(\\dots\\) \\(y_{ij1}\\) \\(\\dots\\) \\(y_{in}\\) \\(\\dots\\) \\(\\dots\\) k \\(y_{k1}\\) \\(y_{k2}\\) \\(\\dots\\) \\(y_{kj}\\) \\(\\dots\\) \\(y_{kn}\\) 1.4 Etapa MEDIR En la fase medir se identifican las características clave del producto (variables resultado) y los parámetros que afectan al funcionamiento del proceso (variables de entrada). Esta caracterización nos llevará a definir el sistema de medición (de materia prima e insumos, de las variables críticas del proceso, de los productos terminados, de las no conformidades, de la satisfacción del cliente, de la eficacia de los proveedores, de la eficiencia y/o eficacia de la organización) para así poder evaluar la calidad del proceso. Completar la identificación de características clave del proceso y completar el mapa de proceso. Desarrollar el plan de recolección de datos. Validar el sistema de medición (evaluación R &amp; R). Toma de datos. Comenzar a relacionar las características o salidas con las causas o entradas. Es propio de esta etapa la caracterización de la distribución de probabilidad de cada variable o característica de estudio (por ejemplo, la evaluación de la normalidad de los datos). 1.4.0.1 Caso Práctico: Etapa ANALIZAR: ANOVA (Ver Práctica 1.- Anova) 2.3 1.4.1 Estudios R&amp;R Es un procedimiento muy común en estudio de procesos industriales que consiste en la evaluación de la repetitividad y la reproducibilidad de un sistema de medición. Llamamos REPETITIVIDAD a la precisión de un sistema de medición (también llamado “Gage”), estimada mediante la desviación estándar de las mediciones realizadas sobre una misma pieza, por el mismo operario y la misma máquina. La REPRODUCIBILIDAD es la parte de la varianza global debida al factor operador o máquina y a la interacción de operador o máquina con el factor pieza o unidad medida. El modelo general está dado por: \\[ \\sigma_{total}^2= \\sigma_{piezas}^2+\\sigma_{\\text{operador o máquina}}^2+\\sigma_{\\text{operador o máquina x piezas}}^2 + \\sigma_{error}^2 \\] Donde \\[ \\sigma_{Reproducibilidad}^2= \\sigma_{\\text{operador o máquina}}^2+\\sigma_{\\text{operador o máquina x piezas}}^2 \\] \\[ \\sigma_{Repititividad}^2= \\sigma_{error}^2 \\] \\[ \\sigma_{RR}^2= \\sigma_{Reproducibilidad}^2+ \\sigma_{Repititividad}^2\\] El procedimiento para evaluar si un sistema de medida es adecuado es el siguiente: Aplicar un análisis de la varianza con dos factores y su interacción (máquina u operador, pieza -unidad en general- y su interacción). Si el factor operador y su interacción con piezas son significativos, el sistema de medida no es el adecuado. Han de completarse los resultados con los parámetros calculados en el punto 3. Calcular las varianzas relativas a la repetitividad y reproducibilidad. Calcular parámetros derivados de estas dos varianzas que son indicadores de la bondad del sistema de medida y complementan los resultados del ANOVA. Estos indicadores se expresan como % o tanto por uno de la varianza total, de 6· desv. típ., etc. En un estudio R &amp; R, los resultados finales se dan en porcentaje de la variación de la repetitividad. Antes de recolectar datos de su proceso (por ejemplo, para controlar o analizar la capacidad del proceso), se deben utilizar estudios R &amp; R para confirmar que el sistema de medición mide de forma uniforme y exacta, y que discrimina adecuadamente entre partes. 1.4.1.1 Caso práctico Gage R &amp; R: tecnología mecánica-sistema de medida del diámetro de una junta tórica de caucho (Ver Práctica 1.- R&amp;R) 2.4 1.5 Etapa CONTROL: En la fase de control deben monitorizarse o someter a vigilancia los logros conseguidos en etapas anteriores, así como documentar las nuevas condiciones o especificaciones del proceso de estudio. Esta etapa está caracterizada por el empleo de herramientas basadas en la detección de errores y su corrección: las más representativas son los gráficos de control. El objetivo último de la mejora de la calidad no es sólo ofrecer productos de buena calidad, sino también mejorar la productividad y la satisfacción de los clientes (que permitirá afrontar el gasto del proceso de mejora). Una forma de mejorar la productividad es a través de la reducción de los defectos y las revisiones, por inspección y control de los procesos en curso antes de que se generen productos o servicios defectuosos. Las variaciones de las características medidas son desviaciones de los objetivos prefijados. Aparecen independientemente de que el proceso esté o no bajo control. Las causas que originan la variaciones se dividen en dos categorías: comunes (E. Deming) o aleatorias (W. Shewhart), cuando son inherentes al proceso de producción, y especiales (E. Deming) o asignables (W. Shewhart ) cuando no son atribuibles al proceso de producción (por ejemplo, un operador que tiene sueño). Importante: para ser capaz de predecir el nivel de calidad de los productos o servicios, los procesos que los generan han de ser estables, es decir, con total ausencia de causas especiales de variación. 1.5.1 Gráficos de control El gráfico de control es la herramienta más usada en el análisis de variaciones con el fin de evaluar, monitorear y controlar el redimiento de los procesos de producción o servicios; mediante el uso de los gráficos de control se pretende identificar variaciones en el proceso debido a causas comunes y causas especiales. A través de los años, los gráficos de control se han posicionado entre los medios de control operativo más importantes, hasta adquirir tanta importancia como los controles de costos y materiales. La tecnología moderna de los ordenadores ha facilitado la implementación de los gráficos de control para cualquier tipo de proceso, ya que es posible obtener y analizar los datos en tiempo real y en línea en el centro de trabajo. [Scepi and Acconcia, 1996] Un gráfico de control es un gráfico de dos dimensiones cuyo eje y representa la variable que estamos monitorizando. Los valores de la característica a medir se representan secuencialmente con respecto al tiempo. Los valores de la variable pueden ser individuales o, más comúnmente, los promedios referidos a grupos de tamaño 4, 5, etc., llamados muestras racionales. El eje x de la gráfica muestra los números de identificación para el conjunto de ítems (individuales o grupos). Los valores de la variable se representan con puntos unidos mediante líneas rectas, para poder identificar patrones indicadores de cambios significativos en el rendimiento del proceso. Gráficamente, se caracterizan por: • Una línea central (CL). Media de las variables incluidas en la muestra. Los valores monitorizados varían en torno a esta media. • Límite de control inferior (LCL), por debajo del cual es muy poco probable que se produzcan realizaciones de la variable. • Límite de control superior (UCL). El LCL y UCL son simétricos si la distribución de probabilidad de la variable es simétrica (se suele utilizar la normal). Utilidades de los gráficos de control: • Evitar que el proceso esté fuera de control, detectando las causas asignables a cada variación de la característica medida y tomando las medidas al respecto. • Para no hacer ajustes cuando no se necesitan. La mayoría de los procesos de producción dan a los operadores margen de maniobra para hacer ajustes en los equipos que están utilizando. Los gráficos de control pueden indicar cuando los ajustes son necesarios y cuando no lo son. • Para determinar el rango natural (límites de control) de un proceso y para comparar este rango con sus límites especificados. Si el rango de los límites de control es más amplio que el de los límites especificados, el proceso va a generar productos defectuosos y tendrá que ser ajustado. • Dar a conocer la capacidad y estabilidad del proceso, entendiendo como capacidad de proceso a su adecuación para ofrecer productos dentro de los límites especificados continuamente en el tiempo. • Para llevar a cabo el proceso de monitorizado del proceso y así evitar los defectos en el producto final. • Para facilitar la planificación de la asignación de recursos de producción. Las variaciones de una característica de calidad determinan la cantidad de defectos. Tener información para predecir estas variaciones ayuda a asignar los recursos. Entre las varias razones para el uso de los gráficos de control, Montgomery [2007] destaca las siguientes: Son una técnica comprobada para reducir la variabilidad Son efectivos en la prevención de defectos Previenen ajustes innecesarios en el proceso Proveen información de diagnóstico__ Proveen información acerca de la capacidad del proceso Los gráficos de control se construyen en dos fases El uso del gráfico de control estándar implica aplicaciones de fase I y fase II, con dos objetivos diferentes y distintos. En la fase I, un conjunto de datos históricos procesados es recolectado y analizado a la vez en un análisis retrospectivo, usando esta muestra preliminar se estiman los límites de control. En esta fase se identifican las principales causas de variación asignables y se toman las medidas para corregirlas, hasta lograr la estimación de los límites de control de la variable CTQ correspondiente al proceso bajo control. Los límites de control se calculan como un intervalo de confianza. Se suelen tomar aquellos que distan de la media en tres desviaciones típicas \\((\\mu \\pm 3\\sigma)\\). Al conjunto de datos históricos se lo denomina muestra de calibrado, siendo el contraste de hipótesis \\((H_0)\\) sobre una misma población F. Así, en la fase I comparamos una colección de m puntos contra un conjunto de límites de control calculados a partir de esos puntos. Se recomienda que los límites de control naturales se estimen a partir de una muestra de calibrado constituida por 20 o más observaciones. [Montgomery, 2007] Es bastante usual suponer que en la fase I el proceso está inicialmente fuera de control, por lo que el objetivo del analista es llevar el proceso a un estado de control estadístico. Los límites de control se calculan en función de los m subgrupos y los datos graficados en los gráficos de control. Se investigan los puntos que están fuera de los límites de control, en busca de posibles causas asignables. Los puntos fuera de los límites de control se excluyen y se calcula un nuevo conjunto de límites de control revisados. Luego se recopilan nuevos datos y se comparan con estos límites revisados. En ocasiones, este tipo de análisis requerirá varios ciclos en los que se emplee el gráfico de control, se detecten y corrijan las causas asignables, se calculen los límites de control revisados y se actualize y amplíe el plan de acción fuera de control. Los tipos de causas asignables que usualmente ocurren en la fase I resultan en cambios de proceso bastante grandes. La longitud de corrida promedio (ARL) no es un buen indicador de rendimiento para esta fase, dado que se busca la probabilidad de que se detecte una causa asignable en lugar de la aparición de falsas alarmas. En la fase II, las muestras tomadas posteriormente se representan en un gráfico con los límites de control anteriores. Cuando las observaciones individuales de la variable de estudio X están dentro de los límites de control, se dice que el proceso está estadísticamente bajo control. Los límites de control son completamente diferentes de los límites de especificación (aquellos aceptados por el cliente o fijados por los ingenieros, que representan la consigna o target). La Figura 1 muestra el proceso estándar de monitorización de una variable CTQ (critical to quality). Nota: Las hipótesis de partida para los gráficos de control que a continuación se muestran son la normalidad e independencia de las observaciones. Existen gráficos de control para medidas dependientes y variables no normales (por ejemplo Weibull). Sin embargo, los gráficos EWMA son insensibles a la no normalidad de los datos (Montgomery, 2005), caso completamente contrario a los gráficos de medidas individuales. Ventajas de los gráficos de control de atributos: Los gráficos de control de atributos tienen la ventaja de resumir rápidamente los diversos aspectos de la calidad de un producto, es decir, el ingeniero puede simplemente clasificar los productos como aceptables o inaceptables, basándose en diversos criterios de calidad. Por tanto, la elaboración de gráficos de atributos no requiere procedimientos especialmente costosos en tiempo ni necesitan el empleo de precisos dispositivos de medición. Además, este tipo de gráfico tiende a ser más fácil de entender por los gerentes que no están familiarizados con los procedimientos de control de calidad. Ventajas de los gráficos de control de variables: Gráficos de control de variables son más sensibles que los gráficos de control de atributos. De hecho, los gráficos de control de variables nos pueden alertar de problemas de calidad antes de que se produzca cualquier “fuera de control” o “inaceptable” real que pudiera ser detectado por el diagrama de atributos. Reglas para la detección de procesos fuera de control (Western Electric Handbook, 1956): Un punto fuera de los límites de control \\(3\\sigma\\). Dos puntos de tres consecutivos más allá de los límites de aviso \\(2\\sigma\\). Cuatro de cinco puntos consecutivos a una distancia de \\(\\sigma\\) o más de la línea central. Ocho puntos consecutivos a un lado de la línea central. No se suelen utilizar más de 3 reglas a la vez para evitar incurrir en falsos rechazos de la \\(H_0\\) (proceso bajo control). La librería R qcc emplea la regla 1 y otra regla que detecta como estado fuera de control la situación donde más de 6 medidas seguidas están a un lado de la CL. 1.5.2 Gráficos de control multivariantes Cuando varias variables aleatorias caracterizan la calidad de un proceso/servi- cio, es necesario aplicar técnicas estadísticas de control de calidad multivariante. Existen dos retos formidables en el análisis de procesos de datos multivariantes. Primero, los datos se vuelven más dispersos mientras aumenta la dimensión. Re- querimientos de tamaños de muestras son formidables y una muestra de referencia de cientos de miles de observaciones puede ser necesitada para caracterizar por completo un proceso en control si tres o más variables de calidad (que no siguen una distribución normal multivariante) son medidas. Usar gráficos de control indi- viduales para monitorear las p características independientes separadamente puede ser muy engañoso. Si una de las variables está fuera de control, el sistema resultaría fuera de control. Si P(Error Tipo I) = \\(\\alpha\\), entonces el error Tipo I para el control con- junto de las p medidas independientes, puede ser muy grande para un valor grande de p, \\(\\alpha´\\) = 1 − (1 − \\(\\alpha)^{p}\\). De igual forma, si todas las variables están fuera de control, todo el sistema estaría fuera de control. Si P(Error Tipo II) = \\(\\beta\\), entonces el error Tipo II para el control conjunto de las p medidas independientes, puede ser muy grande para un valor grande de p, \\(\\beta ´\\) = 1 − (1 − \\(\\beta)^p\\). Por lo tanto, los límites de control son diferentes a los construidos; si las varia- bles son dependientes, el cálculo del nivel de significancia, α, se vuelve complicado. Este tema es particularmente importante hoy en día, ya que los procedimientos de inspección automáticos hacen que sea relativamente fácil medir muchos parámetros en cada unidad de producto fabricado.[Montgomery, 2007] Más aún, existen cambios en la localización o escala mientras no sea posible con- trolar la estructura de correlación entre dos (o más) variables. En este sentido, es posible tener dos variables las cuales estén ambas en control cuando son consideras por separado en un sentido univariante, pero fuera de control cuando son conside- radas en conjunto bajo un esquema multivariante [Wierda, 1994]. Figura 1.12: Clasificación de gráficos de control de acuerdo al tipo de muestra y distribución de las observaciones En la figura 1.12 se muestran los distintos tipos de gráficos de control estándar dependiendo si el proceso está definido para uno o más variables y de si se asume o no una distribución paramétrica para las observaciones. 1.5.3 Graficos de control por variables Para el control de una característica medible y representada por una variable aleatoria X, existen dos tipos de gráficos, por una parte aquellos que nos ayudan a controlar las medidas de posición (de la media o mediana) y, por otra, los que controlan la dispersión de la variable (gráficos de desviaciones, varianzas o recorridos). Este tipo de gráficos son más informativos que los gráficos de atributos; aparte de darnos una idea de la conformidad o no conformidad del proceso, nos dan información acerca del nivel o magnitud. En este curso se trabajará fundamentalmente con dos paquetes: el paquete qcc y la librería qcr (desarrollada por Miguel Flores). Librería qcc El paquete R qcc sirve principalmente para generar gráficos de control. Primero se crea un objeto qcc.groups, utilizando la función con el mismo nombre, con los siguientes argumentos: las medidas en formato de vector y la identificación de las mismas como pertenecientes a un grupo. A continuación, se crea un objeto qcc con el objeto qcc.groups como argumento, indicando el tipo de gráfico de control. Una vez creado el objeto qcc, podemos realizar dos acciones sobre él: un resumen y un gráfico. Para trabajar con casi todas las funciones y aplicaciones que existen dentro de este paquete estadístico, debemos crear un objeto qcc. Necesitamos básicamente dos cosas: unos datos (un data frame, una matriz, un vector,..) y un “string value” especificando el tipo de control que deseamos hacer (por atributos o por variables). También, opcionalmente, se pueden modificar el tamaño (sizes), el tipo de estimación de la desviación estándar (std.dev), los límites de control (limits), el valor objetivo del proceso (target)… La única diferencia que existe a la hora de trabajar con variables o con atributos radica en “type”. Para variables podemos optar por elegir entre “xbar”, “xbar.one”, “R” o “S” y para atributos tenemos “p”, “np”, “c”, “u” o “g”. EJEMPLO 2.1 : Gráficos qcc para variables 3.2.1 Librería qcr Es una librería creada fundamentalmente para obtener gráficos de control univariantes (“xbar.one”, “R” o “S” y “p”, “np”, “c”, “u” o “g”) y multivariantes (MEWMA, MCUSUM y T2). Presenta algunas mejoras en el proceso de obtención de los límites de control naturales de una variable CTQ. En esta sección se utilizará como ejemplo el siguiente caso práctico: Una conocida empresa química está desarrollando la patente de una nueva variante de piedra artificial, compuesta en su mayor parte por cuarzo (93 wt%) y resina de poliéster. Esta compañía pone en marcha una planta piloto donde se comienzan a producir planchas de este material a escala industrial. Con el fin de medir el grado de homogeneidad del producto, se toman 50 submuestras, realizándose 5 medidas por plancha de la dureza Vickers correspondiente a distintas zonas de la piedra artificial (Ejercicio1.r). ¿Qué tipo de gráficos de control serían los más adecuados para controlar el nivel y la dispersión? Hallar los límites de control natural 3σ con una muestra de calibrado y, seguidamente, monitorizar las muestras restantes. Comentar los resultados, identificar patrones e identificar sus posibles causas. (ver Practica 2) Ejemplo 2.2: tiempos de renderizado 3.2.3 1.5.3.1 Gráficos de control \\(\\hat{x}\\) y R, \\(\\hat{x}\\) y S \\(\\hat{x}\\) y R Cuando una característica de calidad es una variable, es necesario controlar tanto el valor medio de la característica como su variabilidad. El gráfico \\(\\bar{x}\\) se usa para controlar la media del proceso, mientras que la variabilidad se puede monitorear con un gráfico de control para el rango denominado gráfico de control R. Para construir límites de control, debemos calcular la media y el rango de cada muestra \\(\\bar{x}_i\\) y \\(R_i\\), respectivamente \\(i = 1, \\dots, n\\). La media global y el rango se calcularán como: \\[ \\bar{R}=\\frac{\\sum_i R_i}{ k} \\quad \\text{y} \\quad \\bar{\\bar{x}}=\\frac{\\sum_i \\bar{x}_i}{k}\\] Puesto que \\(\\frac{R_i}{d_2}\\) es un estimador insesgado, donde \\(d_2\\) es un estadístico de rango que representa la media del rango relativo dado por \\(W = \\frac{R}{\\sigma}\\), luego, $ =$ se usará como estimador centrado de la desviación estándar teórica. A partir de eso hay que contrastar si cada valor \\(\\bar{x}_i\\) está en el intervalo \\[ \\left[ \\bar{\\bar{x}}-\\frac{3\\bar{R}}{\\sqrt{n} d_2}; \\bar{\\bar{x}}+\\frac{3\\bar{R}}{\\sqrt{n} d_2} \\right] \\] con una probabilidad aproximada al $ 97,73%$ Entonces los límites de control son: \\[ LCI = \\bar{\\bar{x}}-\\frac{3\\bar{R}}{\\sqrt{n} d_2}\\] \\[ LCS = \\bar{\\bar{x}}+\\frac{3\\bar{R}}{\\sqrt{n} d_2}\\] \\(\\hat{X}\\) y R A veces es deseable estimar la desviación estándar del proceso directamente en lugar de indirectamente mediante el uso del rango R, esto lleva a gráficos de control para \\(\\bar{x}\\) y S, donde s es la desviación estándar de la muestra. Para la construcción de los límites de control, la media y la desviación deben calcularse para cada muestra \\(\\bar{x}_i\\) y \\(s_i\\), respectivamente \\(i = 1, . . . , n\\). La media global es un estimador insesgado de la media teórica, mientras que la desviación estándar muestral es un estimador sesgado de la desviación estándar teórica, luego \\[ \\hat{\\sigma} = \\frac{\\bar{s}}{c_2}= \\frac{\\sum_i s_i}{c_2 k }\\] se usara como un estimador centrado de la desviación estándar téorica, donde \\(c_2\\) es una constante que depende del tamaño de muestra n. Cada valor \\(\\bar{x}_i\\) debe estar en el intervalo \\[ \\left[ \\bar{\\bar{x}}-\\frac{3\\bar{s}}{\\sqrt{n} c_2}; \\bar{\\bar{x}}+\\frac{3\\bar{s}}{\\sqrt{n} c_2} \\right] \\] con una probabilidad aproximada al $ 97,73%$ Entonces los límites de control para la media son: \\[ LCI = \\bar{\\bar{x}}-\\frac{3\\bar{s}}{\\sqrt{n} d_2}\\] \\[ LCS = \\bar{\\bar{x}}+\\frac{3\\bar{s}}{\\sqrt{n} d_2}\\] La desviación estándar se debe estimar mediante el análisis de datos pasados. Primero se procede a cargar la librería qcc, suponiendo que ya haya sido instalada a través del CRAN de R. Veamos el código en R para el caso de la base de datos Ejercicio1: 1.5.3.2 Gráficos de control para medidas individuales También se pueden construir gráficos de control por variables para las observaciones individuales tomadas en una línea de producción. Este tipo de gráficos se hacen imprescindibles cuando el coste de cada observación es muy alto y, por tanto un sistema de muestreo como el anteriormente descrito es inasumible. Ejemplos: el número de quejas de los clientes o devoluciones de productos que sólo está disponible una vez al mes, los casos en los se lleva a cabo una inspección automática de cada unidad de producto, etc. En ese último caso, el interés radica en detectar pequeños cambios en la calidad del producto (por ejemplo, el deterioro gradual de la calidad debido al desgaste de la máquina). Aparte de los gráficos para muestras individuales y rangos medios, los gráficos CUSUM y EWMA pueden ser alternativas más adecuadas en estas situaciones. En el siguiente ejemplo se simula el caso particular de una empresa de animación por ordenador (Bran Entertaiment) que dispone de 3 operarios para realizar operaciones de renderizado de imágenes. Hasta hace relativamente poco sólo una persona se dedicaba a este trabajo, siendo especialista. Debido a su periodo de vacaciones, otro operario de la empresa, el de más antigüedad, se ocupó del proceso hasta el momento en que pidió una baja. A partir de ese momento, un becario fue el encargado del proceso. Se pretende obtener los límites de control natural del proceso e identificar las causas asignables de aquellos valores fuera de control. NOTA: el proceso de renderizado se desarrolla con el fin de generar en un espacio espacio 3D formado por estructuras poligonales una simulación realista del comportamiento tanto de luces, texturas y materiales (agua, madera, metal, plástico, tela, etcétera) como también de los comportamientos físicos. Este es el caso de la simulación de colisiones y fluidos, ambientes y estructuras físicas verosímiles.` 1.5.3.3 Interpretación de los gráficos \\(R-\\bar{x}\\) Seguidamente se muestran una serie de patrones que suelen aparecer en el estudio de este tipo de gráficos de control, a modo de guía para una interpretación de los mismos: Gráfico 1.1: Un patrón natural es aquel en el que no existe ninguna relación identificable entre los puntos trazados. No hay puntos que caigan fuera de los límites de control, la mayoría de los puntos están cerca de la línea central, y algunos puntos están cerca de los límites de control. Los patrones naturales son indicativos de un proceso que está en control. Gráfico 1.2: Muchas causas pueden provocar un cambio repentino en el nivel en un gráfico de la media. Los cambios bruscos se producen debido a los cambios en las configuraciones de proceso como temperatura, presión o la profundidad del corte. Un ejemplo de cambio repentino podría ser un cambio en el tiempo de espera del cliente en un supermercado porque el número de cajeros disponibles ha cambiado. Nuevos operadores, nuevos equipos, nuevos instrumentos de medición, nuevos proveedores y nuevos métodos de procesamiento son otras razones para los cambios repentinos en los gráficos media y rango. Gráfico 2.1: Se producen Cambios graduales en el nivel cuando un parámetro de proceso cambia gradualmente durante un período de tiempo. Después, el proceso se estabiliza. Un gráfico de la media puede exhibir ese cambio, porque la calidad de entrada de materias primas o componentes cambió con el tiempo, porque se modificó el programa de mantenimiento o el estilo de supervisión. En cuanto al gráfico R, ese cambio puede surgir a causa de un nuevo operador, una disminución de la habilidad de los trabajadores debido a la fatiga o la monotonía, o una mejora gradual de la calidad de entrada de las materias primas (debido por ejemplo a que un proveedor ha desarrollado un sistema de control estadístico de procesos). Gráfico 2.2: Las tendencias se diferencian de los cambios graduales en que las tendencias no se estabilizan o atenúan. Las tendencias representan cambios, incrementos o decrementos, de pendiente constante. Un diagrama x ̅ puede exhibir una tendencia debido al desgaste progresivo de una herramienta que afecta al proceso productivo, deterioro gradual de equipos, acumulaciones de suciedad en moldes y accesorios, a un cambio gradual en la temperatura o mismo el aumento del consumo eléctrico debido a la contratación creciente de personal. Un gráfico R puede mostrar una tendencia debido a una mejora gradual de la habilidad del operador como resultado de la formación en el puesto de trabajo o a una disminución de la habilidad del operario debido a la fatiga. Gráfico 3.1: Los patrones cíclicos se caracterizan por un comportamiento periódico repetitivo en el sistema. Un gráfico x ̅ puede mostrar un comportamiento cíclico debido a la rotación de los operadores, cambios periódicos en la temperatura y la humedad (por ejemplo, un inicio en frío por la mañana), la periodicidad de las propiedades mecánicas y químicas de un material determinado, o la variación estacional de las materias primas recibidas (p. ej., alimentos). Un gráfico R puede presentar patrones cíclicos debido a la fatiga del operador y su posterior activación después de las pausas, la diferencia entre los turnos, o el mantenimiento periódico de los equipos, etc. Si se toman muestras con muy poca frecuencia, se corre el riesgo de sólo representar los puntos de mayor o menor nivel del ciclo. Por eso se deberían tomar muestras de referencia si se sospecha algún comportamiento cíclico en el proceso. Gráfico 3.2: Wild patterns o patrones salvajes se refieren a puntos que son estadísticamente diferentes al resto. Se clasifican en Freaks y Bunches (o grupos). Los freaks se deben a perturbaciones externas que influyen en una o más muestras. Son puntos demasiado pequeños o demasiado grandes con respecto a los límites de control. Algunas de las causas especiales de los freaks incluyen, fallos repentinos de energía en una instalación, el uso de una nueva herramienta de prueba para un breve período de tiempo, el fallo de un componente, etc. Gráfico 4.1: Los bunches o grupos, son agrupaciones de varias observaciones que son decididamente diferentes de los demás puntos de la trama. La aparición de un nuevo proveedor por un corto período de tiempo, el uso de una máquina diferente de forma puntual y el trabajo de un operario contratado por unas horas o un día pueden causar la aparición de estos patrones. Gráfico 4.2: Los patrones de mezcla se deben a la presencia de dos o más poblaciones en los datos estudiados y se caracterizan porque los puntos del gráfico caen cerca de los límites de control, estando ausentes del área cerca de la línea central. La existencia de un conjunto de valores demasiado altos y demasiado bajos puede ser debida a las diferencias en la calidad de las materias primas proporcionadas por dos proveedores diferentes. La opción correctora indicada es la elaboración de un gráfico diferente para cada proveedor. Estos patrones pueden aparecer al no separar los resultados obtenidos por dos o más máquinas, operadores, sistemas de medición, métodos de producción, fábricas, establecimientos, etc. Gráfico 5.1: Los patrones de estratificación aparecen cuando dos o más distribuciones poblacionales de la misma característica de calidad están presentes en el mismo gráfico. En este caso, las dos poblaciones aparecen mezcladas en cada submuestra. Este patrón se caracteriza por el hecho de que la mayoría de los puntos están muy cerca de la línea central, con casi ningún punto cerca de los límites de control. Podría llevarnos erróneamente a la conclusión de que el proceso está bajo control. Por ejemplo, tenemos datos obtenidos en turnos, cada uno diferente con diferente rendimiento. Para impedir la aparición de estos patrones, se deberían tener gráficos de control independientes para cada turno. Se puede evitar este fenómeno eligiendo cuidadosamente las submuestras, con el objeto de no mezclar poblaciones. Gráfico 5.2: Se produce un patrón de interacción cuando el nivel de una variable afecta al comportamiento de otras variables asociadas con la característica de calidad de interés. Por otra parte, el efecto combinado de dos o más variables sobre la característica de calidad de salida puede ser diferente del efecto individual de cada variable. Ejemplo: supongamos que en un proceso químico, la temperatura y la presión son dos variables controlables importantes que afectan a la característica de calidad (salida) de interés. Una baja presión y una temperatura elevadas pueden producir un efecto muy deseable en la característica de salida, mientras que una presión baja por sí misma no tiene en absoluto ese efecto. Un método de muestreo efectivo implicaría el control de la temperatura a varios valores altos de la misma, para luego determinar el efecto de la presión sobre la característica de salida y para cada valor de temperatura. 1.5.4 Gráficos de control para atributos En ocasiones una característica de calidad no puede o no interesa medirse numéricamente y tan solo se observa si presenta o no determinada propiedad (un producto es defectuoso o no, una pieza encaja o no en otra, un mecanismo funciona o no funciona, etc.). En control de calidad suele emplearse el término conformidad o no conformidad en lugar de éxito o fracaso (defecto). 1.5.4.1 Gráficos de Control p Proporción de disconformidades. Si p es la proporción poblacional de unidades no conformes: \\[ UCL = \\bar{p} + 3\\frac{\\sqrt{\\bar{p}(1-\\bar{p})}}{\\sqrt{n}} \\quad \\text{y} \\quad UCL = \\bar{p} - 3\\frac{\\sqrt{\\bar{p}(1-\\bar{p})}}{\\sqrt{n}} \\] En este tipo de gráfico, se muestra el porcentaje de unidades defectuosas (por lotes, por día, por cada máquina, etc.) como en el gráfico U. Sin embargo, los límites de control de este gráfico no se construyen utilizando la distribución de eventos poco frecuentes, sino la distribución binomial (de proporciones), que por el Teorema central del límite se aproxima a una normal \\((np&gt;5\\) y \\(n(1-p)&gt;5\\), siempre que p no sea excesivamente próximo a 0 o 1). Por lo tanto, este gráfico es adecuado en situaciones donde la ocurrencia de unidades defectuosas no es poco común (por ejemplo, donde el porcentaje de unidades defectuosas pueda ser más del \\(5 \\%\\) del número total de unidades producidas). Nota: El número de no conformidades se distribuye como una \\(B(n,p)\\), que, si se cumplen las condiciones, se puede aproximar a una \\(N(n·p, \\sqrt{(n·p·(1-p))}\\). Entonces, la proporción media \\(\\bar{p}\\) se distribuirá como una \\(N(\\mu,\\frac{\\sigma}{\\sqrt{n}})\\). 1.5.4.2 Gráficos de control np Número de disconformidades. Si p es la proporción poblacional de unidades no conformes: \\[UCL=n\\bar{p}+3·\\sqrt{n\\bar{p}(1-\\bar{p})} \\quad \\text{y} \\quad LCL=n\\bar{p}-3·\\sqrt{n\\bar{p}(1-\\bar{p} )} \\] Es la versión en número de no conformes del gráfico p (multiplicando los sus límites por n). Se representa el número de unidades defectuosas (por lotes, por día, por cada máquina) como en el gráfico C. Sin embargo, los límites de control en esta tabla no se basan en la distribución de eventos raros, sino en la distribución binomial, al igual que en el gráfico p. Por lo tanto, este gráfico debe utilizarse si la ocurrencia de unidades defectuosas no es poco común (más del \\(5 \\%\\) de las unidades revisadas). Por ejemplo, se podrá usar este gráfico para controlar el número de unidades producidas con defectos de menor importancia. 1.5.4.3 Gráficos de Control c Número de disconformidades por unidad. Siendo c la media y la varianza de una distribución de Poisson (del número de defectos), que se puede aproximar a una normal cuando \\(c &gt; 5\\): \\[UCL=\\bar{c}+3·\\sqrt{(\\bar{c} )} \\quad \\text{y} \\quad LCL=\\bar{c}-3·\\sqrt{(\\bar{c} )} \\] En este gráfico, se muestra el número de unidades defectuosas (por lotes, por día, por equipo, por cada 100 metros de tubería, etc.). Los límites de control en este gráfico se calculan a partir de la distribución de Poisson (distribución de los eventos poco frecuentes). 1.5.4.4 Gráficos de control u Número medio de disconformidades por unidad de control. Si u=x/n , siendo x el número de no conformidades en una muestra y n el número de unidades inspeccionadas: \\[UCL=\\bar{c}+3·\\sqrt{\\frac{\\bar{c}}{n}} \\quad \\text{y} \\quad LCL=\\bar{c}-3·\\sqrt{\\frac{\\bar{c}}{n}} \\] En este gráfico, se representa la tasa de unidades defectuosas, es decir, el número de unidades defectuosas dividido por el número de unidades de inspección (la n puede ser, por ejemplo, metros de tubería, número de lotes, etc.). A diferencia del gráfico C, no se requiere un número constante de unidades, por lo tanto, el gráfico U se puede utilizar cuando las muestras-lotes son de diferentes tamaños. 1.5.4.5 Ejemplo Gráfico p Datos Zumo de naranja (orangejuice): Ejemplo 2.4: Gráficos tipo P 3.3.1 1.5.4.6 Ejemplo Gráfico np Datos Zumo de naranja (orangejuice): Ejemplo 2.5: Gráficos tipo NP 3.3.2 1.5.4.7 Ejemplo Gráfico C Datos Placas impresas (Circuit boards data): Ejemplo 2.6: Gráficos tipo C 3.3.3 1.5.4.8 Ejemplo Gráfico U Datos del fabricante de ordenadores personales (Personal computer manufacturer data): Ejemplo 2.7: Gráficos tipo U 3.3.4 1.5.5 Otros graficos de Control univariante Si estamos interesados en detector pequeñas tendencias o desplazamientos a lo largo de las sucesivas submuestras, podemos construir dos tipos de gráficos más sensibles que los tradicionales. Estos son los gráficos CUSUM y los gráficos EWMA. Sin embargo, ambos gráficos funcionan peor que el gráfico de medias cuando se trata de detectar grandes cambios. El gráfico CUSUM se introdujo por primera vez por Page (1954); los principios matemáticos involucrados en su construcción se discuten en Ewan (1963), Johnson (1961), y Johnson y Leone (1962). En el caso de los gráficos EWMA, se puede consultar Montgomery (2001). Tienen mejor rendimiento cuando se aplican a muestras individuales. 1.5.5.1 Gráfico CUSUM Si se representa la suma acumulada de las desviaciones de las medias de las sucesivas submuestras con respecto a la media del proceso, desplazamientos permanentes, incluso los cambios menores, con respecto a dicha media darán lugar a una considerable suma acumulada de desviaciones. Por lo tanto, este gráfico es muy adecuado para la detección de esos pequeños cambios permanentes que pueden pasar desapercibidos utilizando el gráfico de \\(\\bar{X}\\). Ejemplo: debido al desgaste de la máquina, un proceso poco a poco “se desliza” hacia el fuera de control, produciendo resultados por encima de las especificaciones. El uso de este gráfico podría dejar patente el incremento o decremento continuado de la suma de las desviaciones respecto a las especificaciones. Se contabilizan las desviaciones acumuladas negativas y positivas: \\[ C_i^{-} = \\max{( 0,(C_{i-1}^- - (x_i - \\mu))-K)}, \\quad C_i^{+} = \\max{( 0,(C_{i-1}^+ + (x_i - \\mu))-K)}\\] Donde. \\(C_0^{-}=C_0^{+}=0\\), \\(K\\) es el valor a partir del cual la desviación acumulada es significativa. Si la suma acumulada hasta la observación i-ésima es menor que cierto umbral \\(K=k·\\sigma\\), se considera que la desviación acumulada es cero. El valor de K se suele elegir según la desviación que se quiera detectar. Los valores \\(\\pm H\\) son los límites de control de este gráfico (\\(H = h·\\sigma = 5·\\sigma\\)). El estadistico \\(s_r\\) se usará para determinar si el proceso esta bajo control o no \\[ s_r = \\sum_{i=1}^r(\\bar{x}_i - \\mu_0) \\sim N \\left(r(\\mu-\\mu_0), \\frac{r\\sigma_0^2}{n}\\right) \\] Ejemplo práctico con los datos pistonrings y el paquete qcc: bajo los supuestos de normalidad, donde \\(\\mu_0\\) es el objetivo para el promedio del proceso Ejemplo 2.8: Gráficos CUSUM 3.4.1 1.5.5.2 Gráficos EWMA de medias móviles ponderadas de forma exponencial Los gráficos EWMA son un gráfico de medias móviles ponderadas, donde las muestras más cercanas tienen un mayor peso en el cálculo de la media para un punto dado. Para este tipo de gráficos se toman normalmente datos individuales. Las observaciones individuales pueden ser medias (cuando las observaciones individuales de las que provienen las medias no están disponibles), lecturas individuales, cocientes, proporciones o medidas similares. La idea de construir un gráfico de medias móviles se puede generalizar del siguiente modo. En vez de calcular una media aritmética móvil, se puede calcular una media móvil geométrica, dando lugar al gráfico del mismo nombre (Montgomery, 1985, 1991). \\[ z_t = \\lambda x_t+(1-\\lambda)z_{t-1}\\] donde \\(0&lt;\\lambda \\leq 1\\) y el valor inicial \\((z_0=\\mu_0)\\) es el objetivo del proceso Este método especifica que la ponderación correspondiente a la media de una muestra vieja irá decreciendo geométricamente según continuamos a dibujar muestras. El gráfico EWMA nos permite detectar pequeños sesgos o desplazamientos en, por ejemplo, la media de la característica medida y, por tanto, en la calidad del proceso de producción. La línea central y los limites de control para la tabla de control EWMA son los siguientes \\[LCI = \\mu_0 - 3\\sigma \\sqrt{\\frac{\\lambda(1-(1-\\lambda)^{2i})}{2-\\lambda}}\\] \\[LC = \\mu_0\\] \\[LCS = \\mu_0 + 3\\sigma \\sqrt{\\frac{\\lambda(1-(1-\\lambda)^{2i})}{2-\\lambda}}\\] Si el valor de \\(i\\) es alto, los limites de control son: \\[LCI = \\mu_0 - 3\\sigma \\sqrt{\\frac{\\lambda}{2-\\lambda}}\\] \\[LC = \\mu_0 \\] \\[LCS = \\mu_0 + 3\\sigma \\sqrt{\\frac{\\lambda}{2-\\lambda}}\\] Ejemplo práctico con los datos pistonrings y el paquete qcc: Ejemplo 2.9: Gráficos EWMA 3.4.2 1.5.6 Curvas OC Una curva característica de operación (CO) proporciona información acerca de la probabilidad de no detectar un cambio en el proceso cuando este ocurre de verdad. Esto se conoce generalmente como el error de tipo II, es decir, la probabilidad de aceptar erróneamente un proceso como en control. Realizaremos a continuación las curvas OC para desviaciones de la media. La probabilidad de error de tipo II de no detectar un desplazamiento (medido en \\(nº\\) de desviaciones típicas del proceso) con respecto a la media bajo control, tiene la forma: Las curvas CO se pueden obtener fácilmente a partir de un objeto de la clase qcc. La opción más sencilla es crear un objeto qcc (por variables o por atributos). En el caso de gráficos por variables, utilizamos como ejemplo los datos pistonrings: Ejemplo 2.9: CURVAS OC 3.5 1.6 Etapa ANALIZAR: Analisis de capacidad 1.6.1 Introducción 1.6.1.1 Analisis de capacidad Objetivo Estimar lo bien que un proceso se ajusta a las tolerancias definitivas por la empresa, los clientes, la normativa, etc. Definiciones Cunstificación de la variabilidad del proceso y el análisis de esta variabilidad en comparación con las especificaciones del producto final. Comparación de la distribución de pñrobabilidad de una característiica de calidad con respecto a unas efecificaciones o tolerancias fijadas para la misma. Porcentaje del proceso fuera de especificaciones. Aplicaciones Predecir lo bien que un proceso se ajusta a las especificaciones Ayudar a la modificación de un proceso Especificación de requisitos para la adquisición de nuevos equipos Selección entre varios proveedores. Reducción de la variabilidad en un proceso. Requisitos El proceso ha de estar bajo control Se supone que se conoce la distribución de probabilidad de la característica de calidad del proceso. La suposición más común es que los datos se distribuyen segúb una distribución normal. Si bien existen alternativas robustas no paramétricas También para datos autocorrelacionados Herramientas Histogramas Estimación de la distribución de probabilidad de la característica CTQ Comparación con los limites de tolerancia Graficos Cuantil Cuantil Bondad de ajuste, Fiables con &lt;100 observaciones indices de Capacidad Primera generación: Cp Degunda generación: Cpu, Cpl, Cpk Tercera generación: Cpm, Cpkm Indices no paramétricos/ robustos. Indices para una caracteristica CTQ autocorrelada 1.6.2 Indices de capacidad 1.6.2.1 Generalidades Definición: Indicadores desarrollados para medir si un proceso es capaz o no en relación a las tolerancias/especificaciones fijadas por los clientes/empresa. Grado en el que la variabilidad de un proceso, debida a causas comunes, ocupa el intervalo de tolerancia definido por los clientes. Características: Índices altos indican que un proceso es capaz de producir artículos o servicios que cumplen las especificaciones de los clientes. Dan información acerca del: Número de no conformidades esperadas. Desplazamiento de la distribución de la característica de calidad con respecto al objetivo o \"target“ Cuánto más grande sea el índice calculado, habrá menos productos no conformes. Dependen de los límites de tolerancia o consigna (LSL, límite inferior de tolerancia y ULS, límite superior de tolerancia) y los correspondientes a la distribución de probabilidad paramétrica de los datos (límites naturales de control). 1.6.2.2 Indices paramétricos Primera Generación Medida de la capacidad potencial del proceso \\[ C_p = \\frac{USL-LSL}{6 \\sigma} = \\frac{USL-LSL}{X_{0.99865}-X_{0.00135}}\\] \\[ \\hat{C}_p = \\frac{USL-LSL}{6 \\hat{\\sigma}} \\] Segunda Generación \\(C_{pk}\\) describe el desempeño de la capacidad del proceso, capacidad real Tiene en cuenta distacia del valor medio de la característica CTQ a los limites de especificación. A partit de \\(C_{pu}\\) y \\(C_{pl}\\) \\(C_{pu}= \\frac{USL-\\mu}{3\\sigma}\\) \\(\\hat{C}_{pu}=\\frac{USL-\\hat{\\mu}}{3\\hat{\\sigma}}\\) \\(C_{pl}= \\frac{\\mu-LSL}{3\\sigma}\\) \\(\\hat{C}_{pl}= \\frac{\\hat{\\mu-LSL}}{3\\hat{\\sigma}}\\) \\(C_{pk}= \\min{C_{pu},C_{pl}}\\) \\(\\hat{C}_{pk}= \\min \\{\\hat{C}_{pu},\\hat{C}_{pl} \\}\\) \\(C_p\\) y \\(C_{pk}\\): Se utilizan para comparar la capaacidad potencial del proceso (hasta donde puede llegar en lo que a varabilidad se refiere) y la capacidad real. Tercera Generación \\(C_{pm}\\) es un índice de calidad que en su expresión SÍ tiene en cuenta la distancia de la media del proceso al valor objetivo/nominal/Target (T). \\(C_{pkm}=\\frac{C_{pk}}{\\sqrt{1+(\\frac{\\mu-T}{\\sigma})^2}}\\) nace como una corrección del \\(C_{pk}\\) para dotarlo de sensibilidad a desplazamientos de la media de la distribución \\(\\mu\\) con respecto al “target” T . \\(C_p(u,v)\\) generaliza todos los índices en función del los parámetros u y v. \\(C_{pm}= \\frac{USL-LSL}{6\\sqrt{\\sigma^2 + (\\mu -T)^2}}\\) \\(\\hat{C}_{pm}= \\frac{USL-LSL}{3\\sqrt{\\hat{\\sigma}^2 + (\\hat{\\mu} -T)^2}}\\) \\(C_{pkm}= \\frac{d - |\\mu -m|}{3\\sqrt{\\sigma^2 + (\\mu -T)^2}}\\) \\(\\hat{C}_{pkm}= \\frac{d - |\\mu -m|}{3\\sqrt{\\hat{\\sigma}^2 + (\\hat{\\mu} -T)^2}}\\) \\(C_p(u,v)=\\frac{d - u|\\mu -m|}{3\\sqrt{\\sigma^2 + (\\mu -T)^2}}\\) \\(C_p(0,0)=C_{p}\\) \\(C_p(1,0)=C_{pk}\\) \\(C_p(0,1)=C_{pm}\\) \\(C_p(1,1)=C_{pkm}\\) Siendo \\(d=\\frac{USL-LSL}{2}\\) \\(m=\\frac{USL+LSL}{2}\\) 1.6.3 Analisis de capacidad en R 1.6.3.1 Libreria qcc Ejemplo 1: Simulacion Grosor Yates 4.1.1.1 1.6.3.2 Libreria SixSigma Ejemplo 2: Botellas de Refresco 4.1.1.2 1.6.3.3 Libreria qualityTools Ejemplo 3a: Simulacion distribución normal 4.1.1.3 Ejemplo 3b: Simulacion distribución Weibull 4.1.1.3 Ejemplo 4: Pistorings (datos Agrupados) 4.1.1.3 1.6.4 Análisis de capacidad con datos no normales 1.6.4.1 Transformacón de datos Es importante trabajar sobre la distribución correcta de los datos, sino se puede llegar a obtener un número de no conformidades erroneo Aplicar una Transformación de Box Cox a los datos es una forma de estimar correctamente la capacidad de un proceso cuando este no es normal \\[y_i^{(\\lambda)}= \\left\\{ \\begin{array}{lcc} \\frac{y_i^{(\\lambda)}-1}{\\lambda} &amp; si &amp; \\lambda \\not = 0 \\\\ \\\\ ln(y_i) &amp; si &amp; \\lambda = 0 \\\\ \\end{array} \\right.\\] Los datos transformados sí serán normales, pudiendose aplicar de forma fiable los índices de capacidad anteriormente deefinidos La librería qualutyTools de R permite aplicar transformaciones de Box-Cox, que sea la óptima (respecto a \\(\\lambda\\)) que proporciona por defecto o fijando un \\(\\lambda\\) determinado 1.6.4.2 Indices no paramétricos Si no se verifica la suposición de normalidad de los datos u otra distribución paramétrica conocida, no se deben utilizar los índices anteriormente descritos, pues nos llevarían a conciderar una proporción de no conformidades errónea. Índices que no asumen ninguna distribución conocida para la característica CTQ. Chang y Lu (1994) propusieron el índice \\(C_p(u,v)\\)para distribución arbitraria: \\[C_{Np}(u,v)=\\frac{d-u|M-m|}{3\\sqrt{\\frac{F_{99.865}-F_{0.135}}{6}+v(M-T)^2}}\\] \\[\\hat{C}_{Np}(u,v)=\\frac{d-u|\\hat{M}-m|}{3\\sqrt{\\frac{\\hat{F}_{99.865}-\\hat{F}_{0.135}}{6}+v(\\hat{M}-T)^2}}\\] Los Cuantiles \\(F_{0.99865}\\) y \\(F_{0.00135}\\) se estiman mediante los percentiles de la distribución empírica sacada de la muestra \\(\\hat{F}_{0.99865}\\) y \\(\\hat{F}_{0.00135}\\). M es oa mediana de la distribución, \\(d=\\frac{USL-LSL}{2}\\) y \\(m=\\frac{USL+LSL}{2}\\) Ejemplo 5: Peso de Altavoces 4.1.2.1 Ejemplo 6: Piedra artificial 4.1.3 1.7 Etapa CONTROLAR y ANALIZAR 1.7.1 CEC multivariante: Reducción de la Dimención Cuando varias variables aleatorias caracterizan la calidad de un proceso/servicio, es necesario aplicar técnicas de control estadístico de calidad multivariante. Si analizamos cada una de las variables por separado, la probabilidad de que una observación de la variable aparezca dentro de los límites calculados cuando SE SABE que realmente el proceso esta bajo control, ya NO SERÁ 0.9973 para una un intervalo 6·Sigma, SERÁ \\((0.9973)^{(Nº de variables)}\\) = 0.9946. (suponiendo las 2 variab. del ej. sig.). Mientras que \\(\\alpha_{nuevo} = 1-(1-\\alpha)^{nºde variables}\\) Conclusión, los límites de control son diferentes a los dibujados. Pero esto se cumple en el caso que las variables sean independientes, donde la probabilidad de la intersección es el producto de probabilidades. Si las variables son dependientes, el cálculo del nivel de significación, alfa, se vuelve muy complicado: Hay que estudiar las variables conjuntamente, de forma multivariante Ejemplo 7: Control del contenido de contaminantes en el queroseno. 5.1.1.1 Otra alternativa es estudiar las variables por separado, aplicando la corrección de Bonferroni: \\(\\alpha_{Bonferroni} = \\alpha/(\\text{nº de combinaciones posibles, dos a dos, de variables})\\), o mismo dividiendo alfa entre 2*nº de variables [Ver Alt (1985)]. Inconveniente: demasiado conservador con la hipótesis nula (proceso bajo control). Ejemplo 8: Aproximación univariante utilizando una corrección tipo BONFERRONI. 5.1.1.2 Ejemplo 9:Control de calidad multivariante con gráficos Shewhart. 5.1.1.3 Ejemplo 10:Control de calidad multivariante con gráficos MEWMA y MCUSUM. 5.1.1.4 Ejemplo 11:Cotrol de humedad relativa, temperatura y consumo eléctrico.5.1.1.5 1.7.1.1 PCA Análisis de componentes principales (PCA): Objetivo: Reducir el número de variables que caracterizan un conjunto de individuos. Poder aplicar métodos multivariantes de forma fiable (clasificación, regresión, control de calidad). Características: A partir de una matriz de datos con “p” variables, se obtiene otra matriz de datos con “p” componentes principales (nuevas variables). La primera componente principal de se obtiene al proyectar los vectores de observaciones en la dirección de la máxima varianza de los datos. La segunda componente se obtendrá al proyectar la información restante en la dirección de su máxima varianza y así sucesivamente hasta obtener la nuevas p componentes. Las “p” componentes son ORTOGONALES e INDEPENDIENTES entre sí. Ventajas: Útiles cuando tenemos una gran cantidad de variables. Con cerca de 10 variables los gráficos clásicos no son fiables. El ARL1 se incrementa al incrementar el nº de variables, se tarda más en detectar un verdadero fuera de control. Muchas veces se puede resumir la mayor parte de la información de la base de datos en apenas dos variables. Las proyecciones pueden cumplir las hipótesis de normalidad y no autocorrelación, lo que hace aplicables los gráficos de Shewhart. Inconvenientes: Es difícil descubrir cuál es la variable original que origina el fuera de control y, así, identificar las causas asignables. Cálculo: Descomposición en valores singulares de la matriz de características X (SVD): \\[ X =UDV^T=PT^T\\] U y V son matries ortogonales de vectores singulares, D = matriz diagonal de autovalores, P = loadings (peso de las antiguas variables en las nuevas), T = scores (coordenadas de las observaciones en las nuevas variables). Análisis de componentes principales (PCA): Problema a resolver: Se obtienen datos del consumo energético (medido en kW), 3 variables de temperatura ambiente, 3 variables de concentración de CO2 y 3 variables que miden la humedad relativa (HR) en tres zonas diferentes de una oficina. Miden la calidad de la eficiencia energética, del confort térmico y la calidad del aire de la oficina. DATOS referidos a las 18:00 de la tarde durante 45 días laborables Ejemplo 11: Reducción de dimensión: Análisis de componentes principales 1.7.1.1 1.7.1.2 Mínimos cuadrados parciales (PLS): Objetivo: Reducir el número de variables que caracterizan un conjunto de individuos. Poder aplicar métodos multivariantes de forma fiable. Características: Se expresan los vectores de características según nuevas componentes o variables, pero en la obtención de las mismas se ha tenido en cuenta la existencia de una matriz de variables independientes X y una variable respuesta Y. Los datos se proyectan en una nueva base que tiene en cuenta la relación lineal entre Y y X. Ideal cuando se tienen muchas variables X, o parámetros, de los que depende la característica a controlar Y. Caso práctico: Controlar la eficiencia energética de las instalaciones de climatización de una oficina a partir del consumo eléctrico. En el consumo eléctrico influyen parámetros de confort térmico y calidad del aire (se consume para mantener unos estándares de calidad de estos últimos). Ejemplo 12: Reducción de dimensión: Mínimos cuadrados parciales (PLS) 5.1.1.7 1.7.2 CEC para variables autocorrelacionadas Se ajustarán modelos de series de tiempo “Autoregressive integrated moving average” previo paso a la aplicación de gráficos de control. Se suele expresar como ARIMA(p,d,q) donde los parámetros p, d y q son números enteros no negativos que indican el orden de las distintas componentes del modelo, respectivamente, las componentes autorregresiva, integrada y de media móvil. También se puede incluir una parte para la componente estacional p es la componente autorregresiva: a “grosso modo” de cuántas observaciones pasadas (cada una con su parám, phi_i) depende la actual. q es la componente de medias móviles:de cuántos términos de error correspondientes a observaciones anteriores (cada una con su parám, \\(\\theta_i\\)) depende la actual. d indica d las diferencias que son necesarias para convertir la serie original en estacionaria. Ejemplo 13: Control del confort climático en oficinas 5.1.2.1 1.7.2.1 Series de tiempo y gráficos de los residuos Objetivo: Si no se cumple la hipótesis de observaciones independientes, los gráficos de control tipo Shewhart no son fiables. Se pretende “extraer” la autocorrelación y poder aplicar de forma fiable los gráficos estándar. El procedimiento más usual para resolver este problema es el ajuste de un modelo de series de tiempo, obtención de los residuos y posterior aplicación de los gráficos de control. Procedimiento: Se verifica que no se cumple la hipótesis de independencia de las observaciones. En caso afirmativo, se ajusta un modelo de series de tiempo autorregresivo de medias móviles (ARIMA), por ser el más flexible. Una vez modelizada la autocorrelación, se obtienen y controlan los residuos (independientes) mediante gráficos tipo Shewhart , EWMA, T2, MEWMA… Series de tiempo: Colección de mediciones de un cierto fenómeno registrada de forma secuencial en el tiempo \\(Y(t_1),Y(t_2)\\)… Componentes: tendencia, componente estacional, cíclica y aleatoria. Modelos dinámicos para estimar y predecir los valores de una serie de tiempo: modelos de Box-Jenkins. Modelos Box-Jenkins: Modelos autorregresivos: \\[ X_t = c + \\sum_{i=1}^p \\phi_i X_{t-i}+\\epsilon_t \\] Modelos autorregresivos: \\[ X_t = \\epsilon_t + \\sum_{i=1}^q \\theta _i \\epsilon_{t-i} \\] Modelos autorregresivos integrados de medias móviles: \\[ Y_i=-(\\Delta^d Y_t-Y_t)+\\phi _0 + \\sum_{i=1}^p \\phi_i \\Delta^d Y_{t-i}-\\sum_{i=1}^q \\theta_i \\epsilon_{t-i}+\\epsilon_t\\] Ejemplo 14: Ejemplo practico ARIMA 5.1.2.3 EWMA para datos autocorrelados Objetivo: Se pretende obtener unas bandas de confianza móviles que tengan en cuenta la autocorrelación de los datos. Procedimiento: Montgomery y Mastrangelo (1991) sugirieron una aproximación basada en EWMA: \\[x_t=x_{t-1}+ \\epsilon_t - \\theta \\epsilon _{t-1}\\] Se puede demostrar que las medias ponderadas exponencialmente son un buen predictor de X en procesos AR(1) y con un \\(\\lambda = 1 -\\theta\\) \\[\\hat{x}_{t+1}(t)=Z_t\\] Siendo \\(Z_i\\) \\[Z_t=\\lambda x_t + (1-\\lambda)Z_{t-1}\\] Y \\(e_t\\) los residuos \\[e_t=x_t-\\hat{x} _t(t-1)\\] A partir de la estimacion de la variabilidad de los errores se pueden calcular unas banda de confianza móviles para procesos autocorrelados 1.7.3 Análisis de capacidad para datos autocorrelados Objetivo: Supóngase que la característica de calidad del proceso sigue un proceso estacionario autorregresivo de orden 1, AR(1) con parámetro \\(\\Phi_1\\) tal que |\\(\\Phi_1 &lt; 1\\). Entonces el proceso se puede escribir como: \\[ X_t-\\mu = \\phi_1(X_{t-1}-\\mu)-a_t\\] + Donde \\(a_t \\sim N(0,\\sigma_{\\alpha}^2)\\) y \\(\\mu\\) la media del proceso. Índices propuestos por Wallgren (1996, 2001): \\[C_{pmr} = \\frac{USL - LSL}{ \\sqrt[6]{\\sigma_r^2+(\\mu-T)^2}} \\] \\[C_{pkr}=min \\left( \\frac{USL - \\mu}{3\\sigma_r^2},\\frac{ \\mu-LSL}{3\\sigma_r^2}\\right)\\] Donde \\(\\sigma_r^2=\\alpha _r^2/(1-\\Phi_1)\\) Ejemplo 15: Datos autocorrelacionados 5.1.3 1.8 Introducción al diseño de experimentos con R 1.8.1 Ejemplos de contrastes ANOVA Ejemplo 5.1: Ejemplo de la tracción del horigón armado (con acero) Sujeto a tres tratamientos diferentes 6.1.1.1 Ejemplo 5.2: Ejemplo de los laboratorios que miden el peso de muestras de estaño. Respuesta: peso 6.1.1.2 Ejemplo 5.3: Exprerimento para medir la velocidad de la luz ideado por Morley 6.1.1.3 Ejemplo 5.4: Diseño que incluye el test de Tuckey para la resistencia a la rotura de la lana (con dos tipos diferentes) en un telar 6.1.1.4 1.8.2 Diseño de experimentos factorial \\(2^k\\) Para obtener más información sobre el modelo de caja negra por el cuál la combinación de los distintos niveles de factores trtamiento y nuisance originan cambios en la variable respuesta, se puede crear un diseño factorial de \\(2^k\\) utilizando la funcion facDesign del paquete ´qualityTools´. Como se indica en los libros de texto y en los apuntes de la materia, \\(k\\) denota el número de factores y 2 es el número de niveles por factor. Un diseño con \\(k\\) factores y 2 combinaciones por factor se caracteriza por estar formado por \\(2^k\\) combinaciones de factores diferentes, denominados réplicas o “runs” Ejemplo 5.4: Fiabilidad de una resina epoxy (polímero) con fibras de carbono 6.1.2.1 1.8.3 Diseño de experimentos factoriales fraccionarios Supóngase que se prueban 5 factores diferentes en un diseño de \\(2^k\\), dando lugar a \\(2^5=32\\) réplicas. Es probable que esto sea bastante costoso de ejecutar en cualquier máquina de ensayo, proceso o configuración experimental en un proceso de producción o investigación. Antes de descartar el diseño, es aconsejable reflejar lo que este diseño es capaz de hacer. Es decir, qué tipos de interacciones puede estimar. La interacción más alta en un diseño \\(2^5\\) es la interacción entre los cinco factores ABCDE. Esta interacción, aunque sea significativa, es realmente difícil de interpretar, y es probable que no exista. Lo mismo se aplica a las interacciones entre cuatro factores y algunas de las interacciones entre 3 factores, por lo que, en lugar de sus correspondientes diseños completos, la mayoría de las veces se consideran diseños factoriales fraccionados ya desde las primeras etapas de la experimentación. Para diseños factoriales fraccionados, se puede utilizar el método fracDesign del paquete. Para un diseño de \\(2^3\\) (es decir, 3 factores que deben analizarse en un \\(2^2\\) réplicas al confundir el tercer factor con la interacción entre los dos primeros factores) esto estaría dado por el argumento gen=“C=AB”, que significa que la interacción entre A y B debe confundirse con el efecto de un tercer factor C. El efecto estimado para C se confunde con la interacción AB; es decir, no pueden estimarse por separado, por lo tanto, C = AB (alias) o el alias de C es AB. Caso de estudio Se ajusta el modelo paramétrico de Paris, dependiente de los parámetros C y m (su valor depende del tipo de material) para estimar la longitud de grietas en un material en función del número de ciclos de esfuerzos a fatiga. Se trata de ver si el efecto de unos parámetros de un modelo de fiabilidad (prueba de fatiga tipo Paris) son significativos sobre la respuesta, error de ajuste del modelo, a la par que se analiza el posible efecto de la interacción. Lo que se quiere dilucidar es si el modelo de Paris ajusta mejor o peor dependiendo del material (C y m) y su heterogeneidad \\((\\sigma_C, \\sigma_m, \\sigma_{Cm})\\). Ejemplo 5.5: EJEMPLO de DISEÑO FRACCIONADO 1/4 6.1.3.1 1.8.4 Estudios Interlaboratorios Un estudio interlaboratorio se puede definir como un procedimiento de control para evaluar el rendimiento de un grupo de laboratorios a traves de un ensayo en colaboración [1,2]. En un estudiio interlaboratorio, un número adecuado de los laboratorios son elegidos para participar en el experimento con el objetivo de anaizar las muestras y obtener resultados. los laboratorios participantes reciben muestras (previamente homogeneizadas o ser homogeneizadas por los laboratorios) para el análisis, acontinuacion, ñas mediciones de resultados de los laboratorios se evalúan de acuerdo con el grado de variabilidad de los datos. Alguno de los factores más comunes que pueden ser una causa de la variabilidad son el equipamiento de laboratorios los operadores los materiales la temperatura la humedad Varias técnicas estadisticas escalares se aplican con frecuencia para estudiar la consistencia de los resultados de prueba de los diferentes laboratorios que participan en un ILS. Norma ASTM E-691 (Práctica estándar para la realización de un estudio entre laboratorios para determinar la precisión de una prueba modelo) recomienda aplicar sólo una gráfica de Mendel k y h estadisticas, mientras que ISO 5735-2 (Presición-veracidad y precisión de los métodos de medición y resultados) recomienda además de la técnica gráfica, para utilizar el test de Cochran y Grubbs Además, a través de análisis de varianza (ANOVA), el efecto del factor de laboratorio sobre la respuesta puede ser estudiado. La varianza de la repetibilidad y reproducibilidad puede ser también estima cuando se considera un modelo de efectos aleatorios ANOVA, como se muestra en la norma ISO 5725-2. Por otra parte, si un modelo de efectos fijo es ajustado, además de la prueba F, comparaciones múltiples de medios se pueden realizar con el método Tukey Honest Significant Difference (HSD). Para llevar a cabo pruebas de coherencia para las hipótesis de repetibilidad y reproducibilidad, así como para la detección de valores atípicos, los valores de los estadísticos deben ser comparados con sus correspondientes valores críticos. Si éstos son mayores, la incoherencia se detecta en los resultados de los laboratorios. ISO 5725-2 proporciona algunos valores críticos en función del número de laboratorios p, número de mediciones n y el nivel de significacia \\(\\alpha\\). En la actualidad, tanto ISO 5725 y ASTM-E691 no proporcionan una metodología para la realización de un ILS cuando los datos son funcionales, esto es, en el caso en que los resultados de la prueba son curvas (datos funcionales). Análisis de datos funcional (FDA) es relativamente una nueva rama de la estadística que toma las curvas como unidad de análisis, también las superficies y volúmenes definidos de forma continua (como el tiempo, o el dominio de frecuencia). Teniendo en cuenta los últimos avances en la ciencia de la computación y la creciente cantidad de datos generados por las técnicas experimentales y sensores, la FDA ha tenido un gran desarrollo en los últimos años. De hecho, tenemos muchas metodologías estadísticas que se han desarrollado y extendido al caso funcional, tales como análisis exploratorio, regresión, clasificación, análisis de varianza, y las series de tiempo. En el caso específico ILS, las extensiones del Analisis de Datos Funcionales (FDA) para Mandels h y k se han propuesto y descrito por Miguel Flores. El proposito del paquete ILS es, por un lado, para facilitar el uso de nuevas herramientas en el contexto del (FDA) y, por otro lado, para proporcionar un conjunto completo de tests de valores atípicos univariados más utilizados para el ILS con respuesta escalar. Es importante tener en cuenta que las técnicas del FDA para los estudios entre laboratorios que se basan en las propuestas de Naya, Flores, y sobre todo, la propuestas de Flores. Con lo que las nuevas extensiones funcionales de h y k Se introducen las estadísticas para identificar los laboratorios no consistentes. Las funciones que se han implementado en el paquete ILS pueden determinar los estadísticos de Mandel h y k, tanto en forma gráfica y analítica, utilizando un enfoque funcional. Estas pruebas estadísticas también se han implementado para facilitar la ejecución de los estudios de repetibilidad y reproducibilidad (R&amp;R) cuando los datos son funcionales. además, el paquete ILS se aplicar a los métodos sugeridos por las normas ASTM E-691 e ISO 5725-2 para el caso escalar. El paquete ILS está disponible en la red global de R Archivo en http://CRAN.Rproject.org/package=ILS . La presente librería ILS implementa y pide algunas de sus rutinas con el fin de realizar la detección de valores atípicos en el marco de los estudios entre laboratorios. Por lo tanto, con respecto a ILS con la respuesta escalar, hay algunas herramientas computacionales interesantes y útiles en R software. A saber, la metRology del paquete estima la incertidumbre de la medición, y lleva a cabo los cálculos estadísticos necesarios para estudios entre laboratorios, mientras multcomp realiza un análisis de la varianza (ANOVA) a través de pruebas F y Tuckey. Por otro lado, debido a la exponencial creciente del FDA, también hay un número en continuo aumento de las librerias de R dedicadas a la investigación de esta rama de la estadística. Entre todos ellos, los paquetes más importantes y utilizados (en que se basa la presente propuesta) son fda.usc, Que implementa las técnicas de detección de valores atípicos y ANOVA funcional, entre otras herramientas para FDA. El presente paquete ILS utiliza las aplicaciones de la antes mencionada multcomp y fda.usc. Ejemplo 5.5: ESTUDIOS INTERLABORATORIO (CASO PARTICULAR DE DOE Y ESTUDIOS R&amp;R) 6.1.4 "],
["practica-1.html", "Capítulo 2 Práctica 1 2.1 CEC y Seis Signa: alternativas en R 2.2 Etapa DEFINIR: Mapas de procesos, Ishikawa, Pareto 2.3 Etapa ANALIZAR: ANOVA 2.4 Etapa MEDIR: Estudios R&amp;R", " Capítulo 2 Práctica 1 2.1 CEC y Seis Signa: alternativas en R 2.2 Etapa DEFINIR: Mapas de procesos, Ishikawa, Pareto 2.2.1 Mapas de procesos library(SixSigma) library(qcc) library(qualityTools) library(knitr) Ejemplo de la PIZZA El gerente de un restaurante quiere estudiar el proceso de preparar y servir una pizza, por lo que se plantea hacer un mapa de procesos. Después de recoger algunos datos de su personal, determina que las entradas son los ingredientes (ingredients), el cocinero (cook), el horno (oven), y los platos (plates); las salidas o características del proceso son la temperatura (temperature), el sabor (taste), la ternura (tenderness), el peso (weight), el radio (radius) y el tiempo total para servir la pizza (time). Estas salidas son las características principales (CTQ) de la pizza. El proceso de hacer y servir una pizza se divide en las siguientes etapas: Preparar la masa. Añadir los ingredientes. Hornear la pizza. Entregar la pizza al cliente. Suponemos que las “entradas de cada etapa” son las salidas del paso anterior. Las entradas para la fase primera f son las X definidas previamente (ingredientes, cocina, horno y platos). A continuación, se describen en detalle los parámetros y los resultados correspondientes a cada paso (con la clasificación de los parámetros entre paréntesis). Primera etapa. Masa: Parámetros: cocinero (C), la marca de la harina (C), la proporción de agua (P). Salidas: masa (densidad, dureza y grosor). Segunda etapa. Adición de ingredientes: Parámetros: cocinero (C), la marca de los ingredientes (Cr), la cantidad de ingredientes (P), tiempo de preparación (Cr). Salidas: pizza cruda (diámetro, peso, espesor). Tercer paso. Cocción u horneado: Parámetros: cocinero (C), colas (N), el tiempo de cocción (Cr). Salidas: pizza al horno (temperatura, ternura, sabor). Cuarto paso. Entrega: Parámetros: camarero (C), colas (N). Salidas: pizza en la mesa (temperatura, sabor, ternura, peso, radio, tiempo). Una vez definidas las etapas con sus x e y, creamos los siguientes objetos en R para guardar, respectivamente, las entradas, salidas y etapas del proceso: inputs &lt;-c (&quot;Ingredients&quot;, &quot;Cook&quot;, &quot;Oven&quot;, &quot;Plates&quot;) outputs &lt;- c(&quot;temperature&quot;, &quot;taste&quot;, &quot;tenderness&quot;, &quot;weight&quot;, &quot;radius&quot;, &quot;time&quot;) steps &lt;- c(&quot;DOUGH&quot;, &quot;TOPPINGS&quot;, &quot;BAKE&quot;, &quot;DELIVER&quot;) Seguidamente se salvan las salidas de cada etapa en el formato de listas. Las salidas de una etapa se convierten en las entradas de la siguiente: io &lt;- list() Definimos cuatro elementos de la lista donde se meten los elementos de entrada/salida (aquí no son las características, indican el proceso de la pizza): io[[1]] &lt;- list(&quot;X&#39;s&quot;) io[[2]] &lt;- list(&quot;dough&quot;, &quot;ingredients&quot;, &quot;cook&quot;) io[[3]] &lt;- list(&quot;raw pizza&quot;, &quot;cook&quot;, &quot;oven plate&quot;) io[[4]] &lt;- list(&quot;baked pizza&quot;, &quot;plate&quot;) Finally, we save the names, parameter types, and features: param &lt;- list() param[[1]] &lt;- list(c(&quot;cook&quot;, &quot;C&quot;), c(&quot;flour brand&quot;, &quot;C&quot;), c(&quot;prop Water&quot;, &quot;P&quot;)) param[[2]] &lt;- list(c(&quot;cook&quot;, &quot;C&quot;), c(&quot;Ing.Brand&quot;, &quot;Cr&quot;), c(&quot;amount&quot;, &quot;P&quot;), c(&quot;prep.Time&quot;, &quot;Cr&quot;)) param[[3]] &lt;- list(c(&quot;cook&quot;,&quot;C&quot;), c(&quot;queue&quot;, &quot;N&quot;), c(&quot;BakeTime&quot;, &quot;Cr&quot;)) param[[4]] &lt;- list(c(&quot;waiter&quot;,&quot;C&quot;), c(&quot;queue&quot;, &quot;N&quot;)) feat &lt;- list() feat[[1]] &lt;- list(&quot;density&quot;, &quot;toughness&quot;, &quot;thickness&quot;) feat[[2]] &lt;- list(&quot;diameter&quot;, &quot;Weight&quot;, &quot;thickness&quot;) feat[[3]] &lt;- list(&quot;temperature&quot;, &quot;tenderness&quot;, &quot;taste&quot;) feat[[4]] &lt;- list(&quot;temperature&quot;, &quot;taste&quot;, &quot;tenderness&quot;, &quot;weight&quot;, &quot;radius&quot;, &quot;time&quot;) #ss.pMap steps: A vector of characters with the name of the ‘n’ steps* inputs.overall: vector of characters with the name of the overall inputs outputs.overall: A vector of characters with the name of the overall outputs input.output: A vector of lists with the names of the inputs of the \\(i-ésimo\\) step, that will be the outputs of the \\((i-1)-ésimo\\) step x.parameters: A vector of lists with a list of the x parameters of the process. The parameter is a vector with two values: the name and the type (view details) y.features: A vector of lists with a list of the y features of the step. The feature is a vector with two values: the name and the type (view details) main: The main title for the Process Map sub: Subtitle for the diagram (recommended the Six Sigma project name) ss.col: A vector of colours for a custom drawing. At least five colours, sorted by descendant intensity (see details) setEPS(10) windows(12,8) ss.pMap(steps, inputs, outputs, io, param, feat, sub = &quot;Pizza Process Project&quot;) 2.2.2 DIAGRAMA DE ISHIKAWA En la construcción de un edificio, una característica CTQ podría ser el cumplimiento de un plazo, de hecho el incumplimiento del mismo puede llevar al fracaso. Utilizando las técnicas como las descritas anteriormente, un equipo de Six Sigma identifica los siguientes eventos que pueden causar un retraso en el calendario: el tiempo, los errores en la planificación, la demora de los proveedores, operadores inadecuados, las especificaciones del cliente/retrasos, defectos en los materiales y permisos. Un diagrama de causa y efecto nos permitirá organizar la información de tal manera como que la información obtenida sea más fácil de interpretar. Con SixSigma windows() b.effect &lt;- &quot;Retraso&quot; b.groups &lt;- c(&quot;Trabajadores&quot;, &quot;Instrumental&quot;, &quot;Suministradores&quot;, &quot;Planificación y Metodología&quot;) b.causes &lt;- vector(mode = &quot;list&quot;, length = length(b.groups)) b.causes[1] &lt;- list(c(&quot;Entrenamiento&quot;, &quot;Inadecuados&quot;)) b.causes[2] &lt;- list(c(&quot;Tipo de instrumentos&quot;, &quot;Mantenimiento&quot;, &quot;Calibración&quot;,&quot;Fallos en la instalación&quot;)) b.causes[3] &lt;- list(c(&quot;Materiales&quot;, &quot;Retrasos entrega&quot;)) b.causes[4] &lt;- list(c(&quot;Requerimientos clientes&quot;, &quot;Tipo de ensayos&quot;, &quot;No dispon. instrument.&quot;, &quot;Errores de procedim.&quot;,&quot;Replanificación&quot;)) ss.ceDiag(b.effect, b.groups, b.causes, sub = &quot;Ejemplo Laboratorio&quot;,main=&quot;Diagrama de ISHIKAWA&quot;) Con qcc windows() cause.and.effect( cause=list(Trabajadores=c(&quot;Entrenamiento&quot;, &quot;Inadecuados&quot;), Instrumental=c(&quot;Tipo de instrumentos&quot;, &quot;Mantenimiento&quot;, &quot;Calibración&quot;,&quot;fallos en la instalación&quot;), Suministradores=c(&quot;Materiales&quot;, &quot;Retrasos entrega&quot;), Planificacion=c(&quot;Requerimientos clientes&quot;, &quot;Tipo de ensayos&quot;, &quot;No disponibilidad de instrumentos&quot;, &quot;Errores de procedimiento&quot;,&quot;Replanificación&quot;)), effect=c(&quot;Retrasos&quot;), title = &quot;Diagrama Causa-Efecto&quot;, cex = c(1.5, 1.2, 1), font = c(1, 3, 2)) # Se puede modificar el tamaño y la fuente 2.2.3 DIAGRAMA DE PARETO Datos b.data &lt;- data.frame(cause=factor(unlist(b.causes)), count = c(2,1,8,1,2,2,2,3,15,12,18,1,2) , cost = c(50,150,50,50,20,300,50,10,5,10,50,50,150)) Sin emplear ninguna función específica windows(12,8) pChart &lt;- barplot(rev(sort(b.data$count)), names.arg = b.data$cause[order(b.data$count, decreasing = TRUE)]) text(pChart,rep(0.5,13), sort(round(cumsum(100 * (b.data$count/sum(b.data$count))[ order(b.data$count, decreasing = TRUE)]), 1))) Con el paquete qcc windows(12,8) library(qcc) b.vector &lt;- b.data$count names(b.vector) &lt;- b.data$cause pareto.chart(b.vector, cumperc = c(80),ylab=&quot;Nº de retrasos&quot;) ## ## Pareto chart analysis for b.vector ## Frequency Cum.Freq. Percentage Cum.Percent. ## No dispon. instrument. 18.000000 18.000000 26.086957 26.086957 ## Requerimientos clientes 15.000000 33.000000 21.739130 47.826087 ## Tipo de ensayos 12.000000 45.000000 17.391304 65.217391 ## Tipo de instrumentos 8.000000 53.000000 11.594203 76.811594 ## Retrasos entrega 3.000000 56.000000 4.347826 81.159420 ## Entrenamiento 2.000000 58.000000 2.898551 84.057971 ## Calibración 2.000000 60.000000 2.898551 86.956522 ## Fallos en la instalación 2.000000 62.000000 2.898551 89.855072 ## Materiales 2.000000 64.000000 2.898551 92.753623 ## Replanificación 2.000000 66.000000 2.898551 95.652174 ## Inadecuados 1.000000 67.000000 1.449275 97.101449 ## Mantenimiento 1.000000 68.000000 1.449275 98.550725 ## Errores de procedim. 1.000000 69.000000 1.449275 100.000000 Teniendo en cuenta el coste: windows(12,8) library(qcc) b.vector &lt;- b.data$cost*b.data$count names(b.vector) &lt;- b.data$cause pareto.chart(b.vector, cumperc = c(80),ylab=&quot;Coste&quot;) ## ## Pareto chart analysis for b.vector ## Frequency Cum.Freq. Percentage ## No dispon. instrument. 900.000000 900.000000 30.874786 ## Fallos en la instalación 600.000000 1500.000000 20.583190 ## Tipo de instrumentos 400.000000 1900.000000 13.722127 ## Replanificación 300.000000 2200.000000 10.291595 ## Inadecuados 150.000000 2350.000000 5.145798 ## Tipo de ensayos 120.000000 2470.000000 4.116638 ## Entrenamiento 100.000000 2570.000000 3.430532 ## Materiales 100.000000 2670.000000 3.430532 ## Requerimientos clientes 75.000000 2745.000000 2.572899 ## Mantenimiento 50.000000 2795.000000 1.715266 ## Errores de procedim. 50.000000 2845.000000 1.715266 ## Calibración 40.000000 2885.000000 1.372213 ## Retrasos entrega 30.000000 2915.000000 1.029160 ## ## Pareto chart analysis for b.vector ## Cum.Percent. ## No dispon. instrument. 30.874786 ## Fallos en la instalación 51.457976 ## Tipo de instrumentos 65.180103 ## Replanificación 75.471698 ## Inadecuados 80.617496 ## Tipo de ensayos 84.734134 ## Entrenamiento 88.164666 ## Materiales 91.595197 ## Requerimientos clientes 94.168096 ## Mantenimiento 95.883362 ## Errores de procedim. 97.598628 ## Calibración 98.970840 ## Retrasos entrega 100.000000 El paquete qualityTools incluye la funcion paretoChart windows() paretoChart(b.vector, las = 2, percentVec = c(0, 0.5, 0.80, 1)# se sitúan las marcas ene el eje x ) ## ## Frequency 900 600 400 300 150 120 100 100 75 ## Cum. Frequency 900 1500 1900 2200 2350 2470 2570 2670 2745 ## Percentage 30.9% 20.6% 13.7% 10.3% 5.1% 4.1% 3.4% 3.4% 2.6% ## Cum. Percentage 30.9% 51.5% 65.2% 75.5% 80.6% 84.7% 88.2% 91.6% 94.2% ## ## Frequency 50 50 40 30 ## Cum. Frequency 2795 2845 2885 2915 ## Percentage 1.7% 1.7% 1.4% 1.0% ## Cum. Percentage 95.9% 97.6% 99.0% 100.0% ## ## Frequency 900.00000 600.00000 400.00000 300.0000 150.000000 ## Cum. Frequency 900.00000 1500.00000 1900.00000 2200.0000 2350.000000 ## Percentage 30.87479 20.58319 13.72213 10.2916 5.145798 ## Cum. Percentage 30.87479 51.45798 65.18010 75.4717 80.617496 ## ## Frequency 120.000000 100.000000 100.000000 75.000000 ## Cum. Frequency 2470.000000 2570.000000 2670.000000 2745.000000 ## Percentage 4.116638 3.430532 3.430532 2.572899 ## Cum. Percentage 84.734134 88.164666 91.595197 94.168096 ## ## Frequency 50.000000 50.000000 40.000000 30.00000 ## Cum. Frequency 2795.000000 2845.000000 2885.000000 2915.00000 ## Percentage 1.715266 1.715266 1.372213 1.02916 ## Cum. Percentage 95.883362 97.598628 98.970840 100.00000 2.3 Etapa ANALIZAR: ANOVA La directora gerente de una empresa industrial quiere determinar si tres programas de formación ejercen efectos distintos en la productividad de los empleados de dicha empresa. Para ello selecciona aleatoriamente muestras de empleados que han seguido cada uno de los tres programas y los somete a un examen para evaluar su competencia, anotando las puntuaciones (de 0 – 100) obtenidas por cada uno de ellos en la tabla siguiente: Programa 1 85 72 83 80 76 78 Programa 2 80 84 81 78 82 86 90 88 85 Programa 3 82 80 85 90 88 94 92 89 87 91 Contrastar La hipótesis de que el tipo de progarma de formación no tiene infuencia en la puntuación que sacan los trabajadores en el examen de competencia (a un nivel de significación de \\(\\alpha = 5\\%\\) ) Y: puntuación que sacan los trabajadores X: factor “programa de formación” a tres niveles (programa 1, 2 y 3) \\(H_0\\): \\(\\mu_1=\\mu_2=\\mu_3=\\mu\\) Si se cumple \\(H_0\\), \\(F= \\frac{sc_{entre}/(k-1)}{sc_{dentro}/(n-k)}~ F_{k-1,n-k}\\) Contruir la base de Datos library(&quot;RcmdrMisc&quot;) library(&quot;multcomp&quot;) library(&quot;SixSigma&quot;) library(&quot;qcc&quot;) library(&quot;qualityTools&quot;) library(&quot;Rsolnp&quot;) Puntuacion&lt;-c(85,72,83,80,76,78,80,84,81,78,82,86,90,88,85,82,80,85, 90,88,94,92,89,87,91) Programas&lt;-c(rep(&quot;PROGRAMA1&quot;,6),rep(&quot;PROGRAMA2&quot;,9), rep(&quot;PROGRAMA3&quot;,10)) Programa &lt;- data.frame(Puntuacion = Puntuacion, Programas = Programas) Anova Variable Explicada (Puntuación) con (Programas) AnovaModel.1&lt;- aov(Puntuacion ~ Programas, data = Programa) summary(AnovaModel.1) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Programas 2 293.4 146.7 7.888 0.00261 ** ## Residuals 22 409.2 18.6 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Como el \\(p-valor&lt; \\alpha\\), es decir, \\(0.0026&lt;0.05\\), Rechazo \\(H_0\\), la puntuación depende del tipo de programa de formación ¿Cuáles son los programa que realmente generan esas diferencias? Hay que aplicar un contraste de hipótesis para comparaciones dos a dos: (Contraste de Tukey) numSummary(Programa$Puntuacion,groups=Programa$Programas,statistics=c(&quot;mean&quot;,&quot;sd&quot;)) ## mean sd data:n ## PROGRAMA1 79.00000 4.732864 6 ## PROGRAMA2 83.77778 3.898005 9 ## PROGRAMA3 87.80000 4.417138 10 Pairs &lt;- glht(AnovaModel.1, linfct=mcp(Programas=&quot;Tukey&quot;)) summary(Pairs) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = Puntuacion ~ Programas, data = Programa) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## PROGRAMA2 - PROGRAMA1 == 0 4.778 2.273 2.102 0.11206 ## PROGRAMA3 - PROGRAMA1 == 0 8.800 2.227 3.952 0.00198 ** ## PROGRAMA3 - PROGRAMA2 == 0 4.022 1.981 2.030 0.12810 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) Programa3-Programa1 es significativamente distinto de cero \\(p-valor=0.00193&lt;0.05\\) Se ha extraído una muestra aleatoria de los salarios por hora (en euros) de los trabajadores del sector de hostelería de una CCAA española. Se cree que dos factores pueden tener influencia en la heterogeneidad de dichos salarios: A, situación y B, procedencia: Se pide, a un \\(\\alpha = 0.05\\): a) Comprobar si el salario es el mismo para los diferentes niveles de situación personal. b) Comprobar si el salario es el mismo para los diferentes lugares de procedencia. c) Comprobar si existe interacción. Se crea el data-frame library(&quot;RcmdrMisc&quot;) library(&quot;multcomp&quot;) library(&quot;Rsolnp&quot;) Salario&lt;-c(1,2,3,2,3,2,3,3,4,6,6,7,7,7,8,8,10,9) Procedencia&lt;-c(rep(&quot;B1&quot;,3),rep(&quot;B2&quot;,3),rep(&quot;B3&quot;,3), rep(&quot;B1&quot;,3),rep(&quot;B2&quot;,3),rep(&quot;B3&quot;,3)) SituacionLabor&lt;-c(rep(&quot;A1&quot;,9),rep(&quot;A2&quot;,9)) Hosteleria &lt;- data.frame(Salario = Salario, Procedencia = Procedencia, SituacionLabor=SituacionLabor) Para realizar el Análisis de la Varianza con dos factores y su interacción: AnovaModel.3 &lt;- (lm(Salario~ Procedencia*SituacionLabor,data = Hosteleria)) Anova(AnovaModel.3) ## Anova Table (Type II tests) ## ## Response: Salario ## Sum Sq Df F value Pr(&gt;F) ## Procedencia 12.444 2 11.2 0.001802 ** ## SituacionLabor 112.500 1 202.5 7.088e-09 *** ## Procedencia:SituacionLabor 1.333 2 1.2 0.334898 ## Residuals 6.667 12 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 tapply(Hosteleria$Salario, list(Procedencia=Hosteleria$Procedencia,SituacionLabor=Hosteleria$SituacionLabor), mean, na.rm=TRUE) ## SituacionLabor ## Procedencia A1 A2 ## B1 2.000000 6.333333 ## B2 2.333333 7.333333 ## B3 3.333333 9.000000 Las desviaciones típicas del salario dentro de cada combinación de niveles: tapply(Hosteleria$Salario, list(Procedencia=Hosteleria$Procedencia,SituacionLabor=Hosteleria$SituacionLabor), sd, na.rm=TRUE) ## SituacionLabor ## Procedencia A1 A2 ## B1 1.0000000 0.5773503 ## B2 0.5773503 0.5773503 ## B3 0.5773503 1.0000000 El número de observaciones en cada celda: tapply(Hosteleria$Salario,list(Procedencia=Hosteleria$Procedencia,SituacionLabor=Hosteleria$SituacionLabor), function(x) sum(!is.na(x))) ## SituacionLabor ## Procedencia A1 A2 ## B1 3 3 ## B2 3 3 ## B3 3 3 2.4 Etapa MEDIR: Estudios R&amp;R Un fabricante de juntas tóricas para piezas metálicas instala un nuevo sistema de medición digital. El cinturón negro encargado de la mejora de un proyecto de aumento de beneficios quiere determinar con cuánta efectividad se ha aplicado el sistema de medida y si los operarios se han adaptado a él. Para ello se lleva a cabo un estudio R &amp; R donde 3 operarios diferentes miden 10 piezas distintas 2 veces cada una. Operario &lt;- factor(rep(1:3, each = 20)) Pieza &lt;- factor(rep(rep(1:10, each = 2), 3)) run &lt;- factor(rep(1:2, 30)) Diametro &lt;- c(0.65, 0.6, 1,1, 0.85, 0.8, 0.85, 0.95, 0.55, 0.45, 1, 1, 0.95,0.95, 0.8, 0.85, 1, 1, 0.6,0.7, 0.55, 0.55,1.05,0.95, 0.8,0.75, 0.8,0.75, 0.4,0.4, 1,1.05, 0.95,0.9, 0.75,0.7, 1,0.95, 0.55,0.5, 0.5,0.5, 1.05,1, 0.8,0.8, 0.8, 0.8, 0.45,0.5, 1,1.05, 0.95,0.95, 0.8,0.8, 1.05,1.05,0.8, 0.85) Tubos &lt;- data.frame(Operario, Pieza, run, Diametro) Paquete qualityTols create a gage RnR design design = gageRRDesign(Operators=3, Parts=10, Measurements=2,method=&quot;nested&quot;, randomize=FALSE) set the response response(design) = c(0.65, 0.6, 1,1, 0.85, 0.8, 0.85, 0.95, 0.55, 0.45, 1, 1, 0.95,0.95, 0.8, 0.85, 1, 1, 0.6,0.7, 0.55, 0.55,1.05,0.95, 0.8,0.75, 0.8,0.75, 0.4,0.4, 1,1.05, 0.95,0.9, 0.75,0.7, 1,0.95, 0.55,0.5, 0.5,0.5, 1.05,1, 0.8,0.8, 0.8, 0.8, 0.45,0.5, 1,1.05, 0.95,0.95, 0.8,0.8, 1.05,1.05,0.8, 0.85 ) perform Gage RnR gdo = gageRR(design,sigma=6) ## ## AnOVa Table - crossed Design ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Operator 2 0.0461 0.02304 18.433 6.01e-06 *** ## Part 9 2.0832 0.23146 185.170 &lt; 2e-16 *** ## Operator:Part 18 0.1106 0.00614 4.915 6.41e-05 *** ## Residuals 30 0.0375 0.00125 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## ---------- ## ## Gage R&amp;R ## VarComp VarCompContrib Stdev StudyVar StudyVarContrib ## totalRR 0.004542 0.1079 0.0674 0.404 0.328 ## repeatability 0.001250 0.0297 0.0354 0.212 0.172 ## reproducibility 0.003292 0.0782 0.0574 0.344 0.280 ## Operator 0.000845 0.0201 0.0291 0.174 0.142 ## Operator:Part 0.002447 0.0581 0.0495 0.297 0.241 ## Part to Part 0.037553 0.8921 0.1938 1.163 0.945 ## totalVar 0.042095 1.0000 0.2052 1.231 1.000 ## ## --- ## * Contrib equals Contribution in % ## **Number of Distinct Categories (truncated signal-to-noise-ratio) = 4 La tabla R&amp;R consta de las siguientes columnas: VarComp (varianza), * VarCompContrib (tanto por uno con respecto a la varianza total de las medidas), * Stdev (desviación estándar), StudyVar (6·Stdev), * StudyVarContrib (6·Stdev/Stdev total ·100). Como la contribución de la sigma a la varianza total es StudyVarContrib(totalRR) = 0.328 &gt; 0.3, el método de medida no es adecuado, debería buscarse cómo mejorar el proceso de medida. El número de categorías distintas debe ser mayor que o igual a cuatro. Este valor mide la relación entre la variabilidad debida al sistema de medición y la variabilidad inherente. En el caso presente es igual a 4, en el límite de la idoneidad del sistema. visualization of Gage RnR windows(15,10) plot(gdo) Y con el Paquete SixSigma (sigma=6 por defecto): windows(15,10) my.rr &lt;- ss.rr(var = Diametro, part = Pieza, appr = Operario, data = Tubos, main = &quot;Six Sigma Gage R&amp;R Measure&quot;, sub = &quot;Estudio R &amp; R para Juntas Tóricas&quot;) ## Complete model (with interaction): ## ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Pieza 9 2.0832 0.23146 37.676 7.24e-10 ## Operario 2 0.0461 0.02304 3.751 0.0435 ## Pieza:Operario 18 0.1106 0.00614 4.915 6.41e-05 ## Repeatability 30 0.0375 0.00125 ## Total 59 2.2773 ## ## alpha for removing interaction: 0.05 ## ## Gage R&amp;R ## ## VarComp %Contrib ## Total Gage R&amp;R 0.0045416667 10.79 ## Repeatability 0.0012500000 2.97 ## Reproducibility 0.0032916667 7.82 ## Operario 0.0008449074 2.01 ## Pieza:Operario 0.0024467593 5.81 ## Part-To-Part 0.0375532407 89.21 ## Total Variation 0.0420949074 100.00 ## ## StdDev StudyVar %StudyVar ## Total Gage R&amp;R 0.06739189 0.4043513 32.85 ## Repeatability 0.03535534 0.2121320 17.23 ## Reproducibility 0.05737305 0.3442383 27.96 ## Operario 0.02906729 0.1744037 14.17 ## Pieza:Operario 0.04946473 0.2967884 24.11 ## Part-To-Part 0.19378659 1.1627195 94.45 ## Total Variation 0.20517044 1.2310226 100.00 ## ## Number of Distinct Categories = 4 "],
["practica-2.html", "Capítulo 3 Práctica 2 3.1 Gráficos de Control 3.2 Gráficos de Control por variables 3.3 Gráficos de control por atributos 3.4 Otros gráficos de Control: CUSUM y EWMA 3.5 CURVAS OC", " Capítulo 3 Práctica 2 3.1 Gráficos de Control En esta práctica se obtendrán gráficos de control para variables y atributos utilizando dos paquetes: “qcc” y “qcr”. Para trabajar con casi todas las funciones y aplicaciones que existen dentro de este paquete estadástico, debemos crear un objeto qcc. Necesitamos básicamente dos cosas: Unos datos (un data frame, una matriz, un vector,..) y un “string value” especificando el tipo de control que deseamos hacer (por Atributos o por variables). También, opcionalmente, se pueden modificar el tamaño (sizes), el centro del grupo (center), la desviación estándar (std.dev), los limites de control (limits), el valor objetivo del proceso(target). La única diferencia que existe a la hora de trabajar con variables o con atributos, radica en “type”. Para variables podemos optar por elegir entre “xbar”,“xbar.one”, “R” o “S” y para atributos tenemos “p”, “np”,“c”,“u” o “g”. 3.2 Gráficos de Control por variables 3.2.1 Gráficos qcc para variables Vamos a trabajar con dos bases de datos: 1. “pistonrings”, definida en el paquete qcc. 2. “plates”, definida en el paquete qcr. Medidas de dureza de planchas de piedra artificial. Estos datos están sacados del libro de MONTGOMERY .Son medidas del diámetro interior de anillos forjados para los pistones que se usan en los motores de los coches. Las variables que aparecen en el estudio son: diameter, es el diámetro de los pistones sample = 1,2,3,…40 representa el número de la muestra y de cada muestra tenemos 5 observaciones. Trial, es la prueba realizada (T-F) Para cargar los datos pistongrings: library(qcc) data(pistonrings) # Se carga la base de datos pistonrings attach(pistonrings) # Se toman las columnas de la base de datos como variables dim(pistonrings) # 200 datos, 3 variables ## [1] 200 3 # Creacion del objeto qcc.groups o grupos qcc: diameter &lt;- qcc.groups(pistonrings$diameter, pistonrings$sample) # Se agrupan los valores de los diámetros según el valor de la columna &quot;Sample&quot; # Como hay 200 valores en 40 muestras, el resultado es una matriz 40x5 (200/5=40) diameter ## [,1] [,2] [,3] [,4] [,5] ## 1 74.030 74.002 74.019 73.992 74.008 ## 2 73.995 73.992 74.001 74.011 74.004 ## 3 73.988 74.024 74.021 74.005 74.002 ## 4 74.002 73.996 73.993 74.015 74.009 ## 5 73.992 74.007 74.015 73.989 74.014 ## 6 74.009 73.994 73.997 73.985 73.993 ## 7 73.995 74.006 73.994 74.000 74.005 ## 8 73.985 74.003 73.993 74.015 73.988 ## 9 74.008 73.995 74.009 74.005 74.004 ## 10 73.998 74.000 73.990 74.007 73.995 ## 11 73.994 73.998 73.994 73.995 73.990 ## 12 74.004 74.000 74.007 74.000 73.996 ## 13 73.983 74.002 73.998 73.997 74.012 ## 14 74.006 73.967 73.994 74.000 73.984 ## 15 74.012 74.014 73.998 73.999 74.007 ## 16 74.000 73.984 74.005 73.998 73.996 ## 17 73.994 74.012 73.986 74.005 74.007 ## 18 74.006 74.010 74.018 74.003 74.000 ## 19 73.984 74.002 74.003 74.005 73.997 ## 20 74.000 74.010 74.013 74.020 74.003 ## 21 73.988 74.001 74.009 74.005 73.996 ## 22 74.004 73.999 73.990 74.006 74.009 ## 23 74.010 73.989 73.990 74.009 74.014 ## 24 74.015 74.008 73.993 74.000 74.010 ## 25 73.982 73.984 73.995 74.017 74.013 ## 26 74.012 74.015 74.030 73.986 74.000 ## 27 73.995 74.010 73.990 74.015 74.001 ## 28 73.987 73.999 73.985 74.000 73.990 ## 29 74.008 74.010 74.003 73.991 74.006 ## 30 74.003 74.000 74.001 73.986 73.997 ## 31 73.994 74.003 74.015 74.020 74.004 ## 32 74.008 74.002 74.018 73.995 74.005 ## 33 74.001 74.004 73.990 73.996 73.998 ## 34 74.015 74.000 74.016 74.025 74.000 ## 35 74.030 74.005 74.000 74.016 74.012 ## 36 74.001 73.990 73.995 74.010 74.024 ## 37 74.015 74.020 74.024 74.005 74.019 ## 38 74.035 74.010 74.012 74.015 74.026 ## 39 74.017 74.013 74.036 74.025 74.026 ## 40 74.010 74.005 74.029 74.000 74.020 dim(diameter) ## [1] 40 5 #efectivamente es una matriz de 40 filas y 5 columnas Para cargar los datos “plates” hay dos alternativas: Importándolo a R a partir del archivo Ejercicio1.r Ejercicio1=read.table(&quot;Ejercicio1.r&quot;,header=TRUE) names(Ejercicio1) ## [1] &quot;dureza&quot; &quot;sample&quot; dim(Ejercicio1) ## [1] 250 2 # Acto seguido se define el objeto qcc.groups: Dureza &lt;- qcc.groups(Ejercicio1$dureza, Ejercicio1$sample) O cargándolo desde el paquete qcr (que ya lleva incorporado el dataframe) data(plates) str(plates) # Variables de las que se compone plates ## &#39;data.frame&#39;: 250 obs. of 2 variables: ## $ hardness: num 138 181 213 207 184 ... ## $ sample : int 1 1 1 1 1 2 2 2 2 2 ... # dureza: vector numúrico, dureza de las planchas. # sample: identificador de la muestra, 1,2,3,...50 3.2.2 Gráfico de control para el RANGO y la MEDIA: datos “plates” IMPORTANTE. Para construir un gráfico de control de la media, primero hay que observar los diagramas de rangos o desviaciones tipicas (antes que los diagramas de la media). Es debido a que los rangos o desviaciones tipicas estimados se emplean luego para calcular los UCL y LCL en el gráfico de control de la media. Estimacion de sigma=“Rango medio”/d2 o “S media”/c4. 3.2.2.1 Librería qcc: Procedimiento estándar para la construcción de gráficos de control para el rango y la media: etapas I y II Se estiman los límites naturales del gráfico de control. Primero se estima la variabilidad del proceso con el gráfico de rangos. Se sigue el siguiente proceso: Gráfico con 4 paneles windows(15,10) op&lt;-par(mfrow=c(2,2)) Se estiman los límites naturales de control del gráfico de rangos mediante las 25 primeras muestras: qcc(Dureza[1:25,],type=&quot;R&quot;,nsigmas=3,restore.par=FALSE) # type indica gráfico de rangos, R-para variables ## List of 11 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;R&quot;, nsigmas = 3, restore.par = FALSE) ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:25] 75.4 38.9 34.5 30.4 62.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 49.2 ## $ std.dev : num 21.1 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 104 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Se ha creado un objeto qcc, el primer gráfico de control Los parámetros de la funcion qcc son los siguientes: qcc(data, type=“xbar”, sizes, center, std.dev, limits,data.name, labels, newdata, newsizes, newlabels, nsigmas = 3, confidence.level, rules = shewhart.rules, plot = TRUE) El gráfico proporciona además un resumen incluyendo estadástica descriptiva referida a los grupos, tamaño de la submuestra, num de grupos, media del estadístico del gráfico de control, desviación típica resultado de dividir el rango medio entre d2 (tabulado) summary(qcc(Dureza[1:25,], type=&quot;R&quot;,plot=FALSE)) ## ## Call: ## qcc(data = Dureza[1:25, ], type = &quot;R&quot;, plot = FALSE) ## ## R chart for Dureza[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 8.82805 32.43291 40.93472 49.17549 60.46494 149.23799 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 49.17549 ## Standard deviation: 21.14165 ## ## Control limits: ## LCL UCL ## 0 103.9801 #Proceso de control continuo: se aumñaden las muestras restantes: qcc(Dureza[c(1:10,12:25),], type=&quot;R&quot;, newdata=Dureza[26:50,],restore.par=FALSE) ## List of 15 ## $ call : language qcc(data = Dureza[c(1:10, 12:25), ], type = &quot;R&quot;, newdata = Dureza[26:50, ], restore.par = FALSE) ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;Dureza[c(1:10, 12:25), ]&quot; ## $ data : num [1:24, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:24] 75.4 38.9 34.5 30.4 62.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:24] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 45 ## $ std.dev : num 19.3 ## $ newstats : Named num [1:25] 45 42.2 45.3 43.8 67.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 95.2 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Grafico x barra: Con la estimación de la desviación típica obtenida ateriormente con el grumñáfico R, se determinan los lumñáímites de control naturales con las primeras 24 muestras (es recomendable utilizar al menos 20 muestras para ello). qcc(Dureza[c(1:10,12:25),], type=&quot;xbar&quot;,nsigmas=3,restore.par=FALSE) ## List of 11 ## $ call : language qcc(data = Dureza[c(1:10, 12:25), ], type = &quot;xbar&quot;, nsigmas = 3, restore.par = FALSE) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;Dureza[c(1:10, 12:25), ]&quot; ## $ data : num [1:24, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:24] 184 173 193 183 174 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:24] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 187 ## $ std.dev : num 19.3 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 161 213 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Seguidamente se incluyen las 25 restantes (sin afectar al cálculo de los límites de control), con el objeto de monitorizar de forma continua el proceso. qcc(Dureza[c(1:10,12:24),], type=&quot;xbar&quot;, newdata=Dureza[26:50,],nsigmas=3,restore.par=FALSE) ## List of 15 ## $ call : language qcc(data = Dureza[c(1:10, 12:24), ], type = &quot;xbar&quot;, newdata = Dureza[26:50, ], nsigmas = 3, restore.par = FALSE) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;Dureza[c(1:10, 12:24), ]&quot; ## $ data : num [1:23, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:23] 184 173 193 183 174 ... ## ..- attr(*, &quot;names&quot;)= chr [1:23] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:23] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:23] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 187 ## $ std.dev : num 19.7 ## $ newstats : Named num [1:25] 188 195 188 193 196 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 160 213 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; par(op) Gráfico S (desviaciones típicas)-para variables. También podríamos haber calculado el gráfico S en lugar del de rangos. Para muestras pequeñas ses usual usar el R, entre otras cosas por su sencillez. Para submuestras con tamaños muestrales n &gt; 10, debería utilizarse preferiblemente el gráfico S: qcc(Dureza[1:25,], type=&quot;S&quot;) ## List of 11 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;S&quot;) ## $ type : chr &quot;S&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:25] 29.8 13.9 14.3 14.1 24.7 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 19.7 ## $ std.dev : num 21 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 41.2 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; qcc(Dureza[1:25,], type=&quot;S&quot;, newdata=Dureza[26:50,]) ## List of 15 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;S&quot;, newdata = Dureza[26:50, ]) ## $ type : chr &quot;S&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 29.8 13.9 14.3 14.1 24.7 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 19.7 ## $ std.dev : num 21 ## $ newstats : Named num [1:25] 17.3 16.6 19 15.9 26.2 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 41.2 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Algunas utilidades de la función qcc Diversas maneras de representación de los gráficos de control: q&lt;-qcc(Dureza[1:25,],type=&quot;xbar&quot;, newdata=Dureza[26:50,], plot=FALSE) Se pueden mostrar sólo aquellas muestras que no han sido utilizadas para obtener los límites naturales de control fijando el parámetro chart.all=FALSE (sólo muestra de monitorizado). plot(q, chart.all=FALSE) nsigmas es el número de sigmas que se van a usar para construir los límites # de control, sumando y restando dicha cantidad al valor central. qcc(Dureza[1:25,],type=&quot;xbar&quot;,newdata=Dureza[26:50,], nsigmas=2) ## List of 15 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;xbar&quot;, newdata = Dureza[26:50, ], nsigmas = 2) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 184 173 193 183 174 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 185 ## $ std.dev : num 21.1 ## $ newstats : Named num [1:25] 188 195 188 193 196 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 2 ## $ limits : num [1, 1:2] 166 204 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; confidence.level es el nivel de confianza. El parámetro nsigmas queda anulado cuando se define confidence.level qcc(Dureza[1:25,],type=&quot;xbar&quot;,newdata=Dureza[26:50,],confidence.level=0.99) ## List of 15 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;xbar&quot;, newdata = Dureza[26:50, ], confidence.level = 0.99) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 184 173 193 183 174 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 185 ## $ std.dev : num 21.1 ## $ newstats : Named num [1:25] 188 195 188 193 196 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name : chr &quot;Dureza[26:50, ]&quot; ## $ confidence.level: num 0.99 ## $ limits : num [1, 1:2] 161 210 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Si los limites de control se calcularan para una distancia de 1.5 * sigma Datos: “pistonrings” windows(15,10) #otros 4 gráficos op&lt;-par(mfrow=c(2,2)) Se obtienen los límites naturales de control para el gráfico R q=qcc(diameter[1:25,], type=&quot;R&quot;,nsigmas=1.5,restore.par=FALSE) summary(q) ## ## Call: ## qcc(data = diameter[1:25, ], type = &quot;R&quot;, nsigmas = 1.5, restore.par = FALSE) ## ## R chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00800 0.01800 0.02100 0.02276 0.02600 0.03900 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 0.02276 ## Standard deviation: 0.009785039 ## ## Control limits: ## LCL UCL ## 0.01007733 0.03544267 # Se elimiminan los puntos fuera de control (1, 3, 11, 14) qcc(diameter[c(2,4:10,12,13,15:25),], type=&quot;R&quot;, newdata=diameter[26:40,],nsigmas=1.5 ,restore.par=FALSE) ## List of 15 ## $ call : language qcc(data = diameter[c(2, 4:10, 12, 13, 15:25), ], type = &quot;R&quot;, newdata = diameter[26:40, ], nsigmas = 1.5, re| __truncated__ ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;diameter[c(2, 4:10, 12, 13, 15:25), ]&quot; ## $ data : num [1:21, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:21] 0.019 0.022 0.026 0.024 0.012 ... ## ..- attr(*, &quot;names&quot;)= chr [1:21] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ sizes : Named int [1:21] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:21] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ center : num 0.0213 ## $ std.dev : num 0.00917 ## $ newstats : Named num [1:15] 0.044 0.025 0.015 0.019 0.017 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:15, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:15] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;diameter[26:40, ]&quot; ## $ nsigmas : num 1.5 ## $ limits : num [1, 1:2] 0.00945 0.03322 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; # Todavia queda un punto fuera de control, el 25. Se elimina qcc(diameter[c(2,4:10,12,13,15:24),], type=&quot;R&quot;, newdata=diameter[26:40,],nsigmas=1.5 ,restore.par=FALSE) ## List of 15 ## $ call : language qcc(data = diameter[c(2, 4:10, 12, 13, 15:24), ], type = &quot;R&quot;, newdata = diameter[26:40, ], nsigmas = 1.5, re| __truncated__ ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;diameter[c(2, 4:10, 12, 13, 15:24), ]&quot; ## $ data : num [1:20, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:20] 0.019 0.022 0.026 0.024 0.012 ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ sizes : Named int [1:20] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ center : num 0.0206 ## $ std.dev : num 0.00888 ## $ newstats : Named num [1:15] 0.044 0.025 0.015 0.019 0.017 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:15, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:15] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;diameter[26:40, ]&quot; ## $ nsigmas : num 1.5 ## $ limits : num [1, 1:2] 0.00914 0.03216 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; # Se construye el diagrama para las medias: qcc(diameter[c(2,4:10,12,13,15:24),], type=&quot;xbar&quot;, newdata=diameter[26:40,],nsigmas=1.5 ,restore.par=FALSE) ## List of 15 ## $ call : language qcc(data = diameter[c(2, 4:10, 12, 13, 15:24), ], type = &quot;xbar&quot;, newdata = diameter[26:40, ], nsigmas = 1.5,| __truncated__ ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;diameter[c(2, 4:10, 12, 13, 15:24), ]&quot; ## $ data : num [1:20, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:20] 74 74 74 74 74 ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ sizes : Named int [1:20] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ center : num 74 ## $ std.dev : num 0.00888 ## $ newstats : Named num [1:15] 74 74 74 74 74 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:15, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:15] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;diameter[26:40, ]&quot; ## $ nsigmas : num 1.5 ## $ limits : num [1, 1:2] 74 74 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; par(op) Todavía hay dos puntos fuera de control. Los eliminamos: a=c(2,4:10,12,13,15:24) qcc(diameter[a[-c(14,16)],], type=&quot;xbar&quot;, newdata=diameter[26:40,],nsigmas=1.5) ## List of 15 ## $ call : language qcc(data = diameter[a[-c(14, 16)], ], type = &quot;xbar&quot;, newdata = diameter[26:40, ], nsigmas = 1.5) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;diameter[a[-c(14, 16)], ]&quot; ## $ data : num [1:18, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:18] 74 74 74 74 74 ... ## ..- attr(*, &quot;names&quot;)= chr [1:18] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ sizes : Named int [1:18] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:18] &quot;2&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; ... ## $ center : num 74 ## $ std.dev : num 0.00896 ## $ newstats : Named num [1:15] 74 74 74 74 74 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:15, 1:5] 74 74 74 74 74 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:15] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:15] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;diameter[26:40, ]&quot; ## $ nsigmas : num 1.5 ## $ limits : num [1, 1:2] 74 74 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; El proceso está bajo control; por eso se toman los límites naturales obtenidos y se utilizan para controlar el proceso en continuo. Al representar las muestras restantes, se observa que varios puntos están fuera de control. Deberían identificarse las causas que provocaron esos resultados anómalos, con el fin de corregir las anomalías y/o identificar cualquier cambio en el proceso (si esto último ocurre, habría que recalcular los límites de control). detach(pistonrings) Al principio del código se introdujo un attach para poder llamar a las variables que componen pistonrings. Es conveniente, aplicar un detach para no confundir variables en adelante 3.2.3 Grafico de control para valores individuales de las variables Ejemplo: tiempos de renderizado Se simulan los tiempos de operación que cada operario dedica a cada tarea de renderizado: muestra1=rnorm(50,33.52,0.34) # Operador 1 muestra2=rnorm(50,32,0.37) # Operador 2 muestra3=rnorm(10,40,0.5) # Operador 3 muestra=c(muestra1,muestra2,muestra3) sample &lt;- 1:length(muestra) datos &lt;- data.frame(muestra,sample) # datos.qcc &lt;- qcd(datos) tiempo &lt;- qcc.groups(muestra, sample) La empresa pretende establecer los límites de control naturales para la tarea de renderizado, a partir de los cuales monitorizará el proceso con el fin de detectar posibles futuras anomalías. Para ello, toma 30 muestras de 1 elemento que se corresponden con el trabajo realizado por el operador 1. Para hallar los límites de control ejecutamos la función qcc para las 30 primeras muestras \\((&gt;20)\\) con type=\"xbar.one\" y, como el proceso está bajo control, representamos el resto de las muestras a monitorizar (de los tres operarios). windows(12,7) qcc(tiempo[1:30], type=&quot;xbar.one&quot;, newdata=tiempo[31:110],nsigmas=3) ## List of 15 ## $ call : language qcc(data = tiempo[1:30], type = &quot;xbar.one&quot;, newdata = tiempo[31:110], nsigmas = 3) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;tiempo[1:30]&quot; ## $ data : num [1:30, 1] 33.8 33.2 33.4 33.7 33.4 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:30] 33.8 33.2 33.4 33.7 33.4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:30] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:30] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 33.6 ## $ std.dev : num 0.379 ## $ newstats : Named num [1:80] 32.9 33.3 33.4 33.7 33.7 ... ## ..- attr(*, &quot;names&quot;)= chr [1:80] &quot;31&quot; &quot;32&quot; &quot;33&quot; &quot;34&quot; ... ## $ newdata : num [1:80, 1] 32.9 33.3 33.4 33.7 33.7 ... ## $ newsizes : int [1:80] 1 1 1 1 1 1 1 1 1 1 ... ## $ newdata.name: chr &quot;tiempo[31:110]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 32.5 34.8 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Lo que sucede es la sucesión de dos cambios bruscos bien delimitados. El primero se corresponde con el cambio del primer operario al segundo. El segundo operario, teniendo más experiencia, realiza la tarea en menos tiempo pero, como realiza su trabajo desde diferentes equipos, sus tiempos tienen más variabilidad. Finalmente, el becario se hace cargo del trabajo y el cambio se ve claramente en el gráfico de control: tarda más en realizar la tarea. El trabajo de los dos operarios aparece como puntos fuera de los límites de control, nos damos cuenta perfectamente de que su trabajo pertenece otras distribuciones diferentes a la que rige los tiempos de trabajo del operador 1. Al detectar el primer cambio deberíamos haber recalculado de nuevo los límites de control, pues se ha producido un cambio en el proceso que afecta a la variable medida 3.3 Gráficos de control por atributos Gráficos qcc para atributos: 3.3.1 Gráficos p Al igual que en el caso anterior, lo mejor para ver cómo trabajar con qcc, es con un ejemplo. Usaremos los datos de orangejuice, sacados también del MONTGOMERY y que estudian el sellado de las juntas de los botes de zumo de naranja concentrado. Consta de 54 muestras de tamaño 50 cada una de ellas. D es el número de disconformidades trial es la prueba (V-F). La forma más simple para trabajar con los datos es: data(orangejuice) attach(orangejuice) ## The following object is masked _by_ .GlobalEnv: ## ## sample orangejuice ## D sample size trial ## 1 12 1 50 TRUE ## 2 15 2 50 TRUE ## 3 8 3 50 TRUE ## 4 10 4 50 TRUE ## 5 4 5 50 TRUE ## 6 7 6 50 TRUE ## 7 16 7 50 TRUE ## 8 9 8 50 TRUE ## 9 14 9 50 TRUE ## 10 10 10 50 TRUE ## 11 5 11 50 TRUE ## 12 6 12 50 TRUE ## 13 17 13 50 TRUE ## 14 12 14 50 TRUE ## 15 22 15 50 TRUE ## 16 8 16 50 TRUE ## 17 10 17 50 TRUE ## 18 5 18 50 TRUE ## 19 13 19 50 TRUE ## 20 11 20 50 TRUE ## 21 20 21 50 TRUE ## 22 18 22 50 TRUE ## 23 24 23 50 TRUE ## 24 15 24 50 TRUE ## 25 9 25 50 TRUE ## 26 12 26 50 TRUE ## 27 7 27 50 TRUE ## 28 13 28 50 TRUE ## 29 9 29 50 TRUE ## 30 6 30 50 TRUE ## 31 9 31 50 FALSE ## 32 6 32 50 FALSE ## 33 12 33 50 FALSE ## 34 5 34 50 FALSE ## 35 6 35 50 FALSE ## 36 4 36 50 FALSE ## 37 6 37 50 FALSE ## 38 3 38 50 FALSE ## 39 7 39 50 FALSE ## 40 6 40 50 FALSE ## 41 2 41 50 FALSE ## 42 4 42 50 FALSE ## 43 3 43 50 FALSE ## 44 6 44 50 FALSE ## 45 5 45 50 FALSE ## 46 4 46 50 FALSE ## 47 8 47 50 FALSE ## 48 5 48 50 FALSE ## 49 6 49 50 FALSE ## 50 7 50 50 FALSE ## 51 5 51 50 FALSE ## 52 6 52 50 FALSE ## 53 3 53 50 FALSE ## 54 5 54 50 FALSE Se emplean las 30 primeras muestras para el calibrado, para la obtención de los límites de los graficos de control. Hago el diagrama de atributos tipo p (proporción de disconformidades) para Trial ==TRUE windows(15,8) qcc.atributos &lt;- qcc(D[trial], sizes=size[trial], type=&quot;p&quot;) Se realiza una modificación, ya que encontramos que los puntos 15 y 23 están fuera de los límites de control. Se pueden eliminar puntos que no me interesan con la función “setdiff”: nuevos &lt;- setdiff(which(trial), c(15,23)) nuevos ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 24 25 ## [24] 26 27 28 29 30 Y ahora realizo el control por atributos pero de mis nuevos datos windows(15,8) qcc.nuev.atributos &lt;- qcc(D[nuevos], sizes=size[nuevos],type=&quot;p&quot;) qcc.nuev.atributos ## List of 11 ## $ call : language qcc(data = D[nuevos], type = &quot;p&quot;, sizes = size[nuevos]) ## $ type : chr &quot;p&quot; ## $ data.name : chr &quot;D[nuevos]&quot; ## $ data : int [1:28, 1] 12 15 8 10 4 7 16 9 14 10 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:28] 0.24 0.3 0.16 0.2 0.08 0.14 0.32 0.18 0.28 0.2 ... ## ..- attr(*, &quot;names&quot;)= chr [1:28] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:28] 50 50 50 50 50 50 50 50 50 50 ... ## $ center : num 0.215 ## $ std.dev : num 0.411 ## $ nsigmas : num 3 ## $ limits : num [1:28, 1:2] 0.0407 0.0407 0.0407 0.0407 0.0407 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Todavía hay una submuestra fuera de control aunque ahora es la 20, antes de la primera tanda de eliminación, en la muestra original, era la 21. Se procede a su eliminación: nuevos2 &lt;- setdiff(which(trial), c(15,21,23)) nuevos2 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 22 24 25 26 ## [24] 27 28 29 30 qcc.nuev.atributos &lt;- qcc(D[nuevos2], sizes=size[nuevos2],type=&quot;p&quot;) El proceso esta bajo control: ahora incluyo las demás muestras b=qcc(D[nuevos2], sizes=size[nuevos2], type=&quot;p&quot;,newdata=D[!trial], newsizes=size[!trial]) summary(b) ## ## Call: ## qcc(data = D[nuevos2], type = &quot;p&quot;, sizes = size[nuevos2], newdata = D[!trial], newsizes = size[!trial]) ## ## p chart for D[nuevos2] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0800000 0.1500000 0.2000000 0.2081481 0.2600000 0.3600000 ## ## Group sample size: 50 ## Number of groups: 27 ## Center of group statistics: 0.2081481 ## Standard deviation: 0.4059834 ## ## Summary of group statistics in D[!trial]: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0400000 0.0800000 0.1100000 0.1108333 0.1200000 0.2400000 ## ## Group sample size: 50 ## Number of groups: 24 ## ## Control limits: ## LCL UCL ## 0.03590399 0.3803923 ## 0.03590399 0.3803923 ## ... ## 0.03590399 0.3803923 3.3.2 Gráfico tipo np número de disconformidades a partir de la aprox. norma a la distribución binomial # Hago el diagrama de atributos tipo np (num de disconformidades) para Trial ==TRUE windows(15,8) qcc.atributos &lt;- qcc(D[trial], sizes=size[trial], type=&quot;np&quot;) Se realiza una modificación, ya que los puntos que se “salen” son el 15 y el 23 Se pueden quitar puntos que no me interesan con la función “setdiff”: nuevos &lt;- setdiff(which(trial), c(15,23)) nuevos ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 21 22 24 25 ## [24] 26 27 28 29 30 y ahora hago el control por atributos pero a partir de mis nuevos datos qcc.nuev.atributos &lt;- qcc(D[nuevos], sizes=size[nuevos],type=&quot;np&quot;) qcc.nuev.atributos # Todavía hay dos fuera de control ## List of 11 ## $ call : language qcc(data = D[nuevos], type = &quot;np&quot;, sizes = size[nuevos]) ## $ type : chr &quot;np&quot; ## $ data.name : chr &quot;D[nuevos]&quot; ## $ data : int [1:28, 1] 12 15 8 10 4 7 16 9 14 10 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named int [1:28] 12 15 8 10 4 7 16 9 14 10 ... ## ..- attr(*, &quot;names&quot;)= chr [1:28] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:28] 50 50 50 50 50 50 50 50 50 50 ... ## $ center : num 10.8 ## $ std.dev : num 2.9 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 2.04 19.46 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; nuevos2 &lt;- setdiff(which(trial), c(15,21,23)) # Aunque ahora es el 20, antes # de la primera tanda de eliminación era el 21 nuevos2 ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20 22 24 25 26 ## [24] 27 28 29 30 qcc.nuev.atributos &lt;- qcc(D[nuevos2], sizes=size[nuevos2],type=&quot;np&quot;) # Ahora incluyo las demás muestras b=qcc(D[nuevos2], sizes=size[nuevos2], type=&quot;np&quot;,newdata=D[!trial], newsizes=size[!trial]) summary(b) ## ## Call: ## qcc(data = D[nuevos2], type = &quot;np&quot;, sizes = size[nuevos2], newdata = D[!trial], newsizes = size[!trial]) ## ## np chart for D[nuevos2] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4.00000 7.50000 10.00000 10.40741 13.00000 18.00000 ## ## Group sample size: 50 ## Number of groups: 27 ## Center of group statistics: 10.40741 ## Standard deviation: 2.870736 ## ## Summary of group statistics in D[!trial]: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.000000 4.000000 5.500000 5.541667 6.000000 12.000000 ## ## Group sample size: 50 ## Number of groups: 24 ## ## Control limits: ## LCL UCL ## 1.7952 19.01962 detach(orangejuice) 3.3.3 Gráficos C Número de no conformidades # Se cargan los datos: data(circuit) attach(circuit) ## The following object is masked _by_ .GlobalEnv: ## ## sample # Hago el diagrama de atributos tipo c (num de disconformidades) para Trial ==TRUE windows(15,8) qcc.atributos &lt;- qcc(x[trial], sizes=size[circuit$trial], type=&quot;c&quot;) # Se pueden quitar puntos que no me interesan con la función &quot;setdiff&quot; (el 6 y el 20): nuevos &lt;- setdiff(which(trial), c(6,20)) nuevos ## [1] 1 2 3 4 5 7 8 9 10 11 12 13 14 15 16 17 18 19 21 22 23 24 25 ## [24] 26 #y ahora hago el control por atributos pero de mis nuevos datos qcc.nuev.atributos &lt;- qcc(x[nuevos], sizes=size[nuevos],type=&quot;c&quot;,title=&quot;Gráfico c para el nnum de unidades defectuosas por muestra&quot;,xlab=&quot;muestra&quot;, ylab=&quot;No conformidades por muestra inspeccionada&quot;) qcc.nuev.atributos &lt;- qcc(x[nuevos], sizes=size[nuevos],newdata=x[!trial],type=&quot;c&quot;,title=&quot;Gráfico c para el num de unidades defectuosas por muestra&quot;,xlab=&quot;muestra&quot;, ylab=&quot;No conformidades por muestra inspeccionada&quot;) detach(circuit) 3.3.4 Gráficos U Número medio de no conformidades por muestra # Se cargan los datos: data(pcmanufact) attach(pcmanufact) ## The following object is masked _by_ .GlobalEnv: ## ## sample # Hago el diagrama de atributos tipo c (num de disconformidades) para Trial ==TRUE windows(15,8) qcc.atributos &lt;- qcc(x, sizes=size, type=&quot;u&quot;,title=&quot;Gráfico u para el num medio de unidades defectuosas por muestra&quot;,xlab=&quot;muestra&quot;, ylab=&quot;Num no conformidades medias por muestra&quot;) detach(pcmanufact) 3.4 Otros gráficos de Control: CUSUM y EWMA 3.4.1 GRÀFICOS CUSUM Se cargan los datos y se agrupan para poder realizar el gráfico de control ##revision.archivo pistonrings data(pistonrings) attach(pistonrings) ## The following objects are masked _by_ .GlobalEnv: ## ## diameter, sample diameter &lt;- qcc.groups(pistonrings$diameter,pistonrings$sample) # se.shif: es el valor K que nos da la sensibilidad del gráfico, # detectará cambios, desplazamientos de la media mayores que k veces # la desviación típica estimada # decision.interval: es el parámetro h, a partir de cual se construyen # los límites de control: H = h_sigma. Suele valer 4 o 5. windows(15,10) # 4 paneles en un gráfico: op&lt;-par(mfrow=c(2,2)) q &lt;- cusum(diameter[1:25,], decision.interval = 4, se.shift = 1 ,restore.par=FALSE) summary(q) ## ## Call: ## cusum(data = diameter[1:25, ], decision.interval = 4, se.shift = 1, restore.par = FALSE) ## ## cusum chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99 74.00 74.00 74.00 74.00 74.01 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 74.00118 ## Standard deviation: 0.009785039 ## ## Decision interval (std.err.): 4 ## Shift detection (std. err.): 1 q1 &lt;- cusum(diameter[1:25,], newdata=diameter[26:40,], decision.interval = 4, se.shift = 1,restore.par=FALSE) q2 &lt;- cusum(diameter[1:25,], newdata=diameter[26:40,], decision.interval = 5, se.shift = 1,restore.par=FALSE) summary(q2) ## ## Call: ## cusum(data = diameter[1:25, ], decision.interval = 5, se.shift = 1, newdata = diameter[26:40, ], restore.par = FALSE) ## ## cusum chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99 74.00 74.00 74.00 74.00 74.01 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 74.00118 ## Standard deviation: 0.009785039 ## ## Summary of group statistics in diameter[26:40, ]: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99220 74.00290 74.00720 74.00765 74.01270 74.02340 ## ## Group sample size: 5 ## Number of groups: 15 ## ## Decision interval (std.err.): 5 ## Shift detection (std. err.): 1 plot(q2, chart.all=FALSE,restore.par=FALSE) par(op) Con una mayor sensibilidad, detectando cambios de magnitud 0.6 sigma: windows(15,10) # 4 paneles en un gráfico: op&lt;-par(mfrow=c(2,2)) q &lt;- cusum(diameter[1:25,], decision.interval = 4, se.shift = 0.6 ,restore.par=FALSE) # Elimino un punto, el 14 q1 &lt;- cusum(diameter[c(1:13,15:25),], decision.interval = 4, se.shift = 0.6 ,restore.par=FALSE) summary(q1) ## ## Call: ## cusum(data = diameter[c(1:13, 15:25), ], decision.interval = 4, se.shift = 0.6, restore.par = FALSE) ## ## cusum chart for diameter[c(1:13, 15:25), ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99 74.00 74.00 74.00 74.00 74.01 ## ## Group sample size: 5 ## Number of groups: 24 ## Center of group statistics: 74.00163 ## Standard deviation: 0.009494124 ## ## Decision interval (std.err.): 4 ## Shift detection (std. err.): 0.6 q2 &lt;- cusum(diameter[c(1:13,15:25),], newdata=diameter[26:40,], se.shift = 0.6 , decision.interval = 4,restore.par=FALSE) summary(q) ## ## Call: ## cusum(data = diameter[1:25, ], decision.interval = 4, se.shift = 0.6, restore.par = FALSE) ## ## cusum chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99 74.00 74.00 74.00 74.00 74.01 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 74.00118 ## Standard deviation: 0.009785039 ## ## Decision interval (std.err.): 4 ## Shift detection (std. err.): 0.6 plot(q2, chart.all=FALSE,restore.par=FALSE) par(op) #revision pistonrings detach(pistonrings) Aplicación del gráfico de control CUSUM a los datos “Dureza” o “plates”: windows(10,15) op&lt;-par(mfrow=c(2,1)) # Se suele tomar como buena práctica el asignar el valor de h = 5 cuando se pretende # identificar un cambio en la media de una desviación típica: q &lt;- cusum(Dureza[1:25,], decision.interval = 5, se.shift = 1,restore.par=FALSE) summary(q) names(q); q$limits # Para la muestra a monitoriza: q2 &lt;- cusum(Dureza[1:25,], decision.interval = 5, se.shift = 1, newdata=Dureza[26:50,], restore.par=FALSE) summary(q2) par(op) En este caso, el gráfico de control de la media detecta antes el cambio del proceso. Es un cambio grande. El gráfico CUSUM detecta mejor los cambios pequeños. Cambios inferiores 2sigma: los detectan mejor los gráficos CUSUM y EWMA Cambios superiores a 2sigma: los detectan mejor los gráficos de la media y rango. # Alternativamente se podría haber utilizado la librería qcr: library(qcr) res.qcd &lt;- qcd(plates, type.data = &quot;dependence&quot;) res.qcs &lt;- qcs.cusum(res.qcd, type = &quot;cusum&quot;) plot(res.qcs) 3.4.2 GRÁFICOS EWMA # revision data(pistonrings) attach(pistonrings) ## The following objects are masked _by_ .GlobalEnv: ## ## diameter, sample diameter &lt;- qcc.groups(pistonrings$diameter, pistonrings$sample) windows(15,8) # 4 paneles en un gráfico: op&lt;-par(mfrow=c(1,2)) # Se suele tomar como buena práctica el asignar el valor de 0.2 al parametro lambda q &lt;- ewma(diameter[1:25,], lambda=0.2, nsigmas=3,restore.par=FALSE) summary(q) ## ## Call: ## ewma(data = diameter[1:25, ], lambda = 0.2, nsigmas = 3, restore.par = FALSE) ## ## ewma chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99020 73.99820 74.00080 74.00118 74.00420 74.01020 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 74.00118 ## Standard deviation: 0.009785039 ## ## Smoothing parameter: 0.2 ## Control limits: ## LCL UCL ## 1 73.99855 74.00380 ## 2 73.99781 74.00454 ## ... ## 25 73.99680 74.00555 names(q); q$limits ## [1] &quot;call&quot; &quot;type&quot; &quot;data.name&quot; &quot;data&quot; &quot;statistics&quot; ## [6] &quot;sizes&quot; &quot;center&quot; &quot;std.dev&quot; &quot;x&quot; &quot;y&quot; ## [11] &quot;sigma&quot; &quot;lambda&quot; &quot;nsigmas&quot; &quot;limits&quot; &quot;violations&quot; ## LCL UCL ## 1 73.99855 74.00380 ## 2 73.99781 74.00454 ## 3 73.99742 74.00493 ## 4 73.99718 74.00517 ## 5 73.99704 74.00531 ## 6 73.99695 74.00540 ## 7 73.99690 74.00545 ## 8 73.99686 74.00549 ## 9 73.99684 74.00551 ## 10 73.99683 74.00553 ## 11 73.99682 74.00554 ## 12 73.99681 74.00554 ## 13 73.99681 74.00555 ## 14 73.99680 74.00555 ## 15 73.99680 74.00555 ## 16 73.99680 74.00555 ## 17 73.99680 74.00555 ## 18 73.99680 74.00555 ## 19 73.99680 74.00555 ## 20 73.99680 74.00555 ## 21 73.99680 74.00555 ## 22 73.99680 74.00555 ## 23 73.99680 74.00555 ## 24 73.99680 74.00555 ## 25 73.99680 74.00555 # Para la muestra a monitorizar se emplean unos límites ligeramente más exigentes q2 &lt;- ewma(diameter[1:25,], lambda=0.2, nsigmas=3, newdata=diameter[26:40,], plot = FALSE,restore.par=FALSE) summary(q2) ## ## Call: ## ewma(data = diameter[1:25, ], lambda = 0.2, nsigmas = 3, newdata = diameter[26:40, ], plot = FALSE, restore.par = FALSE) ## ## ewma chart for diameter[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99020 73.99820 74.00080 74.00118 74.00420 74.01020 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 74.00118 ## Standard deviation: 0.009785039 ## ## Summary of group statistics in diameter[26:40, ]: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 73.99220 74.00290 74.00720 74.00765 74.01270 74.02340 ## ## Group sample size: 5 ## Number of groups: 15 ## ## Smoothing parameter: 0.2 ## Control limits: ## LCL UCL ## 1 73.99855 74.00380 ## 2 73.99781 74.00454 ## ... ## 40 73.99680 74.00555 plot(q2) par(op) #detach(pistonrings) names(q2) ## [1] &quot;call&quot; &quot;type&quot; &quot;data.name&quot; &quot;data&quot; ## [5] &quot;statistics&quot; &quot;sizes&quot; &quot;center&quot; &quot;std.dev&quot; ## [9] &quot;newstats&quot; &quot;newdata&quot; &quot;newsizes&quot; &quot;newdata.name&quot; ## [13] &quot;x&quot; &quot;y&quot; &quot;sigma&quot; &quot;lambda&quot; ## [17] &quot;nsigmas&quot; &quot;limits&quot; &quot;violations&quot; q2$limits ## LCL UCL ## 1 73.99855 74.00380 ## 2 73.99781 74.00454 ## 3 73.99742 74.00493 ## 4 73.99718 74.00517 ## 5 73.99704 74.00531 ## 6 73.99695 74.00540 ## 7 73.99690 74.00545 ## 8 73.99686 74.00549 ## 9 73.99684 74.00551 ## 10 73.99683 74.00553 ## 11 73.99682 74.00554 ## 12 73.99681 74.00554 ## 13 73.99681 74.00555 ## 14 73.99680 74.00555 ## 15 73.99680 74.00555 ## 16 73.99680 74.00555 ## 17 73.99680 74.00555 ## 18 73.99680 74.00555 ## 19 73.99680 74.00555 ## 20 73.99680 74.00555 ## 21 73.99680 74.00555 ## 22 73.99680 74.00555 ## 23 73.99680 74.00555 ## 24 73.99680 74.00555 ## 25 73.99680 74.00555 ## 26 73.99680 74.00555 ## 27 73.99680 74.00555 ## 28 73.99680 74.00555 ## 29 73.99680 74.00555 ## 30 73.99680 74.00555 ## 31 73.99680 74.00555 ## 32 73.99680 74.00555 ## 33 73.99680 74.00555 ## 34 73.99680 74.00555 ## 35 73.99680 74.00555 ## 36 73.99680 74.00555 ## 37 73.99680 74.00555 ## 38 73.99680 74.00555 ## 39 73.99680 74.00555 ## 40 73.99680 74.00555 ## ## En el caso de observaciones individuales: ## x &lt;- c(33.75, 33.05, 34, 33.81, 33.46, 34.02, 33.68, 33.27, 33.49, 33.20, 33.62, 33.00, 33.54, 33.12, 33.84) # viscosity data (Montgomery, pag. 242) q &lt;- ewma(x, lambda=0.2, nsigmas=2.7) summary(q) ## ## Call: ## ewma(data = x, lambda = 0.2, nsigmas = 2.7) ## ## ewma chart for x ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 33.00000 33.23500 33.54000 33.52333 33.78000 34.02000 ## ## Group sample size: 1 ## Number of groups: 15 ## Center of group statistics: 33.52333 ## Standard deviation: 0.4261651 ## ## Smoothing parameter: 0.2 ## Control limits: ## LCL UCL ## [1,] 33.29320 33.75346 ## [2,] 33.22862 33.81804 ## ... ## [15,] 33.14002 33.90664 Aplicación del gráfico de control EWMA a los datos “Dureza” o “plates”: windows(10,15) # 4 paneles en un gráfico: op&lt;-par(mfrow=c(2,1)) # Se suele tomar como buena práctica el asignar el valor de 0.2 al parametro lambda q &lt;- ewma(Dureza[1:25,], lambda=0.2, nsigmas=3,restore.par=FALSE) summary(q) names(q); q$limits # Para la muestra a monitorizar se emplean unos límites ligeramente más exigentes q2 &lt;- ewma(Dureza[1:25,], lambda=0.25, nsigmas=3, newdata=Dureza[26:50,], restore.par=FALSE) summary(q2) par(op) En este caso, el gráfico de control de la media detecta antes el cambio del proceso. Es un cambio grande. El gráfico EWMA detecta mejor los cambios pequeños. Cambios inferiores 2sigma: los detectan mejor los gráficos CUSUM y EWMA Cambios superiores a 2sigma: los detectan mejor los gráficos de la media y rango. # Alternativamente se podría haber utilizado la librería qcr: library(qcr) res.qcd &lt;- qcd(plates, type.data = &quot;dependence&quot;) # res.qcs &lt;- qcs.ewma(res.qcd, type = &quot;ewma&quot;) #REVISION plot(res.qcs) 3.5 CURVAS OC Tenemos dos opciones: La más sencilla es crear un objeto qcc (por variables por atributos) y después ejecutar. 3.5.1 Curvas OC para gráfica de variables library(qcc) ### Curvas OC para el gráfico de la media ################################# data(pistonrings) pistonrings ## diameter sample trial ## 1 74.030 1 TRUE ## 2 74.002 1 TRUE ## 3 74.019 1 TRUE ## 4 73.992 1 TRUE ## 5 74.008 1 TRUE ## 6 73.995 2 TRUE ## 7 73.992 2 TRUE ## 8 74.001 2 TRUE ## 9 74.011 2 TRUE ## 10 74.004 2 TRUE ## 11 73.988 3 TRUE ## 12 74.024 3 TRUE ## 13 74.021 3 TRUE ## 14 74.005 3 TRUE ## 15 74.002 3 TRUE ## 16 74.002 4 TRUE ## 17 73.996 4 TRUE ## 18 73.993 4 TRUE ## 19 74.015 4 TRUE ## 20 74.009 4 TRUE ## 21 73.992 5 TRUE ## 22 74.007 5 TRUE ## 23 74.015 5 TRUE ## 24 73.989 5 TRUE ## 25 74.014 5 TRUE ## 26 74.009 6 TRUE ## 27 73.994 6 TRUE ## 28 73.997 6 TRUE ## 29 73.985 6 TRUE ## 30 73.993 6 TRUE ## 31 73.995 7 TRUE ## 32 74.006 7 TRUE ## 33 73.994 7 TRUE ## 34 74.000 7 TRUE ## 35 74.005 7 TRUE ## 36 73.985 8 TRUE ## 37 74.003 8 TRUE ## 38 73.993 8 TRUE ## 39 74.015 8 TRUE ## 40 73.988 8 TRUE ## 41 74.008 9 TRUE ## 42 73.995 9 TRUE ## 43 74.009 9 TRUE ## 44 74.005 9 TRUE ## 45 74.004 9 TRUE ## 46 73.998 10 TRUE ## 47 74.000 10 TRUE ## 48 73.990 10 TRUE ## 49 74.007 10 TRUE ## 50 73.995 10 TRUE ## 51 73.994 11 TRUE ## 52 73.998 11 TRUE ## 53 73.994 11 TRUE ## 54 73.995 11 TRUE ## 55 73.990 11 TRUE ## 56 74.004 12 TRUE ## 57 74.000 12 TRUE ## 58 74.007 12 TRUE ## 59 74.000 12 TRUE ## 60 73.996 12 TRUE ## 61 73.983 13 TRUE ## 62 74.002 13 TRUE ## 63 73.998 13 TRUE ## 64 73.997 13 TRUE ## 65 74.012 13 TRUE ## 66 74.006 14 TRUE ## 67 73.967 14 TRUE ## 68 73.994 14 TRUE ## 69 74.000 14 TRUE ## 70 73.984 14 TRUE ## 71 74.012 15 TRUE ## 72 74.014 15 TRUE ## 73 73.998 15 TRUE ## 74 73.999 15 TRUE ## 75 74.007 15 TRUE ## 76 74.000 16 TRUE ## 77 73.984 16 TRUE ## 78 74.005 16 TRUE ## 79 73.998 16 TRUE ## 80 73.996 16 TRUE ## 81 73.994 17 TRUE ## 82 74.012 17 TRUE ## 83 73.986 17 TRUE ## 84 74.005 17 TRUE ## 85 74.007 17 TRUE ## 86 74.006 18 TRUE ## 87 74.010 18 TRUE ## 88 74.018 18 TRUE ## 89 74.003 18 TRUE ## 90 74.000 18 TRUE ## 91 73.984 19 TRUE ## 92 74.002 19 TRUE ## 93 74.003 19 TRUE ## 94 74.005 19 TRUE ## 95 73.997 19 TRUE ## 96 74.000 20 TRUE ## 97 74.010 20 TRUE ## 98 74.013 20 TRUE ## 99 74.020 20 TRUE ## 100 74.003 20 TRUE ## 101 73.988 21 TRUE ## 102 74.001 21 TRUE ## 103 74.009 21 TRUE ## 104 74.005 21 TRUE ## 105 73.996 21 TRUE ## 106 74.004 22 TRUE ## 107 73.999 22 TRUE ## 108 73.990 22 TRUE ## 109 74.006 22 TRUE ## 110 74.009 22 TRUE ## 111 74.010 23 TRUE ## 112 73.989 23 TRUE ## 113 73.990 23 TRUE ## 114 74.009 23 TRUE ## 115 74.014 23 TRUE ## 116 74.015 24 TRUE ## 117 74.008 24 TRUE ## 118 73.993 24 TRUE ## 119 74.000 24 TRUE ## 120 74.010 24 TRUE ## 121 73.982 25 TRUE ## 122 73.984 25 TRUE ## 123 73.995 25 TRUE ## 124 74.017 25 TRUE ## 125 74.013 25 TRUE ## 126 74.012 26 FALSE ## 127 74.015 26 FALSE ## 128 74.030 26 FALSE ## 129 73.986 26 FALSE ## 130 74.000 26 FALSE ## 131 73.995 27 FALSE ## 132 74.010 27 FALSE ## 133 73.990 27 FALSE ## 134 74.015 27 FALSE ## 135 74.001 27 FALSE ## 136 73.987 28 FALSE ## 137 73.999 28 FALSE ## 138 73.985 28 FALSE ## 139 74.000 28 FALSE ## 140 73.990 28 FALSE ## 141 74.008 29 FALSE ## 142 74.010 29 FALSE ## 143 74.003 29 FALSE ## 144 73.991 29 FALSE ## 145 74.006 29 FALSE ## 146 74.003 30 FALSE ## 147 74.000 30 FALSE ## 148 74.001 30 FALSE ## 149 73.986 30 FALSE ## 150 73.997 30 FALSE ## 151 73.994 31 FALSE ## 152 74.003 31 FALSE ## 153 74.015 31 FALSE ## 154 74.020 31 FALSE ## 155 74.004 31 FALSE ## 156 74.008 32 FALSE ## 157 74.002 32 FALSE ## 158 74.018 32 FALSE ## 159 73.995 32 FALSE ## 160 74.005 32 FALSE ## 161 74.001 33 FALSE ## 162 74.004 33 FALSE ## 163 73.990 33 FALSE ## 164 73.996 33 FALSE ## 165 73.998 33 FALSE ## 166 74.015 34 FALSE ## 167 74.000 34 FALSE ## 168 74.016 34 FALSE ## 169 74.025 34 FALSE ## 170 74.000 34 FALSE ## 171 74.030 35 FALSE ## 172 74.005 35 FALSE ## 173 74.000 35 FALSE ## 174 74.016 35 FALSE ## 175 74.012 35 FALSE ## 176 74.001 36 FALSE ## 177 73.990 36 FALSE ## 178 73.995 36 FALSE ## 179 74.010 36 FALSE ## 180 74.024 36 FALSE ## 181 74.015 37 FALSE ## 182 74.020 37 FALSE ## 183 74.024 37 FALSE ## 184 74.005 37 FALSE ## 185 74.019 37 FALSE ## 186 74.035 38 FALSE ## 187 74.010 38 FALSE ## 188 74.012 38 FALSE ## 189 74.015 38 FALSE ## 190 74.026 38 FALSE ## 191 74.017 39 FALSE ## 192 74.013 39 FALSE ## 193 74.036 39 FALSE ## 194 74.025 39 FALSE ## 195 74.026 39 FALSE ## 196 74.010 40 FALSE ## 197 74.005 40 FALSE ## 198 74.029 40 FALSE ## 199 74.000 40 FALSE ## 200 74.020 40 FALSE attach(pistonrings) ## The following objects are masked _by_ .GlobalEnv: ## ## diameter, sample ## The following objects are masked from pistonrings (pos = 3): ## ## diameter, sample, trial dim(pistonrings) ## [1] 200 3 #200 datos 3 variables #creacion de los grupos qcc diameter &lt;- qcc.groups(pistonrings$diameter, pistonrings$sample) #hace grupos por diametro y muestra; lo que me da una matriz 40x5 #Como hay 5 observaciones por submuestra, hay 200/5=40 submuestras diameter ## [,1] [,2] [,3] [,4] [,5] ## 1 74.030 74.002 74.019 73.992 74.008 ## 2 73.995 73.992 74.001 74.011 74.004 ## 3 73.988 74.024 74.021 74.005 74.002 ## 4 74.002 73.996 73.993 74.015 74.009 ## 5 73.992 74.007 74.015 73.989 74.014 ## 6 74.009 73.994 73.997 73.985 73.993 ## 7 73.995 74.006 73.994 74.000 74.005 ## 8 73.985 74.003 73.993 74.015 73.988 ## 9 74.008 73.995 74.009 74.005 74.004 ## 10 73.998 74.000 73.990 74.007 73.995 ## 11 73.994 73.998 73.994 73.995 73.990 ## 12 74.004 74.000 74.007 74.000 73.996 ## 13 73.983 74.002 73.998 73.997 74.012 ## 14 74.006 73.967 73.994 74.000 73.984 ## 15 74.012 74.014 73.998 73.999 74.007 ## 16 74.000 73.984 74.005 73.998 73.996 ## 17 73.994 74.012 73.986 74.005 74.007 ## 18 74.006 74.010 74.018 74.003 74.000 ## 19 73.984 74.002 74.003 74.005 73.997 ## 20 74.000 74.010 74.013 74.020 74.003 ## 21 73.988 74.001 74.009 74.005 73.996 ## 22 74.004 73.999 73.990 74.006 74.009 ## 23 74.010 73.989 73.990 74.009 74.014 ## 24 74.015 74.008 73.993 74.000 74.010 ## 25 73.982 73.984 73.995 74.017 74.013 ## 26 74.012 74.015 74.030 73.986 74.000 ## 27 73.995 74.010 73.990 74.015 74.001 ## 28 73.987 73.999 73.985 74.000 73.990 ## 29 74.008 74.010 74.003 73.991 74.006 ## 30 74.003 74.000 74.001 73.986 73.997 ## 31 73.994 74.003 74.015 74.020 74.004 ## 32 74.008 74.002 74.018 73.995 74.005 ## 33 74.001 74.004 73.990 73.996 73.998 ## 34 74.015 74.000 74.016 74.025 74.000 ## 35 74.030 74.005 74.000 74.016 74.012 ## 36 74.001 73.990 73.995 74.010 74.024 ## 37 74.015 74.020 74.024 74.005 74.019 ## 38 74.035 74.010 74.012 74.015 74.026 ## 39 74.017 74.013 74.036 74.025 74.026 ## 40 74.010 74.005 74.029 74.000 74.020 dim(diameter) ## [1] 40 5 # Se crea el objeto qcc y luego se utiliza como argumento de la función # oc.curves. windows() qcc.variables &lt;- qcc(diameter, type=&quot;xbar&quot;) oc.curves(qcc.variables) # Representa las curvas características de # operación para el gráfico, variando en tamaño de muestra # Y otra forma es crearlo todo junto, del siguiente modo: beta1 &lt;- oc.curves(qcc(diameter, type=&quot;xbar&quot;, nsigmas=3, plot=FALSE),n=c(1,5,10,15,20,25)) # Puedo elegir los tamaños muestrales variando &quot;n&quot;. beta1 ## sample size ## shift (std.dev) n=1 n=5 n=10 n=15 ## 0 0.99730020 9.973002e-01 9.973002e-01 9.973002e-01 ## 0.05 0.99726692 9.971330e-01 9.969637e-01 9.967923e-01 ## 0.1 0.99716658 9.966188e-01 9.959040e-01 9.951556e-01 ## 0.15 0.99699769 9.957200e-01 9.939699e-01 9.920483e-01 ## 0.2 0.99675773 9.943735e-01 9.909063e-01 9.868928e-01 ## 0.25 0.99644321 9.924902e-01 9.863525e-01 9.788745e-01 ## 0.3 0.99604960 9.899543e-01 9.798427e-01 9.669608e-01 ## 0.35 0.99557135 9.866237e-01 9.708145e-01 9.499523e-01 ## 0.4 0.99500188 9.823300e-01 9.586275e-01 9.265805e-01 ## 0.45 0.99433356 9.768805e-01 9.425945e-01 8.956506e-01 ## 0.5 0.99355771 9.700606e-01 9.220279e-01 8.562239e-01 ## 0.55 0.99266457 9.616383e-01 8.962990e-01 8.078112e-01 ## 0.6 0.99164336 9.513704e-01 8.649063e-01 7.505463e-01 ## 0.65 0.99048217 9.390106e-01 8.275477e-01 6.852962e-01 ## 0.7 0.98916809 9.243187e-01 7.841850e-01 6.136755e-01 ## 0.75 0.98768711 9.070724e-01 7.350935e-01 5.379468e-01 ## 0.8 0.98602420 8.870794e-01 6.808860e-01 4.608126e-01 ## 0.85 0.98416333 8.641901e-01 6.225040e-01 3.851296e-01 ## 0.9 0.98208748 8.383105e-01 5.611755e-01 3.135953e-01 ## 0.95 0.97977871 8.094129e-01 4.983389e-01 2.484631e-01 ## 1 0.97721820 7.775460e-01 4.355436e-01 1.913361e-01 ## 1.05 0.97438633 7.428409e-01 3.743358e-01 1.430689e-01 ## 1.1 0.97126278 7.055136e-01 3.161453e-01 1.037839e-01 ## 1.15 0.96782660 6.658644e-01 2.621864e-01 7.298274e-02 ## 1.2 0.96405634 6.242714e-01 2.133844e-01 4.971944e-02 ## 1.25 0.95993015 5.811807e-01 1.703338e-01 3.279399e-02 ## 1.3 0.95542600 5.370926e-01 1.332926e-01 2.093156e-02 ## 1.35 0.95052173 4.925435e-01 1.022072e-01 1.292268e-02 ## 1.4 0.94519530 4.480873e-01 7.676275e-02 7.713924e-03 ## 1.45 0.93942495 4.042744e-01 5.644880e-02 4.450597e-03 ## 1.5 0.93318940 3.616312e-01 4.063044e-02 2.481118e-03 ## 1.55 0.92646806 3.206416e-01 2.861629e-02 1.336117e-03 ## 1.6 0.91924123 2.817304e-01 1.971628e-02 6.948704e-04 ## 1.65 0.91149035 2.452505e-01 1.328566e-02 3.489249e-04 ## 1.7 0.90319821 2.114745e-01 8.753767e-03 1.691396e-04 ## 1.75 0.89434921 1.805900e-01 5.638663e-03 7.913507e-05 ## 1.8 0.88492954 1.526999e-01 3.550185e-03 3.573024e-05 ## 1.85 0.87492745 1.278265e-01 2.184493e-03 1.556632e-05 ## 1.9 0.86433346 1.059187e-01 1.313449e-03 6.542812e-06 ## 1.95 0.85314057 8.686236e-02 7.715821e-04 2.652909e-06 ## 2 0.84134446 7.049208e-02 4.427983e-04 1.037564e-06 ## 2.05 0.82894365 5.660376e-02 2.482207e-04 3.913831e-07 ## 2.1 0.81593970 4.496730e-02 1.359050e-04 1.423792e-07 ## 2.15 0.80233733 3.533858e-02 7.267075e-05 4.994766e-08 ## 2.2 0.78814450 2.747006e-02 3.794674e-05 1.689573e-08 ## 2.25 0.77337257 2.111974e-02 1.934850e-05 5.510659e-09 ## 2.3 0.75803629 1.605830e-02 9.632705e-06 1.732884e-09 ## 2.35 0.74215385 1.207421e-02 4.682193e-06 5.253525e-10 ## 2.4 0.72574685 8.977056e-03 2.221903e-06 1.535414e-10 ## 2.45 0.70884029 6.599274e-03 1.029324e-06 4.325872e-11 ## 2.5 0.69146244 4.796428e-03 4.654875e-07 1.174834e-11 ## 2.55 0.67364477 3.446464e-03 2.054817e-07 3.075504e-12 ## 2.6 0.65542173 2.448161e-03 8.853782e-08 7.760279e-13 ## 2.65 0.63683064 1.719073e-03 3.723551e-08 1.887316e-13 ## 2.7 0.61791142 1.193208e-03 1.528420e-08 4.423888e-14 ## 2.75 0.59870632 8.186271e-04 6.123076e-09 9.994083e-15 ## 2.8 0.57925971 5.551191e-04 2.394001e-09 2.175950e-15 ## 2.85 0.55961769 3.720484e-04 9.134680e-10 4.565737e-16 ## 2.9 0.53982784 2.464393e-04 3.401454e-10 9.232474e-17 ## 2.95 0.51993880 1.613254e-04 1.236023e-10 1.799122e-17 ## 3 0.50000000 1.043673e-04 4.382971e-11 3.378541e-18 ## 3.05 0.48006119 6.672385e-05 1.516632e-11 6.113855e-19 ## 3.1 0.46017216 4.215422e-05 5.120972e-12 1.066130e-19 ## 3.15 0.44038231 2.631676e-05 1.687236e-12 1.791456e-20 ## 3.2 0.42074029 1.623470e-05 5.424280e-13 2.900657e-21 ## 3.25 0.40129367 9.896157e-06 1.701545e-13 4.525573e-22 ## 3.3 0.38208858 5.960591e-06 5.208017e-14 6.803483e-23 ## 3.35 0.36316935 3.547346e-06 1.555327e-14 9.855156e-24 ## 3.4 0.34457826 2.085934e-06 4.531947e-15 1.375511e-24 ## 3.45 0.32635522 1.211915e-06 1.288414e-15 1.849814e-25 ## 3.5 0.30853754 6.956814e-07 3.573777e-16 2.396898e-26 ## 3.55 0.29115969 3.945556e-07 9.671533e-17 2.992429e-27 ## 3.6 0.27425312 2.210847e-07 2.553604e-17 3.599534e-28 ## 3.65 0.25784611 1.223925e-07 6.578049e-18 4.171693e-29 ## 3.7 0.24196365 6.694082e-08 1.653183e-18 4.658195e-30 ## 3.75 0.22662735 3.617102e-08 4.053413e-19 5.011392e-31 ## 3.8 0.21185540 1.930895e-08 9.695988e-20 5.194340e-32 ## 3.85 0.19766254 1.018308e-08 2.262719e-20 5.187166e-33 ## 3.9 0.18406013 5.305393e-09 5.151483e-21 4.990615e-34 ## 3.95 0.17105613 2.730666e-09 1.144178e-21 4.625927e-35 ## 4 0.15865525 1.388442e-09 2.479194e-22 4.131056e-36 ## 4.05 0.14685906 6.974136e-10 5.240585e-23 3.554168e-37 ## 4.1 0.13566606 3.460610e-10 1.080683e-23 2.945957e-38 ## 4.15 0.12507194 1.696330e-10 2.174015e-24 2.352467e-39 ## 4.2 0.11506967 8.214093e-11 4.266479e-25 1.809784e-40 ## 4.25 0.10564977 3.929133e-11 8.168018e-26 1.341324e-41 ## 4.3 0.09680048 1.856600e-11 1.525460e-26 9.577262e-43 ## 4.35 0.08850799 8.666044e-12 2.779199e-27 6.587912e-44 ## 4.4 0.08075666 3.995777e-12 4.939356e-28 4.365666e-45 ## 4.45 0.07352926 1.819937e-12 8.563484e-29 2.787067e-46 ## 4.5 0.06680720 8.188099e-13 1.448298e-29 1.714101e-47 ## 4.55 0.06057076 3.638973e-13 2.389407e-30 1.015583e-48 ## 4.6 0.05479929 1.597499e-13 3.845431e-31 5.796721e-50 ## 4.65 0.04947147 6.927333e-14 6.036992e-32 3.187393e-51 ## 4.7 0.04456546 2.967239e-14 9.245168e-33 1.688392e-52 ## 4.75 0.04005916 1.255445e-14 1.381102e-33 8.615760e-54 ## 4.8 0.03593032 5.246855e-15 2.012572e-34 4.235404e-55 ## 4.85 0.03215677 2.165981e-15 2.860817e-35 2.005744e-56 ## 4.9 0.02871656 8.832060e-16 3.966799e-36 9.150272e-58 ## 4.95 0.02558806 3.557290e-16 5.365373e-37 4.021321e-59 ## 5 0.02275013 1.415222e-16 7.078931e-38 1.702466e-60 ## sample size ## shift (std.dev) n=20 n=25 ## 0 9.973002e-01 9.973002e-01 ## 0.05 9.966188e-01 9.964432e-01 ## 0.1 9.943735e-01 9.935577e-01 ## 0.15 9.899543e-01 9.876871e-01 ## 0.2 9.823300e-01 9.772182e-01 ## 0.25 9.700606e-01 9.599302e-01 ## 0.3 9.513704e-01 9.331894e-01 ## 0.35 9.243187e-01 8.943492e-01 ## 0.4 8.870794e-01 8.413445e-01 ## 0.45 8.383105e-01 7.733726e-01 ## 0.5 7.775460e-01 6.914624e-01 ## 0.55 7.055136e-01 5.987063e-01 ## 0.6 6.242714e-01 5.000000e-01 ## 0.65 5.370926e-01 4.012937e-01 ## 0.7 4.480873e-01 3.085375e-01 ## 0.75 3.616312e-01 2.266274e-01 ## 0.8 2.817304e-01 1.586553e-01 ## 0.85 2.114745e-01 1.056498e-01 ## 0.9 1.526999e-01 6.680720e-02 ## 0.95 1.059187e-01 4.005916e-02 ## 1 7.049208e-02 2.275013e-02 ## 1.05 4.496730e-02 1.222447e-02 ## 1.1 2.747006e-02 6.209665e-03 ## 1.15 1.605830e-02 2.979763e-03 ## 1.2 8.977056e-03 1.349898e-03 ## 1.25 4.796428e-03 5.770250e-04 ## 1.3 2.448161e-03 2.326291e-04 ## 1.35 1.193208e-03 8.841729e-05 ## 1.4 5.551191e-04 3.167124e-05 ## 1.45 2.464393e-04 1.068853e-05 ## 1.5 1.043673e-04 3.397673e-06 ## 1.55 4.215422e-05 1.017083e-06 ## 1.6 1.623470e-05 2.866516e-07 ## 1.65 5.960591e-06 7.604961e-08 ## 1.7 2.085934e-06 1.898956e-08 ## 1.75 6.956814e-07 4.462172e-09 ## 1.8 2.210847e-07 9.865876e-10 ## 1.85 6.694082e-08 2.052263e-10 ## 1.9 1.930895e-08 4.016001e-11 ## 1.95 5.305393e-09 7.392258e-12 ## 2 1.388442e-09 1.279813e-12 ## 2.05 3.460610e-10 2.083858e-13 ## 2.1 8.214093e-11 3.190892e-14 ## 2.15 1.856600e-11 4.594627e-15 ## 2.2 3.995777e-12 6.220961e-16 ## 2.25 8.188099e-13 7.919726e-17 ## 2.3 1.597499e-13 9.479535e-18 ## 2.35 2.967239e-14 1.066764e-18 ## 2.4 5.246855e-15 1.128588e-19 ## 2.45 8.832060e-16 1.122463e-20 ## 2.5 1.415222e-16 1.049452e-21 ## 2.55 2.158594e-17 9.223414e-23 ## 2.6 3.133911e-18 7.619853e-24 ## 2.65 4.330703e-19 5.917177e-25 ## 2.7 5.696045e-20 4.319006e-26 ## 2.75 7.130499e-21 2.963081e-27 ## 2.8 8.495462e-22 1.910660e-28 ## 2.85 9.633063e-23 1.157960e-29 ## 2.9 1.039543e-23 6.595771e-31 ## 2.95 1.067609e-24 3.530942e-32 ## 3 1.043434e-25 1.776482e-33 ## 3.05 9.704940e-27 8.399796e-35 ## 3.1 8.589907e-28 3.732564e-36 ## 3.15 7.235101e-29 1.558726e-37 ## 3.2 5.799020e-30 6.117164e-39 ## 3.25 4.422952e-31 2.256016e-40 ## 3.3 3.210047e-32 7.818807e-42 ## 3.35 2.216902e-33 2.546476e-43 ## 3.4 1.456841e-34 7.793537e-45 ## 3.45 9.109685e-36 2.241406e-46 ## 3.5 5.420199e-37 6.057495e-48 ## 3.55 3.068621e-38 1.538324e-49 ## 3.6 1.653038e-39 3.670966e-51 ## 3.65 8.472864e-41 8.231656e-53 ## 3.7 4.132199e-42 1.734461e-54 ## 3.75 1.917486e-43 3.434066e-56 ## 3.8 8.466023e-45 6.388754e-58 ## 3.85 3.556474e-46 1.116822e-59 ## 3.9 1.421508e-47 1.834463e-61 ## 3.95 5.405872e-49 2.831314e-63 ## 4 1.955985e-50 4.105996e-65 ## 4.05 6.733582e-52 5.594968e-67 ## 4.1 2.205488e-53 7.163459e-69 ## 4.15 6.872877e-55 8.617701e-71 ## 4.2 2.037723e-56 9.740949e-73 ## 4.25 5.748074e-58 1.034546e-74 ## 4.3 1.542651e-59 1.032370e-76 ## 4.35 3.938934e-61 9.679551e-79 ## 4.4 9.568715e-63 8.527224e-81 ## 4.45 2.211517e-64 7.058147e-83 ## 4.5 4.862802e-66 5.489115e-85 ## 4.55 1.017281e-67 4.010892e-87 ## 4.6 2.024655e-69 2.753624e-89 ## 4.65 3.833678e-71 1.776200e-91 ## 4.7 6.906098e-73 1.076467e-93 ## 4.75 1.183589e-74 6.129572e-96 ## 4.8 1.929826e-76 3.279278e-98 ## 4.85 2.993530e-78 1.648328e-100 ## 4.9 4.417691e-80 7.784397e-103 ## 4.95 6.202289e-82 3.453988e-105 ## 5 8.284234e-84 1.439892e-107 # Average run length (ARL): muestras necesarias hasta la primera # fuera de los límites de control ARL=1/(1-beta1) ARL ## sample size ## shift (std.dev) n=1 n=5 n=10 n=15 n=20 ## 0 370.398347 370.398347 370.398347 370.398347 370.398347 ## 0.05 365.888042 348.793060 329.343558 311.746066 295.751245 ## 0.1 352.930815 295.751245 244.138167 206.423621 177.731939 ## 0.15 333.076446 233.645820 165.833615 125.759709 99.545446 ## 0.2 308.426052 177.731939 109.966815 76.293826 56.593243 ## 0.25 281.152524 133.159432 73.273472 47.336210 33.400779 ## 0.3 253.139054 99.545446 49.609699 30.267032 20.563623 ## 0.35 225.802632 74.759150 34.263577 19.980947 13.213299 ## 0.4 200.075337 56.593243 24.170630 13.620351 8.855777 ## 0.45 176.477671 43.253572 17.419934 9.583193 6.184692 ## 0.5 155.224201 33.400779 12.825107 6.955257 4.495312 ## 0.55 136.324728 26.067652 9.643106 5.203216 3.395742 ## 0.6 119.665255 20.563623 7.402271 4.008760 2.661495 ## 0.65 105.066013 16.396286 5.798704 3.177591 2.160259 ## 0.7 92.319824 13.213299 4.633598 2.588498 1.811881 ## 0.75 81.215702 10.761063 3.774917 2.164253 1.566493 ## 0.8 71.552277 8.855777 3.133676 1.854643 1.392235 ## 0.85 63.144603 7.363234 2.649035 1.626359 1.268190 ## 0.9 55.826884 6.184692 2.278815 1.456866 1.180219 ## 0.95 49.452827 5.246945 1.993378 1.330607 1.118466 ## 1 43.894682 4.495312 1.771616 1.236608 1.075838 ## 1.05 39.041655 3.888643 1.598301 1.166955 1.047085 ## 1.1 34.798080 3.395742 1.462299 1.115802 1.028246 ## 1.15 31.081578 2.992797 1.355356 1.078729 1.016320 ## 1.2 27.821314 2.661495 1.271269 1.052321 1.009058 ## 1.25 24.956423 2.387665 1.205304 1.033906 1.004820 ## 1.3 22.434602 2.160259 1.153792 1.021379 1.002454 ## 1.35 20.210891 1.970612 1.113843 1.013092 1.001195 ## 1.4 18.246609 1.811881 1.083145 1.007774 1.000555 ## 1.45 16.508447 1.678625 1.059826 1.004470 1.000247 ## 1.5 14.967685 1.566493 1.042351 1.002487 1.000104 ## 1.55 13.599532 1.471977 1.029459 1.001338 1.000042 ## 1.6 12.382556 1.392235 1.020113 1.000695 1.000016 ## 1.65 11.298203 1.324943 1.013465 1.000349 1.000006 ## 1.7 10.330388 1.268190 1.008831 1.000169 1.000002 ## 1.75 9.465144 1.220390 1.005671 1.000079 1.000001 ## 1.8 8.690327 1.180219 1.003563 1.000036 1.000000 ## 1.85 7.995359 1.146561 1.002189 1.000016 1.000000 ## 1.9 7.371014 1.118466 1.001315 1.000007 1.000000 ## 1.95 6.809233 1.095125 1.000772 1.000003 1.000000 ## 2 6.302963 1.075838 1.000443 1.000001 1.000000 ## 2.05 5.846027 1.060000 1.000248 1.000000 1.000000 ## 2.1 5.433002 1.047085 1.000136 1.000000 1.000000 ## 2.15 5.059124 1.036633 1.000073 1.000000 1.000000 ## 2.2 4.720198 1.028246 1.000038 1.000000 1.000000 ## 2.25 4.412529 1.021575 1.000019 1.000000 1.000000 ## 2.3 4.132851 1.016320 1.000010 1.000000 1.000000 ## 2.35 3.878282 1.012222 1.000005 1.000000 1.000000 ## 2.4 3.646266 1.009058 1.000002 1.000000 1.000000 ## 2.45 3.434541 1.006643 1.000001 1.000000 1.000000 ## 2.5 3.241097 1.004820 1.000000 1.000000 1.000000 ## 2.55 3.064146 1.003458 1.000000 1.000000 1.000000 ## 2.6 2.902098 1.002454 1.000000 1.000000 1.000000 ## 2.65 2.753536 1.001722 1.000000 1.000000 1.000000 ## 2.7 2.617194 1.001195 1.000000 1.000000 1.000000 ## 2.75 2.491941 1.000819 1.000000 1.000000 1.000000 ## 2.8 2.376763 1.000555 1.000000 1.000000 1.000000 ## 2.85 2.270754 1.000372 1.000000 1.000000 1.000000 ## 2.9 2.173100 1.000247 1.000000 1.000000 1.000000 ## 2.95 2.083068 1.000161 1.000000 1.000000 1.000000 ## 3 2.000000 1.000104 1.000000 1.000000 1.000000 ## 3.05 1.923303 1.000067 1.000000 1.000000 1.000000 ## 3.1 1.852442 1.000042 1.000000 1.000000 1.000000 ## 3.15 1.786934 1.000026 1.000000 1.000000 1.000000 ## 3.2 1.726341 1.000016 1.000000 1.000000 1.000000 ## 3.25 1.670268 1.000010 1.000000 1.000000 1.000000 ## 3.3 1.618355 1.000006 1.000000 1.000000 1.000000 ## 3.35 1.570276 1.000004 1.000000 1.000000 1.000000 ## 3.4 1.525735 1.000002 1.000000 1.000000 1.000000 ## 3.45 1.484462 1.000001 1.000000 1.000000 1.000000 ## 3.5 1.446210 1.000001 1.000000 1.000000 1.000000 ## 3.55 1.410755 1.000000 1.000000 1.000000 1.000000 ## 3.6 1.377891 1.000000 1.000000 1.000000 1.000000 ## 3.65 1.347429 1.000000 1.000000 1.000000 1.000000 ## 3.7 1.319198 1.000000 1.000000 1.000000 1.000000 ## 3.75 1.293038 1.000000 1.000000 1.000000 1.000000 ## 3.8 1.268803 1.000000 1.000000 1.000000 1.000000 ## 3.85 1.246358 1.000000 1.000000 1.000000 1.000000 ## 3.9 1.225581 1.000000 1.000000 1.000000 1.000000 ## 3.95 1.206354 1.000000 1.000000 1.000000 1.000000 ## 4 1.188573 1.000000 1.000000 1.000000 1.000000 ## 4.05 1.172139 1.000000 1.000000 1.000000 1.000000 ## 4.1 1.156960 1.000000 1.000000 1.000000 1.000000 ## 4.15 1.142951 1.000000 1.000000 1.000000 1.000000 ## 4.2 1.130032 1.000000 1.000000 1.000000 1.000000 ## 4.25 1.118130 1.000000 1.000000 1.000000 1.000000 ## 4.3 1.107175 1.000000 1.000000 1.000000 1.000000 ## 4.35 1.097102 1.000000 1.000000 1.000000 1.000000 ## 4.4 1.087851 1.000000 1.000000 1.000000 1.000000 ## 4.45 1.079365 1.000000 1.000000 1.000000 1.000000 ## 4.5 1.071590 1.000000 1.000000 1.000000 1.000000 ## 4.55 1.064476 1.000000 1.000000 1.000000 1.000000 ## 4.6 1.057976 1.000000 1.000000 1.000000 1.000000 ## 4.65 1.052046 1.000000 1.000000 1.000000 1.000000 ## 4.7 1.046644 1.000000 1.000000 1.000000 1.000000 ## 4.75 1.041731 1.000000 1.000000 1.000000 1.000000 ## 4.8 1.037269 1.000000 1.000000 1.000000 1.000000 ## 4.85 1.033225 1.000000 1.000000 1.000000 1.000000 ## 4.9 1.029566 1.000000 1.000000 1.000000 1.000000 ## 4.95 1.026260 1.000000 1.000000 1.000000 1.000000 ## 5 1.023280 1.000000 1.000000 1.000000 1.000000 ## sample size ## shift (std.dev) n=25 ## 0 370.398347 ## 0.05 281.152524 ## 0.1 155.224201 ## 0.15 81.215702 ## 0.2 43.894682 ## 0.25 24.956423 ## 0.3 14.967685 ## 0.35 9.465144 ## 0.4 6.302963 ## 0.45 4.412529 ## 0.5 3.241097 ## 0.55 2.491941 ## 0.6 2.000000 ## 0.65 1.670268 ## 0.7 1.446210 ## 0.75 1.293038 ## 0.8 1.188573 ## 0.85 1.118130 ## 0.9 1.071590 ## 0.95 1.041731 ## 1 1.023280 ## 1.05 1.012376 ## 1.1 1.006248 ## 1.15 1.002989 ## 1.2 1.001352 ## 1.25 1.000577 ## 1.3 1.000233 ## 1.35 1.000088 ## 1.4 1.000032 ## 1.45 1.000011 ## 1.5 1.000003 ## 1.55 1.000001 ## 1.6 1.000000 ## 1.65 1.000000 ## 1.7 1.000000 ## 1.75 1.000000 ## 1.8 1.000000 ## 1.85 1.000000 ## 1.9 1.000000 ## 1.95 1.000000 ## 2 1.000000 ## 2.05 1.000000 ## 2.1 1.000000 ## 2.15 1.000000 ## 2.2 1.000000 ## 2.25 1.000000 ## 2.3 1.000000 ## 2.35 1.000000 ## 2.4 1.000000 ## 2.45 1.000000 ## 2.5 1.000000 ## 2.55 1.000000 ## 2.6 1.000000 ## 2.65 1.000000 ## 2.7 1.000000 ## 2.75 1.000000 ## 2.8 1.000000 ## 2.85 1.000000 ## 2.9 1.000000 ## 2.95 1.000000 ## 3 1.000000 ## 3.05 1.000000 ## 3.1 1.000000 ## 3.15 1.000000 ## 3.2 1.000000 ## 3.25 1.000000 ## 3.3 1.000000 ## 3.35 1.000000 ## 3.4 1.000000 ## 3.45 1.000000 ## 3.5 1.000000 ## 3.55 1.000000 ## 3.6 1.000000 ## 3.65 1.000000 ## 3.7 1.000000 ## 3.75 1.000000 ## 3.8 1.000000 ## 3.85 1.000000 ## 3.9 1.000000 ## 3.95 1.000000 ## 4 1.000000 ## 4.05 1.000000 ## 4.1 1.000000 ## 4.15 1.000000 ## 4.2 1.000000 ## 4.25 1.000000 ## 4.3 1.000000 ## 4.35 1.000000 ## 4.4 1.000000 ## 4.45 1.000000 ## 4.5 1.000000 ## 4.55 1.000000 ## 4.6 1.000000 ## 4.65 1.000000 ## 4.7 1.000000 ## 4.75 1.000000 ## 4.8 1.000000 ## 4.85 1.000000 ## 4.9 1.000000 ## 4.95 1.000000 ## 5 1.000000 matplot(seq(0,5,length=101),ARL,col=c(1,2,3,4,5,6),type=&quot;l&quot;, lty=1,xlab=&quot;Desviaciones de la media medidas en nº desv. tipicas&quot;) legend(2,300,c(&quot;n=1&quot;,&quot;n=5&quot;,&quot;n=10&quot;,&quot;n=15&quot;,&quot;n=20&quot;,&quot;n=25&quot;), col=c(1,2,3,4,5,6),lty=1,lwd=2) detach(pistonrings) Si es por atributos ## Curvas características para un grafico p ## data(orangejuice) attach(orangejuice) # Primero se realiza el gráfico de control: qcc(D[trial], sizes=size[trial], type=&quot;p&quot;, plot=TRUE) # Se eliminan los puntos fuera de control y se recalculan los límit es nuevos2 &lt;- setdiff(which(trial), c(15,21,23)) windows(15,10) qcc.nuev.atributos &lt;- qcc(D[nuevos2], sizes=size[nuevos2],type=&quot;p&quot;) # Curva OC a partir de los resultados del grafico de control: beta &lt;- oc.curves(qcc(D[nuevos2], sizes=size[nuevos2], type=&quot;p&quot;, plot=FALSE)) print(round(beta, digits=4)) windows(15,10) op&lt;-par(mfrow=c(1,2)) oc.curves(qcc(D[nuevos2], sizes=size[nuevos2], type=&quot;p&quot;, plot=FALSE)) # Curva ARL: plot(seq(0,1,length=101),as.numeric(1/(1-beta)),type=&quot;l&quot;, ylab=&quot;Average Run Length to detect shift, ARL&quot;,xlab=&quot;p&quot; ) par(op) NOTA: debido a que la función oc.curves utiliza distribución binomial en lugar de la aproximación normal, se #obtiene un valor de la proporción media diferente a la que proporciona el gráfico de control y, además, el ARL obenido para esa media no se corresponde con 1/0.0027=370 para una distancia de 3*sigma. SEGUIDAMENTE SE MUESTRA UN SCRIPT QUE UTILIZA LA APROXIMACIÓN NORMAL: data(orangejuice) attach(orangejuice) ## The following object is masked _by_ .GlobalEnv: ## ## sample ## The following objects are masked from pistonrings: ## ## sample, trial # gráfico de control: obj.qcc &lt;- qcc(D[nuevos2], sizes=size[nuevos2], type=&quot;p&quot;, plot=TRUE) # p.hat: la proporción de errores media por muestra # LI, LS: límites de control naturales # sd: desviación típica de la aproximación normal p.hat &lt;- obj.qcc$center n &lt;-mean(size) varianza.hat &lt;- ((p.hat)*(1-p.hat))/n sd &lt;- sqrt(varianza.hat) nsigma=3 LI &lt;- p.hat-nsigma*sd LS &lt;- p.hat+nsigma*sd # Diferentes valores de la proporción de errores: p &lt;- seq(0,1,0.01) #Definimos una función para calcular los beta (ERROR TIPO II) con el TCL beta.norm &lt;- function(p.hat,sd,LI,LS){ b &lt;- round(pnorm(LS, mean = p.hat,sd = sd )-pnorm(LI, mean = p.hat,sd = sd ) ,3) return(b) } beta &lt;- apply(as.matrix(p),1,beta.norm,sd,LI,LS) windows(19,10) op=par(mfrow=c(1,2)) #Realizamos el gráfico plot(p, beta, type = &quot;n&quot;, ylim = c(0, 1), xlim = c(0, 1), main = &quot;OC curves for disconformities proportion using TCL&quot;, xlab = expression(p), ylab = &quot;Prob. type II error &quot;) #rect(par(&quot;usr&quot;)[1], par(&quot;usr&quot;)[3], par(&quot;usr&quot;)[2], par(&quot;usr&quot;)[4], # col = qcc.options(&quot;bg.figure&quot;)) lines(p, beta) lines(rep(p[which.max(beta)], 2), c(0, max(beta)), lty = 2) # Curva ARL: plot(seq(0,1,length=101),as.numeric(1/(1-beta)),type=&quot;l&quot;, ylab=&quot;Average Run Length to detect shift, ARL&quot;,xlab=&quot;p&quot; ) par(op) detach(orangejuice) ## Curvas OC para un gráfico de control tipo c ############################ data(circuit) attach(circuit) ## The following objects are masked _by_ .GlobalEnv: ## ## sample, x ## ## The following objects are masked from pistonrings: ## ## sample, trial windows(15,10) op&lt;-par(mfrow=c(1,2)) #q &lt;- qcc(x[trial], sizes=size[trial], type=&quot;c&quot;, plot=TRUE) #beta &lt;- oc.curves(q) #print(round(beta, digits=4))par(op) detach(circuit) NOTA: debido a a que la función oc.curves distribución de poisson en lugar de la aproximación normal, se obtiene un valor del número de disconformidades diferente a la que proporciona el gráfico de control y, además, el ARL obenido para esa media no se corresponde con 1/0.0027=370 para una distancia de 3*sigma "],
["practica-3.html", "Capítulo 4 Práctica 3 4.1 Etapa ANALIZAR: Análisis de la capacidad", " Capítulo 4 Práctica 3 4.1 Etapa ANALIZAR: Análisis de la capacidad 4.1.1 Análisis de capacidad con R: 4.1.1.1 qcc Ejemplo para entender lo que miden los índices de capacidad y poder diferenciar unos de otros Estudio de simulacion. Espesores del casco de un yate, 5 medidas por cada pieza medida: library(qcc) d1 = cbind(rnorm(125, mean = 50,sd=4 ),rep( 1:25,each=5) ) d2 = cbind(rnorm(125, mean = 56,sd=2 ),rep( 1:25,each=5) ) d3 = cbind(rnorm(125, mean = 59,sd=1 ),rep( 1:25,each=5) ) Representación de sus funciones de densidad (mismo significado que el histograma): setEPS(12) windows(12,8) plot(density(d1[,1])$x,density(d1[,1])$y, ylim=c(0,0.4 ) ,xlim=c(38,62),xlab=&quot;Longitud(mm) &quot;, ylab=&quot;Funcion de densidad&quot;,type=&quot;l&quot;,lwd=2) lines(density(d2[,1])$x,density(d2[,1])$y,lty=1,col=2,lwd=2 ) lines(density(d3[,1])$x,density(d3[,1])$y,lty=1,col=3 ,lwd=2) legend(38,0.4,c(&quot;Muestra d.1&quot;,&quot;Muestra d.2&quot;,&quot;Muestra d.3&quot;),col=c(1,2,3),lty=1,lwd=2) Se agrupan según las muestras racionales. Creo objetos qcc d.1 &lt;- qcc.groups(d1[,1], d1[,2]) d.2 &lt;- qcc.groups(d2[,1], d2[,2]) d.3 &lt;- qcc.groups(d3[,1], d3[,2]) Se establecen los límites de control natural del proceso: Primero con los rangos de la característica de calidad op=par(mfrow=c(1,3)) q1 &lt;- qcc(d.1, type=&quot;R&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = TRUE, title=&quot;R chart d.1&quot;,restore.par=FALSE) Segunda muestra q2 &lt;- qcc(d.2, type=&quot;R&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = TRUE, title=&quot;R chart d.2&quot;,restore.par=FALSE) Tercera muestra q3 &lt;- qcc(d.3, type=&quot;R&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = TRUE, title=&quot;R chart d.3&quot;,restore.par=FALSE) par(op) Se eliminan, si procede, los puntos fuera de control con el gráfico para las medias setEPS(12) windows(28,14) op=par(mfrow=c(2,3)) Se estima la variabilidad a partir del grafico de control de la media Primera muestra par(mfrow=c(2,3)) q1 &lt;- qcc(d.1, type=&quot;xbar&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = FALSE, title=&quot;xbar chart d.1&quot;,restore.par=FALSE) Segunda muestra q2 &lt;- qcc(d.2, type=&quot;xbar&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = FALSE, title=&quot;xbar chart d.2&quot;,restore.par=FALSE) Tercera muestra q3 &lt;- qcc(d.3, type=&quot;xbar&quot;, nsigmas=3, plot=TRUE,digits=4,add.stats = FALSE, title=&quot;xbar chart d.3&quot;,restore.par=FALSE) No hay ningún punto fuera de control. El sistema está bajo control Por tanto, se realiza el análisis de la CAPACIDAD DEL PROCESO process.capability(q1, spec.limits=c(38,62), restore.par = FALSE) #, target=50) ## ## Process Capability Analysis ## ## Call: ## process.capability(object = q1, spec.limits = c(38, 62), restore.par = FALSE) ## ## Number of obs = 125 Target = 50 ## Center = 50.56 LSL = 38 ## StdDev = 3.572 USL = 62 ## ## Capability indices: ## ## Value 2.5% 97.5% ## Cp 1.120 0.9806 1.259 ## Cp_l 1.172 1.0405 1.304 ## Cp_u 1.067 0.9457 1.189 ## Cp_k 1.067 0.9224 1.213 ## Cpm 1.106 0.9676 1.245 ## ## Exp&lt;LSL 0.022% Obs&lt;LSL 0% ## Exp&gt;USL 0.068% Obs&gt;USL 0.8% process.capability(q2, spec.limits=c(38,62), restore.par = FALSE) #, target=50) ## ## Process Capability Analysis ## ## Call: ## process.capability(object = q2, spec.limits = c(38, 62), restore.par = FALSE) ## ## Number of obs = 125 Target = 50 ## Center = 56.32 LSL = 38 ## StdDev = 1.943 USL = 62 ## ## Capability indices: ## ## Value 2.5% 97.5% ## Cp 2.0588 1.8027 2.3145 ## Cp_l 3.1425 2.8106 3.4744 ## Cp_u 0.9752 0.8621 1.0882 ## Cp_k 0.9752 0.8405 1.1099 ## Cpm 0.6053 0.5017 0.7087 ## ## Exp&lt;LSL 0% Obs&lt;LSL 0% ## Exp&gt;USL 0.17% Obs&gt;USL 0% process.capability(q3, spec.limits=c(38,62), restore.par = FALSE) #, target=50) ## ## Process Capability Analysis ## ## Call: ## process.capability(object = q3, spec.limits = c(38, 62), restore.par = FALSE) ## ## Number of obs = 125 Target = 50 ## Center = 58.88 LSL = 38 ## StdDev = 0.9403 USL = 62 ## ## Capability indices: ## ## Value 2.5% 97.5% ## Cp 4.2540 3.725 4.7823 ## Cp_l 7.4002 6.626 8.1747 ## Cp_u 1.1077 0.982 1.2334 ## Cp_k 1.1077 0.958 1.2574 ## Cpm 0.4482 0.370 0.5263 ## ## Exp&lt;LSL 0% Obs&lt;LSL 0% ## Exp&gt;USL 0.045% Obs&gt;USL 0% par(op) Valores de 1.33, 1.50 denotan procesos capaces. El valor de 2 es el buscado en six sigma Cp estima el potencial del proceso, pues NO tiene en cuenta la localización del proceso, sólo compara la tolerancia de especificanción con la variabilidad natural de la característica de calidad Cpk y Cpm describen el desempeño de la capacidad del proceso. Localización y variabilidad Cpm tiene en cuenta la distancia al valor objetivo. Cpk solo tiene en cuenta la distancia a los limites de especificacion 4.1.1.2 SixSigma. library(SixSigma) En una fábrica de refrescos, la característica de calidad del producto es el contenido por botella. Los límites de especificación son 2.01 l (USL) y 1.99 l (LSL). Se midió la cantidad real de varias muestras resultando: Datos x&lt;-c( 1.999607, 1.998117, 1.999559, 2.001637, 1.999599, 2.000879, 2.001136, 2.000005, 1.999577, 1.999364, 2.000888, 1.998724, 2.000295, 1.999653, 1.997282, 1.998309, 2.001099, 1.999770, 2.000964, 2.002265, 2.001769, 2.000813, 2.000456, 1.999769, 2.001893, 2.000715, 1.998592, 1.999813, 1.997697, 1.999766) windows() ss.study.ca(x, LSL = 1.99, USL = 2.01,alpha = 0.05,Target =((1.99+2.01)/2), f.su = &quot;Contenido Sustancia Maravillosa&quot;) ss.ca.cp(x, LSL = 1.99, USL = 2.01,alpha = 0.05,ci = TRUE) # Proporciona el IC de cp ## [1] 1.98843 3.35642 4.1.1.3 qualityTools. library(qualityTools) set.seed(1234) Se genera una muestra perteneciente a una distribución normal de media = 20 y sd = 1 d1 = rnorm(20, mean = 20) Se genera una muestra de 20 elementos perteneciente a una distribución weibull con parámetros de forma y escala iguales a 2 y 0, respectivamente d2 = rweibull(20, shape = 2, scale = 8) Análisis de la Capacidad de Proceso para la muestra normal windows() pcr(d1, &quot;normal&quot;, lsl = 17, usl = 23) ## ## Anderson Darling Test for normal distribution ## ## data: d1 ## A = 0.5722, mean = 19.749, sd = 1.014, p-value = 0.1191 ## alternative hypothesis: true distribution is not equal to normal Análisis de la Capacidad de Proceso para la muestra Weibull windows() pcr(d2, &quot;logistic&quot;, lsl = 1, usl = 20) # Suponiendo erróneamente dist. logística ## Warning in densfun(x, parm[1], parm[2], ...): NaNs produced ## Warning in densfun(x, parm[1], parm[2], ...): NaNs produced ## Warning in densfun(x, parm[1], parm[2], ...): NaNs produced ## ## Anderson Darling Test for logistic distribution ## ## data: d2 ## A = 0.3795, location = 6.866, scale = 1.428, p-value &gt; 0.25 ## alternative hypothesis: true distribution is not equal to logistic windows() pcr(d2, &quot;normal&quot;, lsl = 1, usl = 20) # Si supongo que la muestra es normal, ## ## Anderson Darling Test for normal distribution ## ## data: d2 ## A = 0.3974, mean = 7.065, sd = 2.543, p-value = 0.3351 ## alternative hypothesis: true distribution is not equal to normal # el test no lo rechaza Hay que tener cuidado con la distribución que se asume, pues llegamos a un número erróneo de muestras no conformes. Asumiendo la distribución correcta: pcr(d2, &quot;weibull&quot;, lsl = 1, usl = 20) ## ## Anderson Darling Test for weibull distribution ## ## data: d2 ## A = 0.3505, shape = 3.050, scale = 7.916, p-value &gt; 0.25 ## alternative hypothesis: true distribution is not equal to weibull Con sólo un límite de especificación: pcr(d1, &quot;normal&quot;, usl = 23) ## ## Anderson Darling Test for normal distribution ## ## data: d1 ## A = 0.5722, mean = 19.749, sd = 1.014, p-value = 0.1191 ## alternative hypothesis: true distribution is not equal to normal pcr(d1, &quot;normal&quot;, lsl = 17) ## ## Anderson Darling Test for normal distribution ## ## data: d1 ## A = 0.5722, mean = 19.749, sd = 1.014, p-value = 0.1191 ## alternative hypothesis: true distribution is not equal to normal Con datos agrupados en diferentes submuestras: library(qcc) data(pistonrings) attach(pistonrings) pcr(pistonrings$diameter[1:125], grouping = sample[1:125], lsl = 73.99, usl = 74.01) Si lo comparamos con las utilidades de la librería qcc: diameter &lt;- qcc.groups(diameter, sample) q &lt;- qcc(diameter[1:25,], type=&quot;xbar&quot;, nsigmas=3, plot=FALSE) process.capability(q, spec.limits=c(73.99,74.01)) La diferencia está en que pcr clacula sigma=s_media/c4, mientras que qcc lo hace con sigma= R_medio/d2 detach(pistonrings) 4.1.2 Análisis de la capacidad con datos no normales 4.1.2.1 Indices no paramétricos Ejemplo library(qualityTools) 1. Ejemplo práctico: Control componentes para altavoces Una empresa fabricante y proveedora de componentes para altavoces, está interesada en controlar la masa de uno de ellos en particular. Si la masa de dicho componente cae fuera del intervalo de especificación, está estudiado que los consumidores no aceptarán los productos. Los límites superior e inferior de especificación son 8.94 y 8.46 (en gramos) y el target es el punto medio de los límites de especificación, 8.70. x=c(8.61, 8.81, 8.72, 8.69, 8.65, 8.64, 8.68, 8.74, 8.68, 8.67, 8.64, 8.68, 8.98, 8.70, 8.74, 8.75, 8.66, 9.00, 8.64, 8.70, 8.53, 8.74, 8.59, 8.69, 8.70, 9.03, 8.83, 8.87, 8.79, 8.68, 8.76, 8.71, 8.71, 8.67, 8.67, 8.68, 8.69, 8.74, 8.80, 8.59, 8.68, 8.55, 8.73, 8.67, 8.71, 8.73, 8.67, 8.68, 8.69, 8.74, 8.55, 8.71, 8.74, 8.70, 8.62, 8.61, 8.79, 8.69, 8.68, 8.77, 8.66, 8.72, 8.81, 8.63, 8.78, 8.64, 8.66, 8.63, 8.71, 8.99, 8.67, 8.71, 8.63, 8.74, 8.67, 8.69, 8.69, 8.68, 8.70, 8.81, 8.76, 8.64, 8.54, 8.71, 8.69, 8.80, 8.70, 8.59, 8.53, 8.74, 8.71, 8.81, 8.60, 8.64, 8.71, 8.75, 8.67, 8.73, 8.61, 8.84) pcr(x, &quot;normal&quot;, lsl = 8.46, usl = 8.94) ## Warning in .myADTest(x, distribution): sample size is greater than 40 ## ## Anderson Darling Test for normal distribution ## ## data: x ## A = 2.3967, mean = 8.706, sd = 0.090, p-value = 4.177e-06 ## alternative hypothesis: true distribution is not equal to normal shapiro.test(x) ## ## Shapiro-Wilk normality test ## ## data: x ## W = 0.90824, p-value = 3.526e-06 Target=(8.94+8.46)/2; USL=8.94; LSL=8.46; d=(USL-LSL)/( 2) ; m=(USL+LSL)/( 2) F2=as.numeric(quantile(x,probs=0.99865)); F1=as.numeric(quantile(x,probs=0.00135)) Para calcular el índice \\(C_{Np}\\): u=0;v=0 CN_p=((USL-LSL)/2-u*abs(median(x)-(USL+LSL)/2))/(3*sqrt(((F2-F1)/6)^2+v*(median(x)-Target)^2)) CN_p ## [1] 0.9677605 Para calcular el índice \\(C_{Npk}\\): u=1;v=0 CN_pk=((USL-LSL)/2-u*abs(median(x)-(USL+LSL)/2))/(3*sqrt(((F2-F1)/6)^2+v*(median(x)-Target)^2)) CN_pk ## [1] 0.9274371 Para calcular el índice \\(C_{Npm}\\): u=0;v=1 CN_pm=((USL-LSL)/2-u*abs(median(x)-(USL+LSL)/2))/(3*sqrt(((F2-F1)/6)^2+v*(median(x)-Target)^2)) CN_pm ## [1] 0.9607563 Para calcular el índice \\(C_{Npmk}\\) u=1;v=1 CN_pmk=((USL-LSL)/2-u*abs(median(x)-(USL+LSL)/2))/(3*sqrt(((F2-F1)/6)^2+v*(median(x)-Target)^2)) CN_pmk ## [1] 0.9207248 Los resultados son los siguientes: Resultado=data.frame(c(CN_p,CN_pk,CN_pm,CN_pmk)) colnames(Resultado)=c(&quot;Índices de capacidad&quot;);rownames(Resultado)=c(&quot;CN_p&quot;,&quot;CN_pk&quot;,&quot;CN_pm&quot;,&quot;CN_pmk&quot;) Resultado ## Índices de capacidad ## CN_p 0.9677605 ## CN_pk 0.9274371 ## CN_pm 0.9607563 ## CN_pmk 0.9207248 Si se supusiera normalidad Utilizando la librería qualityTools pcr(x, &quot;normal&quot;, lsl = LSL, usl = USL) ## Warning in .myADTest(x, distribution): sample size is greater than 40 ## ## Anderson Darling Test for normal distribution ## ## data: x ## A = 2.3967, mean = 8.706, sd = 0.090, p-value = 4.177e-06 ## alternative hypothesis: true distribution is not equal to normal Paso a paso: Para calcular el índice \\(C_{p}\\): u=0;v=0 C_p=((USL-LSL)/2-u*abs(mean(x)-(USL+LSL)/2))/ (3*sqrt(((qnorm(0.99865,mean=mean(x),sd=sd(x))-qnorm(0.00135,mean=mean(x),sd=sd(x)))/6)^2+v*(mean(x)-Target)^2)) C_p ## [1] 0.8846175 Para calcular el índice \\(C_{pk}\\): u=1;v=0 C_pk=((USL-LSL)/2-u*abs(mean(x)-(USL+LSL)/2))/ (3*sqrt(((qnorm(0.99865,mean=mean(x),sd=sd(x))-qnorm(0.00135,mean=mean(x),sd=sd(x)))/6)^2+v*(mean(x)-Target)^2)) C_pk ## [1] 0.8643451 Para calcular el índice \\(C_{pm}\\): u=0;v=1 C_pm=((USL-LSL)/2-u*abs(mean(x)-(USL+LSL)/2))/ (3*sqrt(((qnorm(0.99865,mean=mean(x),sd=sd(x))-qnorm(0.00135,mean=mean(x),sd=sd(x)))/6)^2+v*(mean(x)-Target)^2)) C_pm ## [1] 0.8829861 Para calcular el índice \\(C_{pmk}\\): u=1;v=1 C_pmk=((USL-LSL)/2-u*abs(mean(x)-(USL+LSL)/2))/ (3*sqrt(((qnorm(0.99865,mean=mean(x),sd=sd(x))-qnorm(0.00135,mean=mean(x),sd=sd(x)))/6)^2+v*(mean(x)-Target)^2)) C_pmk ## [1] 0.862751 Resultado Resultado2=data.frame(c(C_p,C_pk,C_pm,C_pmk)) colnames(Resultado2)=c(&quot;Índices de capacidad&quot;);rownames(Resultado2)=c(&quot;C_p&quot;,&quot;C_pk&quot;,&quot;C_pm&quot;,&quot;C_pmk&quot;) Resultado2 ## Índices de capacidad ## C_p 0.8846175 ## C_pk 0.8643451 ## C_pm 0.8829861 ## C_pmk 0.8627510 dat &lt;- data.frame(Resultado,Resultado2) dat ## Índices.de.capacidad Índices.de.capacidad.1 ## CN_p 0.9677605 0.8846175 ## CN_pk 0.9274371 0.8643451 ## CN_pm 0.9607563 0.8829861 ## CN_pmk 0.9207248 0.8627510 Conclusión, si hubiéramos supuesto normalidad de los datos, x, habríamos estimado un mayor número de no conformes que el real. Los índices de capacidad son menores suponiendo normalidad. 4.1.3 Caso Práctico 2. Ejemplo práctico: Control de dureza de la piedra artificial Una conocida empresa química está desarrollando la patente de una nueva variante de piedra artificial, compuesta en su mayor parte por cuarzo \\((93 wt\\%)\\) y resina de poliéster. Esta compañía pone en marcha una planta piloto donde se comienzan a producir planchas de este material a escala industrial. Con el fin de medir el grado de homogeneidad del producto, se toman \\(50\\) submuestras, realizándose \\(5\\) medidas por plancha de la dureza Vickers correspondiente a distintas zonas de la piedra artificial (Ejercicio1.r). ¿Qué tipo de gráficos de control serían los más adecuados para controlar el nivel y la dispersión? Hallar los límites de control natural \\(3 \\sigma\\) con una muestra de calibrado y, seguidamente, monitorizar las muestras restantes. Comentar los resultados, identificar patrones e identificar sus posibles causas. Desde la gerencia de la empresa se manda una circular según la cual la dureza ha de estar entre \\(195\\) y \\(210\\) \\(Kg/cm^2\\) para poder competir con la piedra natural. Suponiendo que la dureza es una variable normal, ¿cuál sería entonces la proporción de planchas no conformes?, ¿habría que cambiar algo en el proceso de producción? library(qcc) Cargar datos Ejercicio1=read.table(&quot;Ejercicio1.r&quot;,header=TRUE) names(Ejercicio1) ## [1] &quot;dureza&quot; &quot;sample&quot; Crear objeto qcc Dureza &lt;- qcc.groups(Ejercicio1$dureza, Ejercicio1$sample) Abrir ventana de gráficos windows() Controlar la variabilidad con gráfico de rangos: qcc(Dureza[1:25,], type=&quot;R&quot;, newdata=Dureza[26:50,],nsigmas=3) ## List of 15 ## $ call : language qcc(data = Dureza[1:25, ], type = &quot;R&quot;, newdata = Dureza[26:50, ], nsigmas = 3) ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;Dureza[1:25, ]&quot; ## $ data : num [1:25, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 75.4 38.9 34.5 30.4 62.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 49.2 ## $ std.dev : num 21.1 ## $ newstats : Named num [1:25] 45 42.2 45.3 43.8 67.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 104 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Se elimina una muestra fuera de control cuando hay causa asignable: qcc(Dureza[c(1:10,12:25),], type=&quot;R&quot;, newdata=Dureza[26:50,],nsigmas=3) ## List of 15 ## $ call : language qcc(data = Dureza[c(1:10, 12:25), ], type = &quot;R&quot;, newdata = Dureza[26:50, ], nsigmas = 3) ## $ type : chr &quot;R&quot; ## $ data.name : chr &quot;Dureza[c(1:10, 12:25), ]&quot; ## $ data : num [1:24, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:24] 75.4 38.9 34.5 30.4 62.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:24] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 45 ## $ std.dev : num 19.3 ## $ newstats : Named num [1:25] 45 42.2 45.3 43.8 67.6 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 0 95.2 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Controlar la medida de posición con el gráfico de medias: windows(12,7) qcc(Dureza[c(1:10,12:25),], type=&quot;xbar&quot;, newdata=Dureza[26:50,],nsigmas=3) ## List of 15 ## $ call : language qcc(data = Dureza[c(1:10, 12:25), ], type = &quot;xbar&quot;, newdata = Dureza[26:50, ], nsigmas = 3) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;Dureza[c(1:10, 12:25), ]&quot; ## $ data : num [1:24, 1:5] 138 175 178 199 205 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:24] 184 173 193 183 174 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:24] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 187 ## $ std.dev : num 19.3 ## $ newstats : Named num [1:25] 188 195 188 193 196 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata : num [1:25, 1:5] 193 182 198 195 231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ newsizes : Named int [1:25] 5 5 5 5 5 5 5 5 5 5 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;26&quot; &quot;27&quot; &quot;28&quot; &quot;29&quot; ... ## $ newdata.name: chr &quot;Dureza[26:50, ]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 161 213 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; 4.1.3.1 Aplicación del gráfico de control EWMA windows(10,15) 4 paneles en un gráfico: op&lt;-par(mfrow=c(2,1)) Se suele tomar como buena práctica el asignar el valor de 0.2 al parametro lambda q &lt;- ewma(Dureza[1:25,], lambda=0.2, nsigmas=3,restore.par=FALSE) summary(q) ## ## Call: ## ewma(data = Dureza[1:25, ], lambda = 0.2, nsigmas = 3, restore.par = FALSE) ## ## ewma chart for Dureza[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 147.9709 180.7828 187.0367 185.1899 190.7910 201.8938 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 185.1899 ## Standard deviation: 21.14165 ## ## Smoothing parameter: 0.2 ## Control limits: ## LCL UCL ## 1 179.5170 190.8628 ## 2 177.9250 192.4547 ## ... ## 25 175.7351 194.6446 names(q); q$limits ## [1] &quot;call&quot; &quot;type&quot; &quot;data.name&quot; &quot;data&quot; &quot;statistics&quot; ## [6] &quot;sizes&quot; &quot;center&quot; &quot;std.dev&quot; &quot;x&quot; &quot;y&quot; ## [11] &quot;sigma&quot; &quot;lambda&quot; &quot;nsigmas&quot; &quot;limits&quot; &quot;violations&quot; ## LCL UCL ## 1 179.5170 190.8628 ## 2 177.9250 192.4547 ## 3 177.0683 193.3114 ## 4 176.5645 193.8152 ## 5 176.2570 194.1227 ## 6 176.0657 194.3141 ## 7 175.9453 194.4344 ## 8 175.8690 194.5107 ## 9 175.8206 194.5592 ## 10 175.7897 194.5900 ## 11 175.7700 194.6098 ## 12 175.7574 194.6224 ## 13 175.7493 194.6304 ## 14 175.7442 194.6356 ## 15 175.7409 194.6388 ## 16 175.7388 194.6410 ## 17 175.7374 194.6423 ## 18 175.7366 194.6432 ## 19 175.7360 194.6437 ## 20 175.7357 194.6441 ## 21 175.7354 194.6443 ## 22 175.7353 194.6444 ## 23 175.7352 194.6445 ## 24 175.7351 194.6446 ## 25 175.7351 194.6446 Para la muestra a monitorizar se emplean unos límites ligeramente más exigentes q2 &lt;- ewma(Dureza[1:25,], lambda=0.25, nsigmas=3, newdata=Dureza[26:50,], restore.par=FALSE) summary(q2) ## ## Call: ## ewma(data = Dureza[1:25, ], lambda = 0.25, nsigmas = 3, newdata = Dureza[26:50, ], restore.par = FALSE) ## ## ewma chart for Dureza[1:25, ] ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 147.9709 180.7828 187.0367 185.1899 190.7910 201.8938 ## ## Group sample size: 5 ## Number of groups: 25 ## Center of group statistics: 185.1899 ## Standard deviation: 21.14165 ## ## Summary of group statistics in Dureza[26:50, ]: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 187.9595 194.8110 201.1229 198.9129 202.5958 205.1781 ## ## Group sample size: 5 ## Number of groups: 25 ## ## Smoothing parameter: 0.25 ## Control limits: ## LCL UCL ## 1 178.0987 192.2810 ## 2 176.3260 194.0538 ## ... ## 50 174.4691 195.9106 par(op) En este caso, el gráfico de control de la media detecta antes el cambio del proceso. Es un cambio grande. El gráfico EWMA detecta mejor los cambios pequeños. Cambios inferiores 2*sigma: los detectan mejor los gráficos CUSUM y EWMA Cambios superiores a 2*sigma: los detectan mejor los gráficos de la media y rango. Análisis de capacidad La librería qcc permite estimar la capacidad del proceso a partir de la desviación típica obtenida de un gráfico de control: qfinal=qcc(Dureza[c(1:10,12:25),], type=&quot;xbar&quot;, newdata=Dureza[26:50,],nsigmas=3) process.capability(qfinal, spec.limits=c(195,210)) ## ## Process Capability Analysis ## ## Call: ## process.capability(object = qfinal, spec.limits = c(195, 210)) ## ## Number of obs = 120 Target = 202.5 ## Center = 186.7 LSL = 195 ## StdDev = 19.35 USL = 210 ## ## Capability indices: ## ## Value 2.5% 97.5% ## Cp 0.1292 0.11280 0.1456 ## Cp_l -0.1423 -0.08999 -0.1946 ## Cp_u 0.4007 0.33489 0.4665 ## Cp_k -0.1423 -0.07997 -0.2046 ## Cpm 0.1002 0.08521 0.1151 ## ## Exp&lt;LSL 67% Obs&lt;LSL 68% ## Exp&gt;USL 11% Obs&gt;USL 10% La proporción de elementos no conformes según las especificaciones del modelo sería del \\(78\\%\\) "],
["practica-4.html", "Capítulo 5 Práctica 4 5.1 Etapa Controlar y Analizar", " Capítulo 5 Práctica 4 5.1 Etapa Controlar y Analizar 5.1.1 Control Estadistico de Calidad Multivariante: 5.1.1.1 Caso práctico: Control del contenido de contaminantes en el queroseno. Se carga la base de datos del contenido en contaminantes (agua y sólidos) en queroseno, aguas abajo del filtro, justo antes de su inyección en el tanque de combustible de un avión. #librerias library(readr) library(qcc) library(qcr) library(qualityTools) library(knitr) library(SixSigma) library(nortest) Contaminacion=read.table(&quot;Contaminacion.txt&quot;,header=TRUE) Contaminacion ## Agua Solidos ## 1 7.402681 0.190930324 ## 2 9.771126 0.112869846 ## 3 9.393595 0.124389822 ## 4 13.372208 0.015461550 ## 5 17.620823 0.052777521 ## 6 9.395278 0.050060051 ## 7 8.031297 0.096234660 ## 8 8.774855 0.195435189 ## 9 10.780045 0.214949280 ## 10 5.404965 0.123844500 ## 11 10.379421 0.097279939 ## 12 12.765760 0.162219308 ## 13 5.102952 0.179774154 ## 14 7.131309 0.172663561 ## 15 6.578566 0.090056306 ## 16 10.633311 0.034264061 ## 17 10.148315 0.172646526 ## 18 8.573035 0.030473052 ## 19 12.374178 0.017828928 ## 20 12.544260 0.000000000 ## 21 13.629888 0.205101196 ## 22 14.829833 0.007868192 ## 23 15.153030 0.073617165 ## 24 12.287752 0.273531260 ## 25 9.244134 0.011234451 ## 26 10.525326 0.205963363 ## 27 13.842711 0.192160331 ## 28 8.813001 0.170891917 ## 29 9.264689 0.066254550 ## 30 9.722806 0.086344393 ## 31 15.984433 0.013864369 ## 32 5.238274 0.257000287 ## 33 5.035533 0.027351509 ## 34 14.924394 0.131306407 ## 35 6.660098 0.127633810 ## 36 7.542646 0.094619125 ## 37 5.199361 0.084951407 ## 38 10.171844 0.208454718 ## 39 9.554239 0.104857708 ## 40 10.075462 0.089650315 ## 41 10.371507 0.048076717 ## 42 6.557636 0.215118027 ## 43 11.583945 0.048531683 ## 44 9.287104 0.025367453 ## 45 12.501666 0.122852765 ## 46 14.331369 0.146691137 ## 47 18.862215 0.193170612 ## 48 7.521767 0.082377890 ## 49 9.310584 0.191373673 ## 50 15.026589 0.100085732 ## 51 11.001580 0.074658770 ## 52 10.683831 0.190846359 ## 53 9.020982 0.106676875 ## 54 4.832568 0.131505711 ## 55 12.019808 0.161584637 ## 56 8.785676 0.090756522 ## 57 4.934583 0.152127616 ## 58 8.987616 0.268966379 ## 59 11.511131 0.039981236 ## 60 8.079746 0.010356682 ## 61 7.295403 0.115334043 ## 62 5.702187 0.036705457 ## 63 11.411383 0.194733846 ## 64 8.605553 0.008731298 ## 65 8.579302 0.078180568 ## 66 11.313893 0.158195939 ## 67 12.525698 0.117941001 ## 68 12.481995 0.089571689 ## 69 10.822331 0.243659602 ## 70 16.966018 0.165494754 ## 71 9.210591 0.073951899 ## 72 10.592792 0.251085804 ## 73 7.139039 0.197889778 ## 74 12.092446 0.191897347 ## 75 4.157249 0.199559387 ## 76 15.824896 0.124931832 ## 77 14.131728 0.077547806 ## 78 11.663469 0.087128256 ## 79 8.126862 0.051614274 ## 80 4.040020 0.175787023 ## 81 9.254390 0.048615793 ## 82 9.003185 0.140693887 ## 83 12.447158 0.108289530 ## 84 4.648495 0.120855259 ## 85 5.448563 0.179933125 ## 86 9.415969 0.165291015 ## 87 11.976278 0.091743170 ## 88 8.137679 0.074382962 ## 89 8.781807 0.091824073 ## 90 10.352384 0.213617912 ## 91 11.021430 0.160545053 ## 92 16.464110 0.076549586 ## 93 10.969676 0.100347119 ## 94 9.872342 0.056330391 ## 95 7.824515 0.203396024 ## 96 8.637530 0.189586611 ## 97 14.349403 0.185472334 ## 98 15.306337 0.133664955 ## 99 11.407374 0.161441789 ## 100 13.158853 0.000000000 Normativa: el contenido de agua en el queroseno no ha de ser superior a 15 ppm, el contenido de sólidos en el queroseno ho ha de ser superior a 0.26 mg/L. ¿Cómo hacer un control del contenido en contaminantes cuando hay 2 características CTQ? 5.1.1.2 Aproximación univariante utilizando una corrección tipo BONFERRONI. # Se comprueba la normalidad de los datos: library(nortest) lillie.test(Contaminacion$Solidos) # Normal ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: Contaminacion$Solidos ## D = 0.076413, p-value = 0.161 lillie.test(Contaminacion[,&quot;Agua&quot;]) # Normal ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: Contaminacion[, &quot;Agua&quot;] ## D = 0.056364, p-value = 0.6061 # ¿Hay autocorrelación en la variable sólidos?, ¿y en la variable contenido en agua? library(stats) # H0: independencia de las observaciones Box.test(Contaminacion$Solidos) # La observación actual no depende de la anterior ## ## Box-Pierce test ## ## data: Contaminacion$Solidos ## X-squared = 0.65657, df = 1, p-value = 0.4178 Box.test(Contaminacion$Agua) # La observación actual no depende de la anterior ## ## Box-Pierce test ## ## data: Contaminacion$Agua ## X-squared = 1.8689, df = 1, p-value = 0.1716 # Entonces se pueden aplicar gráficos de Shewhart para la media de forma fiable: library(qcc) agua=qcc.groups(Contaminacion$Agua,rep(1:25,each=4)) # se agrupan las medidas de 4 en 4. solidos=qcc.groups(Contaminacion$Solidos,rep(1:25,each=4)) # se agrupan las medidas de 4 en 4. # Se aplica la corrección de Bonferroni apuntada por Artl, con un nivel de significación alfa/(2*nº variables) = 0.0027/4=0.000675 qcc(agua,type=&quot;xbar&quot;,confidence.level=(1-0.000675)) ## List of 11 ## $ call : language qcc(data = agua, type = &quot;xbar&quot;, confidence.level = (1 - 0.000675)) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;agua&quot; ## $ data : num [1:25, 1:4] 7.4 17.6 10.8 5.1 10.1 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 9.98 10.96 9.83 7.36 10.91 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 4 4 4 4 4 4 4 4 4 4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 10.2 ## $ std.dev : num 3.3 ## $ confidence.level: num 0.999 ## $ limits : num [1, 1:2] 4.59 15.82 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; qcc(solidos,type=&quot;xbar&quot;,confidence.level=(1-0.000675)) ## List of 11 ## $ call : language qcc(data = solidos, type = &quot;xbar&quot;, confidence.level = (1 - 0.000675)) ## $ type : chr &quot;xbar&quot; ## $ data.name : chr &quot;solidos&quot; ## $ data : num [1:25, 1:4] 0.1909 0.0528 0.2149 0.1798 0.1726 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:25] 0.1109 0.0986 0.1496 0.1192 0.0552 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : Named int [1:25] 4 4 4 4 4 4 4 4 4 4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:25] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ center : num 0.121 ## $ std.dev : num 0.0727 ## $ confidence.level: num 0.999 ## $ limits : num [1, 1:2] -0.00251 0.24472 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; 5.1.1.3 Control de calidad multivariante con gráficos Shewhart (T2 Hotelling). CONTROL MULTIVARIANTE TIPO SHEWART Comprobar si las variables aleatorias a controlar siguen una distribución multinormal (SE UTILIZA EL TEST DE MARDIA, cargando la librería MVN): library(MVN) ## Warning: package &#39;MVN&#39; was built under R version 3.6.1 ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 ## sROC 0.1-2 loaded ## ## Attaching package: &#39;MVN&#39; ## The following object is masked from &#39;package:mgcv&#39;: ## ## mvn mardiaTest(Contaminacion, cov = TRUE, qqplot = TRUE) # Es multinormal ## Warning: &#39;mardiaTest&#39; is deprecated. ## Use &#39;mvn&#39; instead. ## See help(&quot;Deprecated&quot;) La función a emplear es mqcc, de la librería qcc permite calcular gráficos de control T2 para MEDIAS de la variable y para MEDIDAS INDIVIDUALES. Control de medias con datos agrupados Se agrupan los datos en muestras de 4 elementos: Calibrado: obtención de los límites de control a partir de 25 muestras racionales x1=matrix(Contaminacion[1:100,1],nc=4, byrow=TRUE) x2=matrix(Contaminacion[1:100,2],nc=4, byrow=TRUE) X=list(x1,x2) # x1new=matrix(Contaminacion[85:100,1],nc=4, byrow=TRUE) # x2new=matrix(Contaminacion[85:100,2],nc=4, byrow=TRUE) # Xnew=list(x1new,x2new) # Muestra de Monitorizado (20 muestras racionales de 4 observaciones): ContaminacionNew=read.table(&quot;ContaminacionNew.txt&quot;,header=TRUE) x1new=matrix(ContaminacionNew[,1],nc=4, byrow=TRUE) x2new=matrix(ContaminacionNew[,2],nc=4, byrow=TRUE) Xnew=list(x1new,x2new) Gráfico de control con mqcc. Los límites para la muestra de calibrado son más estrechos que los de la muestra de monitorizado (ver Montgomery, 2001). Se recomienda, de ser posible, usar siempre más de 20 grupos y, a menudo, más de m = 50 para formar la muestra de calibrado y estimar los límites de control. q1=mqcc(X,newdata=Xnew, type = &quot;T2&quot;, pred.limits = TRUE) # medidas descriptivas del estadistico T2, nº variab., nº grupos, nºobser./grupo, # vector de medias, matriz de covarianzas muestral, límites de control: summary(q1) ## ## Call: ## mqcc(data = X, type = &quot;T2&quot;, pred.limits = TRUE, newdata = Xnew) ## ## T2 chart for X ## ## Summary of group statistics: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.120144 0.623034 1.182196 1.950055 2.929308 6.888580 ## ## Number of variables: 2 ## Number of groups: 25 ## Group sample size: 4 ## ## Center: ## X[1] X[2] ## 10.2024968 0.1211044 ## ## Covariance matrix: ## X[1] X[2] ## X[1] 9.84551114 -0.047799211 ## X[2] -0.04779921 0.005247199 ## |S|: 0.04937659 ## ## Summary of group statistics in Xnew: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.796210 2.359529 3.670768 4.893884 6.935830 20.217114 ## ## Number of groups: 20 ## Group sample size: 4 ## ## Control limits: ## LCL UCL ## 0 10.91536 ## ## Prediction limits: ## LPL UPL ## 0 11.82498 # La observación 35 se detecta como fuera de control: names(q1);q1$violation$beyond.pred.limits ## [1] &quot;call&quot; &quot;data.name&quot; &quot;var.names&quot; ## [4] &quot;data&quot; &quot;type&quot; &quot;confidence.level&quot; ## [7] &quot;statistics&quot; &quot;means&quot; &quot;center&quot; ## [10] &quot;cov&quot; &quot;newdata&quot; &quot;newdata.name&quot; ## [13] &quot;newstats&quot; &quot;newmeans&quot; &quot;limits&quot; ## [16] &quot;pred.limits&quot; &quot;violations&quot; ## [1] 35 Si tenemos solo dos variables, se puede realizar un grafico de elipse, circunferencia si las variables son independientes (sólo para control de la media de la variable CTQ). ellipseChart(q1, show.id = TRUE, chart.all = TRUE) # con show.id se identifica cada observación según su # secuencia temporal # LA OBSERVACIÓN 10 DE LA M. DE MONITOR. ESTÁ FUERA # DE CONTROL. Control de medidas individuales También es posible obtener el gráfico T2 de Hotelling para medidas individuales. Se empleará la función mqcc con type = “T2.single”: qq = mqcc(Contaminacion, type = &quot;T2.single&quot;,newdata = ContaminacionNew, pred.limits = TRUE) qq$violations$beyond.pred.limits # Las observaciones 137 y 139 están fuera de control ## [1] 137 139 5.1.1.4 Control de calidad multivariante con gráficos MEWMA y MCUSUM. Detectan mejor los cambios pequeños en el proceso debido a que tienen memoria: cada punto representado se calcula teniendo en cuenta, aparte de la actual, las observaciones anteriores. Se utiliza el paquete qcr, elaborado por Miguel Flores Los gráficos MCUSUM y MEWMA estan implementados sólo para el control de medidas individuales library(qcr) CUSUM: gráfico de las diferencias acumumadas con respecto al vector de medias Función mqcd para crear el objeto multivariante y mqcs.mcusum para obtener el gráfico multivariante: # Muestra de calibrado: data.mqcd &lt;- mqcd(Contaminacion) res.mqcs &lt;- mqcs.mcusum(data.mqcd) summary(res.mqcs) # Resumen de las principales características del gráfico de control ## ## Summary of group statistics: ## V1 ## Min. :0.0000 ## 1st Qu.:0.7687 ## Median :1.2954 ## Mean :1.5467 ## 3rd Qu.:2.2837 ## Max. :4.3011 ## ## Number of quality characteristics: 2 ## Number of samples or observations: 100 ## Number of observations or sample size: 1 ## ## Mean Vector: ## 10.2025 0.1211044 ## Covariance Matrix: ## Agua Solidos ## [1,] 10.39533177 -0.022928656 ## [2,] -0.02292866 0.004750744 ## ## Control limits: ## lcl ucl ## 0.0 5.5 ## ## Number beyond limits: 0 plot(res.mqcs, title =&quot; MCUSUM Control Chart for Water and Solids in Jet Fuel&quot;) # Muestra de monitorizado: data.mqcd.new &lt;- mqcd(ContaminacionNew) # Se toman el vector de medias y la matriz de covarianzas de la muestra de calibrado Xmv=matrix(res.mqcs$mean,byrow=TRUE) S = data.frame(matrix(res.mqcs$S,byrow=FALSE,nc=2)) # Se calcula el nuevo gráfico con los límites obtenidos en la muestra de calibrado: res.mqcs.new &lt;- mqcs.mcusum(data.mqcd.new,Xmv=Xmv,S=S) plot(res.mqcs.new, title =&quot; MCUSUM Control Chart for Water and Solids in Jet Fuel&quot;) names(res.mqcs.new);res.mqcs.new$violations. ## [1] &quot;mqcd&quot; &quot;type&quot; &quot;statistics&quot; &quot;mean&quot; &quot;S&quot; ## [6] &quot;k&quot; &quot;h&quot; &quot;limits&quot; &quot;data.name&quot; &quot;violations&quot; ## NULL # A partir de la observación 18 de la muestra de monitorizado, se muestra # que el proceso se ha desplazado respecto al vector de medias calculado en # la muestra de calibrado. EWMA: gráfico de las medias móviles ponderadas exponencialmente Función mqcd para crear el objeto multivariante y mqcs.mewma para obtener el gráfico multivariante: # Muestra de calibrado: data.mqcd &lt;- mqcd(Contaminacion) res.mqcs &lt;- mqcs.mewma(data.mqcd) summary(res.mqcs) ## ## Summary of group statistics: ## V1 ## Min. :0.008703 ## 1st Qu.:0.485543 ## Median :1.235444 ## Mean :1.287885 ## 3rd Qu.:1.841987 ## Max. :4.251642 ## ## Number of quality characteristics: 2 ## Number of samples or observations: 100 ## Number of observations or sample size: 1 ## ## Mean Vector: ## 10.2025 0.1211044 ## Covariance Matrix: ## Agua Solidos ## [1,] 10.39533177 -0.022928656 ## [2,] -0.02292866 0.004750744 ## ## Control limits: ## lcl ucl ## 0.0000 8.6336 ## ## Number beyond limits: 0 plot(res.mqcs, title =&quot; MEWMA Control Chart for Water and Solids in Jet Fuel&quot;) # Muestra de monitorizado: data.mqcd.new &lt;- mqcd(ContaminacionNew) # Se toman el vector de medias y la matriz de covarianzas de la muestra de calibrado Xmv=matrix(res.mqcs$mean,byrow=TRUE) S = data.frame(matrix(res.mqcs$S,byrow=FALSE,nc=2)) # Se calcula el nuevo gráfico con los límites obtenidos en la muestra de calibrado: res.mqcs.new &lt;- mqcs.mewma(data.mqcd.new,Xmv=Xmv,S=S) plot(res.mqcs.new, title =&quot; MEWMA Control Chart for Water and Solids in Jet Fuel&quot;) names(res.mqcs.new);res.mqcs.new$violations ## [1] &quot;mqcd&quot; &quot;type&quot; &quot;statistics&quot; &quot;mean&quot; &quot;S&quot; ## [6] &quot;lambda&quot; &quot;limits&quot; &quot;data.name&quot; &quot;violations&quot; ## [1] 8 10 18 19 20 21 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 ## [24] 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 ## [47] 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 79 80 A partir de la observación 8 de la muestra de monitorizado, se muestra que el proceso se ha desplazado respecto al vector de medias calculado en la muestra de calibrado. * CONCLUSIÓN: usando MEWMA, en la observación número 108 (teniendo en cuenta la de calibrado), se observa que el proceso está fuera de control. Con un gráfico T2, se verifica que el proceso está fuera de control en la observación 137. Este tipo de gráficos detectan mejor los cambios pequeños y paulatinos. 5.1.1.4.1 Caso práctico: Cotrol de humedad relativa, temperatura y consumo eléctrico. 5.1.1.5 Regression adjustment. Se obtienen datos del consumo energético (medido en KW) de una instalación de climatización para mantener unas determinadas condiciones de temperatura, humedad relativa y contenido de CO2. Supóngase que la característica de calidad del proceso “Confort térmico” de las instalaciones de climatización es su temperatura. La temperatura depende de las condiciones de humedad en una determinada oficina. Además, en la base de datos que se muestra hay tres medidas diferentes de la temp. y la humedad relativa, tomadas en tres zonas de la oficina. Se pretende controlar la temperatura del fondo de la oficina (la variable no es normal). ¿Cómo controlar el proceso? Una alternativa cuando se tienen varios parámetros que influyen en una característica CTQ a controlar es la aplicacion del metodo: REGRESSION ADJUSTMENT VENTAJA: simple, no es necesario aplicar estadisticos con condiciones de optimalidad. El ARL es similar al de gráficos como el T2 y otros. REQUERIMIENTOS: (1) dependencia entre variables, (2) para medidas individuales. PROCEDIMIENTO: + A) Se hace una regresión de la caracteristica Y sobre el parámetro X1; luego, una regresión de los residuos sobre el parámetro X2, y así sucesivamente con todos los parametros. + B) Se hace un gráfico de control de los residuos (muchas veces normales e independientes). DATOS referidos a las 18:00 de la tarde durante 45 días laborables ConTempHRco2=read.table(&quot;ConTempHRco2.txt&quot;) # Hay relación entre las variables, hay cierta información redundante: # Antención: cargar antes library(car) library(car) windows() scatterplotMatrix(~CO2Entrada+CO2Fondo+CO2Medio+ConsumoUE03+HREntrada+HRFondo+HRMedio+TempEntrada+TempFondo+TempMedio, reg.line=FALSE, smooth=FALSE, spread=FALSE, span=0.5, ellipse=FALSE, levels=c(.5, .9), id.n=0, diagonal = &#39;density&#39;, data=ConTempHRco2) # Efectúo regresiones sucesivas... # de la temperatura del fondo de la habitación sobre la temperatura del medio... regre1=lm(ConTempHRco2$TempFondo~ConTempHRco2$TempMedio); summary(regre1) ## ## Call: ## lm(formula = ConTempHRco2$TempFondo ~ ConTempHRco2$TempMedio) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.91480 -0.27329 -0.03027 0.25650 1.28543 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.27987 1.32515 7.758 1.05e-09 ## ConTempHRco2$TempMedio 0.62327 0.05143 12.118 1.86e-15 ## ## Residual standard error: 0.42 on 43 degrees of freedom ## Multiple R-squared: 0.7735, Adjusted R-squared: 0.7682 ## F-statistic: 146.8 on 1 and 43 DF, p-value: 1.86e-15 # de los residuos de la regresión anterior sobre la temperatura de entrada... regre2=lm(regre1$residuals~ConTempHRco2$TempEntrada); summary(regre2) ## ## Call: ## lm(formula = regre1$residuals ~ ConTempHRco2$TempEntrada) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.70442 -0.28573 -0.00773 0.22007 1.14201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3.6950 1.6776 -2.203 0.0330 ## ConTempHRco2$TempEntrada 0.1404 0.0637 2.204 0.0329 ## ## Residual standard error: 0.3982 on 43 degrees of freedom ## Multiple R-squared: 0.1015, Adjusted R-squared: 0.0806 ## F-statistic: 4.857 on 1 and 43 DF, p-value: 0.03293 # de los residuos de la regresión anterior sobre la humedad relativa del fondo... regre3=lm(regre2$residuals~ConTempHRco2$HRFondo); summary(regre3) ## ## Call: ## lm(formula = regre2$residuals ~ ConTempHRco2$HRFondo) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.8317 -0.2669 0.0048 0.2390 0.9677 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.007802 0.497035 -2.028 0.0488 ## ConTempHRco2$HRFondo 0.020354 0.009973 2.041 0.0474 ## ## Residual standard error: 0.3802 on 43 degrees of freedom ## Multiple R-squared: 0.08832, Adjusted R-squared: 0.06711 ## F-statistic: 4.165 on 1 and 43 DF, p-value: 0.04743 # de los residuos de la regresión anterior sobre la humedad relativa del medio... regre4=lm(regre3$residuals~ConTempHRco2$HRMedio); summary(regre4) ## ## Call: ## lm(formula = regre3$residuals ~ ConTempHRco2$HRMedio) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.84531 -0.26646 -0.00013 0.23238 0.94441 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.219747 0.885884 -0.248 0.805 ## ConTempHRco2$HRMedio 0.004092 0.016464 0.249 0.805 ## ## Residual standard error: 0.3799 on 43 degrees of freedom ## Multiple R-squared: 0.001435, Adjusted R-squared: -0.02179 ## F-statistic: 0.06178 on 1 and 43 DF, p-value: 0.8049 # de los residuos de la regresión anterior sobre la humedad relativa de la entrada... regre5=lm(regre4$residuals~ConTempHRco2$HREntrada); summary(regre5) ## ## Call: ## lm(formula = regre4$residuals ~ ConTempHRco2$HREntrada) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.83534 -0.27627 0.00573 0.24096 0.95649 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.153549 0.729445 0.211 0.834 ## ConTempHRco2$HREntrada -0.003068 0.014530 -0.211 0.834 ## ## Residual standard error: 0.3797 on 43 degrees of freedom ## Multiple R-squared: 0.001036, Adjusted R-squared: -0.0222 ## F-statistic: 0.04458 on 1 and 43 DF, p-value: 0.8338 # Test sobre los residuos correspondientes al primer mes: lillie.test(regre5$residuals[1:20]) # Normalidad ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: regre5$residuals[1:20] ## D = 0.13866, p-value = 0.3993 Box.test(regre5$residuals[1:20]) # No autocorrelación ## ## Box-Pierce test ## ## data: regre5$residuals[1:20] ## X-squared = 0.58081, df = 1, p-value = 0.446 lillie.test(ConTempHRco2$TempFondo[1:20]) # No normalidad en la variable de partida ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: ConTempHRco2$TempFondo[1:20] ## D = 0.28147, p-value = 0.0002135 Aplicación de gráficos de control Sewhart Gráficos de control para las muestras de calibrado y monitorizado (se toman, por ejemplo, los residuos una vez extraida la dependencia lineal con el resto de temperaturas, regre2): q6=qcc(regre2$residuals[1:20],newdata=regre2$residuals[21:45],type=&quot;xbar.one&quot;) q6$violations$beyond.limits ## [1] 32 33 35 q6$violations$violating.runs ## [1] 36 37 38 26 27 28 29 A partir del segundo mes, la temperatura no está bajo control. Han cambiado las condiciones con respecto al primer mes. Al 6º día nos damos cuenta. El regression adjustment se podría extender para el caso de regresión lineal generalizada (GLM), aditiva generalizada (GAM) e, incluso, regresión con datos funcionales. 5.1.1.6 Reducción de dimensión: Análisis de componentes principales (PCA). A partir de una matriz de datos con “p” variables, se obtiene otra matriz de datos con “p” componentes principales (nuevas variables). La primera componente principal de las p-componentes se obtiene al proyectar los vectores de observaciones en la dirección de la máxima varianza de los datos. La segunda componente se obtendrá al proyectar la información restante en la dirección de su máxima varianza y así sucesivamente hasta obtener la nuevas p componentes. Las “p” componentes son ORTOGONALES e INDEPENDIENTES entre sí. VENTAJAS: Útiles cuando tenemos una gran cantidad de variables. Con cerca de 10 variables los gráficos clásicos no son fiables (el ARL se incrementa al incrementar el nº de variables, se tarda más en detectar un verdadero fuera de control). Muchas veces se puede resumir la mayor parte de la información de la base de datos en apenas dos variables. Las proyecciones pueden cumplir las hipótesis de normalidad y no autocorrelación, lo que hace aplicables los gráficos de Shewhart. INCONVENIENTES: Es difícil descubrir cuál es la variable original que origina el fuera de control y, así, identificar las causas asignables. PROBLEMA a resolver Resumir las 9 características del confort térmico y calidad del aire de la oficina en dos variables y aplicar gráficos de control: # Muestra de calibrado (descomposición matricial en valores singulares con svd): HF.svd &lt;- svd(ConTempHRco2[1:20,-c(1:2,12:14)]) # Se obtiene la matriz de puntuaciones respecto a la nueva base de componentes principales # al multiplicar matricialmente la matriz u y d, resultado de la descomposición svd: HF.scores &lt;- as.data.frame(HF.svd$u %*% diag(HF.svd$d)) PCA &lt;- list(scores = HF.svd$u %*% diag(HF.svd$d),loadings = HF.svd$v) # Muestra de monitorizado. Se proyectan las nuevas observaciones (vectores de # características) en la nueva base: HF_test.scores=NULL for(i in 21:45){ HF_test.scores &lt;- rbind(HF_test.scores, as.data.frame(as.numeric(ConTempHRco2[i,-c(1:2,12:14)]) %*% PCA$loadings)) } \\(T^2\\) de Hotelling q10=mqcc(HF.scores[,1:2],newdata=HF_test.scores[,1:2],type = c(&quot;T2.single&quot;), pred.limits = TRUE) Se percibe que el proceso se empieza a descontrolar a partir de la observación 19 de la muestra de monitorizado. Pero si, como se debe, se observan los intervalos de predicción, no se detecta ninguna muestra fuera de control. PRECAUCIÓN: Cuando se reduce a pocas componentes principales, estamos obviando algunas direcciones en las que se producirían posibles desplazamientos hacia el fuera de control. El uso de MEWMA aplicado a las componentes principales retenidas disminuye considerablemente el ARL1: MEWMA # Muestra de calibrado: data.mqcd &lt;- mqcd(HF.scores[,1:2]) res.mqcs &lt;- mqcs.mewma(data.mqcd) summary(res.mqcs) ## ## Summary of group statistics: ## V1 ## Min. :1.668 ## 1st Qu.:2.326 ## Median :3.139 ## Mean :3.074 ## 3rd Qu.:3.716 ## Max. :4.335 ## ## Number of quality characteristics: 2 ## Number of samples or observations: 20 ## Number of observations or sample size: 1 ## ## Mean Vector: ## -1205.909 -3.945748 ## Covariance Matrix: ## V1 V2 ## [1,] 63380.407 -5008.645 ## [2,] -5008.645 1650.250 ## ## Control limits: ## lcl ucl ## 0.0000 8.6336 ## ## Number beyond limits: 0 plot(res.mqcs, title =&quot;MEWMA Control Chart for Water and Solids in Jet Fuel&quot;) # Muestra de monitorizado: data.mqcd.new &lt;- mqcd(HF_test.scores[,1:2]) # Se toman el vector de medias y la matriz de covarianzas de la muestra de calibrado Xmv=matrix(res.mqcs$mean,byrow=TRUE) S = data.frame(matrix(res.mqcs$S,byrow=FALSE,nc=2)) # Se calcula el nuevo gráfico con los límites obtenidos en la muestra de calibrado: res.mqcs.new &lt;- mqcs.mewma(data.mqcd.new,Xmv=Xmv,S=S) plot(res.mqcs.new, title =&quot; MEWMA Control Chart for Thermal confort and Air quality&quot;) names(res.mqcs.new);res.mqcs.new$violations ## [1] &quot;mqcd&quot; &quot;type&quot; &quot;statistics&quot; &quot;mean&quot; &quot;S&quot; ## [6] &quot;lambda&quot; &quot;limits&quot; &quot;data.name&quot; &quot;violations&quot; ## [1] 4 CONCLUSIÓN: Se identifica que el proceso está fuera de control en la 4ª observación de la muestra de monitorizado. 5.1.1.7 Reducción de dimensión: Mínimos cuadrados parciales (PLS). Misma utilidad que las compententes principales, pero con una ventaja fundamental: se expresan los vectores de características según nuevas componentes o variables, pero en la obtención de las mismas se ha tenido en cuenta la existencia de una matriz de variables independientes X y una variable respuesta Y. Los datos se proyectan en una nueva base conforme que tiene en cuenta la relación lineal entre Y y X. Ideal para el caso de tener muchas variables X, o parámetros, de los que depende la característica a controlar o variable respuesta Y. CASO PRÁCTICO: se pretende controlar la eficiencia energética de las instalaciones de climatización de una oficina a partir del consumo eléctrico. En el consumo eléctrico influyen parámetros de confort térmico y calidad del aire (de hecho, dicho consumo se produce para mantener unos estándares de calidad de estos últimos). Procedimiento library(pls) ## Warning: package &#39;pls&#39; was built under R version 3.6.1 ## ## Attaching package: &#39;pls&#39; ## The following object is masked from &#39;package:qualityTools&#39;: ## ## pcr ## The following object is masked from &#39;package:stats&#39;: ## ## loadings Muestra de calibrado (se escalan previamente las varibles regresoras). La función plsr proporciona una regresión por mínimos cuadrados parciales del consumo con respecto a las demás variables (temperaturas, HR, CO2) HF.pls &lt;- plsr(ConTempHRco2[1:20,12] ~ scale(ConTempHRco2[1:20,-c(1:2,12:14)]), ncomp = 9, validation = &quot;CV&quot;) # Muestra de monitorizado. Se proyectan las nuevas observaciones (vectores de características) en la nueva base: tst.scores=NULL for(i in 21:45){ Xtst &lt;- scale(ConTempHRco2[i,-c(1:2,12:14)], center = colMeans(ConTempHRco2[1:20,-c(1:2,12:14)]), scale = apply(ConTempHRco2[1:20,-c(1:2,12:14)],2,sd)) tst.scores &lt;- rbind(tst.scores,as.data.frame(Xtst %*% HF.pls$projection)) } T^2 de Hotelling qPLS=mqcc(scores(HF.pls)[,1:2],newdata=tst.scores[,1:2], type = c(&quot;T2&quot;),pred.limits = TRUE) Se percibe que el proceso se empieza a descontrolar a partir de la 6ª observación de la muestra de monitorizado. Mucho antes que empleando componentes principales Uso de MEWMA aplicado a las componentes PLS: MEWMA # Muestra de calibrado: data.mqcd &lt;- mqcd(scores(HF.pls)[,1:2]) res.mqcs &lt;- mqcs.mewma(data.mqcd) summary(res.mqcs) ## ## Summary of group statistics: ## V1 ## Min. :0.6024 ## 1st Qu.:2.1523 ## Median :2.6653 ## Mean :3.0572 ## 3rd Qu.:4.0983 ## Max. :7.6691 ## ## Number of quality characteristics: 2 ## Number of samples or observations: 20 ## Number of observations or sample size: 1 ## ## Mean Vector: ## -4.440892e-17 4.440892e-17 ## Covariance Matrix: ## Comp 1 Comp 2 ## [1,] 4.202442e+00 1.168656e-16 ## [2,] 1.168656e-16 1.295468e+00 ## ## Control limits: ## lcl ucl ## 0.0000 8.6336 ## ## Number beyond limits: 0 plot(res.mqcs, title =&quot; MEWMA Control Chart for Water and Solids in Jet Fuel&quot;) # Muestra de monitorizado: data.mqcd.new &lt;- mqcd(tst.scores[,1:2]) # Se toman el vector de medias y la matriz de covarianzas de la muestra de calibrado Xmv=matrix(res.mqcs$mean,byrow=TRUE) S = data.frame(matrix(res.mqcs$S,byrow=FALSE,nc=2)) # Se calcula el nuevo gráfico con los límites obtenidos en la muestra de calibrado: res.mqcs.new &lt;- mqcs.mewma(data.mqcd.new,Xmv=Xmv,S=S) plot(res.mqcs.new, title =&quot; MEWMA Control Chart for Thermal confort and Air quality&quot;) names(res.mqcs.new);res.mqcs.new$violations ## [1] &quot;mqcd&quot; &quot;type&quot; &quot;statistics&quot; &quot;mean&quot; &quot;S&quot; ## [6] &quot;lambda&quot; &quot;limits&quot; &quot;data.name&quot; &quot;violations&quot; ## [1] 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ## [24] 25 Nos damos cuenta del desplazamiento al fuera de control en la 2ª observación de la muestra de monitorizado (con PCA nos dábamos cuenta en la 4ª). 5.1.2 Control de Calidad de variables autocorreladas 5.1.2.1 Caso práctico: Control del confort climático en oficinas. DATOS: Variables de confort térmico, calidad del aire y consumo energético en horas de ocupación (11 horas) de una oficina. Medidas horarias de septiembre y octubre. MultivarianteOCUP=read.table(&quot;clima.txt&quot;,header=T) MultivarianteOCUP ## Fecha Hora TempFondo TempEntrada TempMedio CO2Fondo CO2Medio ## 1 09/01/2014 9:00 26.18 27.28 27.99 477.24 510.62 ## 2 09/01/2014 10:00 25.45 25.78 27.18 670.39 722.58 ## 3 09/01/2014 11:00 25.46 25.68 26.89 745.01 795.05 ## 4 09/01/2014 12:00 26.61 27.39 27.71 742.20 796.13 ## 5 09/01/2014 13:00 27.31 28.23 28.26 522.25 558.03 ## 6 09/01/2014 14:00 27.28 27.98 27.93 552.22 537.57 ## 7 09/01/2014 15:00 26.59 27.40 27.19 503.00 501.66 ## 8 09/01/2014 16:00 26.51 27.25 26.98 695.73 711.46 ## 9 09/01/2014 17:00 26.86 27.55 27.18 860.26 838.58 ## 10 09/01/2014 18:00 27.25 27.91 27.48 712.04 672.56 ## 11 09/01/2014 19:00 27.54 28.12 27.62 575.64 571.13 ## 12 09/02/2014 9:00 27.20 28.13 28.75 459.42 527.75 ## 13 09/02/2014 10:00 26.37 26.85 28.07 605.24 680.10 ## 14 09/02/2014 11:00 25.98 26.52 27.47 684.97 753.85 ## 15 09/02/2014 12:00 25.97 26.62 27.22 714.97 704.60 ## 16 09/02/2014 13:00 25.96 26.83 27.00 645.55 613.17 ## 17 09/02/2014 14:00 26.45 26.74 27.05 486.38 488.14 ## 18 09/02/2014 15:00 26.71 27.29 27.16 461.62 457.62 ## 19 09/02/2014 16:00 27.37 27.89 27.45 444.60 448.91 ## 20 09/02/2014 17:00 28.02 28.46 27.85 501.95 491.99 ## 21 09/02/2014 18:00 28.26 28.35 27.83 718.85 757.35 ## 22 09/02/2014 19:00 28.64 28.45 28.03 754.94 799.12 ## 23 09/03/2014 9:00 28.10 28.73 29.54 462.03 515.88 ## 24 09/03/2014 10:00 27.16 27.50 28.49 620.29 665.53 ## 25 09/03/2014 11:00 26.92 26.92 28.05 706.31 743.54 ## 26 09/03/2014 12:00 27.09 27.21 27.98 707.80 776.27 ## 27 09/03/2014 13:00 26.94 27.12 27.88 772.34 842.56 ## 28 09/03/2014 14:00 27.06 27.02 27.76 749.19 811.60 ## 29 09/03/2014 15:00 26.99 27.07 27.64 681.65 754.31 ## 30 09/03/2014 16:00 27.01 27.08 27.52 695.22 764.81 ## 31 09/03/2014 17:00 27.07 27.00 27.64 807.22 860.97 ## 32 09/03/2014 18:00 27.03 27.09 27.77 782.57 811.15 ## 33 09/03/2014 19:00 27.06 26.84 27.80 895.90 967.09 ## 34 09/04/2014 9:00 26.71 27.35 28.15 462.55 534.56 ## 35 09/04/2014 10:00 26.86 27.11 27.97 597.54 661.44 ## 36 09/04/2014 11:00 26.95 26.70 27.70 744.99 791.76 ## 37 09/04/2014 12:00 26.87 26.44 27.54 744.47 804.13 ## 38 09/04/2014 13:00 26.93 26.70 27.53 737.73 769.05 ## 39 09/04/2014 14:00 26.98 26.56 27.36 803.17 807.60 ## 40 09/04/2014 15:00 26.92 26.42 27.35 743.58 728.49 ## 41 09/04/2014 16:00 26.92 26.69 27.45 704.69 735.01 ## 42 09/04/2014 17:00 27.05 26.75 27.60 731.31 728.24 ## 43 09/04/2014 18:00 27.62 27.33 27.87 816.31 832.39 ## 44 09/04/2014 19:00 26.91 26.16 27.39 881.26 917.41 ## 45 09/05/2014 9:00 25.17 25.45 26.50 495.35 546.83 ## 46 09/05/2014 10:00 24.92 24.84 26.00 756.82 826.19 ## 47 09/05/2014 11:00 24.96 24.92 25.87 860.36 901.46 ## 48 09/05/2014 12:00 24.96 25.01 25.87 927.98 995.70 ## 49 09/05/2014 13:00 25.71 25.79 26.28 859.22 912.38 ## 50 09/05/2014 14:00 26.74 26.79 26.81 813.34 839.57 ## 51 09/05/2014 15:00 27.41 27.42 27.31 786.12 793.28 ## 52 09/05/2014 16:00 27.89 27.95 27.57 657.55 686.55 ## 53 09/05/2014 17:00 27.17 27.16 26.94 706.49 716.71 ## 54 09/05/2014 18:00 26.94 26.80 26.75 687.72 694.84 ## 55 09/05/2014 19:00 26.89 26.57 26.68 709.57 711.69 ## 56 09/08/2014 9:00 24.36 25.02 25.64 460.12 517.67 ## 57 09/08/2014 10:00 24.87 25.14 25.88 703.38 805.53 ## 58 09/08/2014 11:00 24.90 24.82 25.70 784.84 877.58 ## 59 09/08/2014 12:00 24.97 24.54 25.50 801.38 834.99 ## 60 09/08/2014 13:00 25.64 25.51 25.92 702.24 788.97 ## 61 09/08/2014 14:00 25.91 25.47 25.96 674.69 721.24 ## 62 09/08/2014 15:00 25.95 25.58 25.75 431.03 487.52 ## 63 09/08/2014 16:00 26.00 25.79 25.72 512.39 488.21 ## 64 09/08/2014 17:00 26.05 25.96 25.60 829.11 844.11 ## 65 09/08/2014 18:00 26.20 26.25 25.63 924.40 960.09 ## 66 09/08/2014 19:00 26.55 26.38 25.86 896.16 911.05 ## 67 09/09/2014 9:00 25.59 26.52 27.07 431.72 502.94 ## 68 09/09/2014 10:00 25.94 26.61 26.99 523.20 611.46 ## 69 09/09/2014 11:00 25.97 26.09 26.66 600.34 660.74 ## 70 09/09/2014 12:00 25.92 25.94 26.45 681.71 722.56 ## 71 09/09/2014 13:00 26.18 26.40 26.60 682.19 720.17 ## 72 09/09/2014 14:00 26.98 27.26 27.02 634.75 658.01 ## 73 09/09/2014 15:00 26.95 27.43 26.96 619.99 644.95 ## 74 09/09/2014 16:00 27.01 27.55 26.98 674.77 664.06 ## 75 09/09/2014 17:00 27.06 27.62 26.99 692.64 679.65 ## 76 09/09/2014 18:00 27.01 27.27 26.79 718.42 712.85 ## 77 09/09/2014 19:00 27.00 27.10 26.69 682.86 712.98 ## 78 09/10/2014 9:00 26.13 26.84 27.42 435.67 551.91 ## 79 09/10/2014 10:00 26.58 26.98 27.59 589.10 721.99 ## 80 09/10/2014 11:00 25.99 25.77 26.95 754.66 850.61 ## 81 09/10/2014 12:00 25.80 25.88 26.65 827.29 894.27 ## 82 09/10/2014 13:00 26.96 27.38 27.22 727.32 836.88 ## 83 09/10/2014 14:00 27.02 27.09 27.02 855.89 910.07 ## 84 09/10/2014 15:00 26.96 27.33 27.07 690.21 722.88 ## 85 09/10/2014 16:00 26.97 27.40 27.09 645.70 683.00 ## 86 09/10/2014 17:00 27.01 27.37 27.01 865.36 903.05 ## 87 09/10/2014 18:00 27.04 26.90 26.93 948.94 1033.97 ## 88 09/10/2014 19:00 27.14 27.37 27.12 952.38 1023.16 ## 89 09/11/2014 9:00 26.46 27.33 27.96 421.03 500.77 ## 90 09/11/2014 10:00 26.90 27.61 28.15 529.24 629.65 ## 91 09/11/2014 11:00 26.81 27.20 27.88 603.35 683.70 ## 92 09/11/2014 12:00 26.98 27.15 27.67 722.89 756.83 ## 93 09/11/2014 13:00 26.97 27.11 27.53 728.26 772.57 ## 94 09/11/2014 14:00 27.00 27.21 27.26 745.30 784.00 ## 95 09/11/2014 15:00 26.94 27.32 27.28 704.08 762.49 ## 96 09/11/2014 16:00 27.02 27.59 27.30 698.64 764.80 ## 97 09/11/2014 17:00 27.21 27.75 27.57 810.89 844.30 ## 98 09/11/2014 18:00 27.19 27.49 27.57 767.27 791.23 ## 99 09/11/2014 19:00 27.25 27.26 27.48 831.17 887.27 ## 100 09/12/2014 9:00 26.76 27.71 28.40 402.12 499.26 ## 101 09/12/2014 10:00 26.94 27.60 28.26 523.45 609.56 ## 102 09/12/2014 11:00 26.93 27.45 27.94 593.63 670.38 ## 103 09/12/2014 12:00 26.99 27.41 27.79 705.94 777.57 ## 104 09/12/2014 13:00 26.96 27.29 27.51 693.92 744.34 ## 105 09/12/2014 14:00 27.04 27.37 27.36 634.62 685.17 ## 106 09/12/2014 15:00 26.91 27.36 27.28 539.53 614.38 ## 107 09/12/2014 16:00 27.00 27.34 27.36 652.07 704.83 ## 108 09/12/2014 17:00 27.03 26.82 27.32 762.41 831.53 ## 109 09/12/2014 18:00 27.02 26.45 27.21 817.40 885.80 ## 110 09/12/2014 19:00 26.99 26.21 27.28 765.98 832.58 ## 111 15/09/2014 9:00 25.73 26.79 27.50 382.95 472.63 ## 112 15/09/2014 10:00 26.20 27.35 27.71 440.13 596.01 ## 113 15/09/2014 11:00 26.68 27.66 27.78 476.62 639.77 ## 114 15/09/2014 12:00 26.93 27.80 27.77 555.23 666.30 ## 115 15/09/2014 13:00 26.91 27.53 27.49 696.95 754.69 ## 116 15/09/2014 14:00 26.92 27.20 27.04 705.32 738.54 ## 117 15/09/2014 15:00 26.88 27.30 27.11 600.08 655.10 ## 118 15/09/2014 16:00 26.93 27.14 27.02 705.88 737.19 ## 119 15/09/2014 17:00 27.03 27.11 26.94 762.97 799.46 ## 120 15/09/2014 18:00 26.96 26.83 26.53 713.34 771.00 ## 121 15/09/2014 19:00 27.01 26.39 26.69 629.00 700.72 ## 122 16/09/2014 9:00 25.33 26.02 26.82 358.26 439.85 ## 123 16/09/2014 10:00 25.86 26.34 26.95 509.64 670.74 ## 124 16/09/2014 11:00 26.58 27.13 27.23 663.17 880.27 ## 125 16/09/2014 12:00 26.90 27.61 27.39 628.61 825.56 ## 126 16/09/2014 13:00 26.88 27.50 27.21 624.96 745.92 ## 127 16/09/2014 14:00 26.98 27.27 26.96 776.38 845.15 ## 128 16/09/2014 15:00 26.93 27.23 26.96 710.91 743.90 ## 129 16/09/2014 16:00 26.97 27.03 26.83 710.36 763.49 ## 130 16/09/2014 17:00 27.04 26.92 26.80 747.53 798.03 ## 131 16/09/2014 18:00 26.93 26.62 26.64 856.86 919.35 ## 132 16/09/2014 19:00 26.91 26.35 26.70 816.20 883.30 ## 133 17/09/2014 9:00 25.32 26.15 26.74 399.56 498.66 ## 134 17/09/2014 10:00 25.66 26.05 26.23 489.65 581.38 ## 135 17/09/2014 11:00 26.25 26.37 26.52 542.90 606.90 ## 136 17/09/2014 12:00 26.84 26.98 26.92 641.70 744.74 ## 137 17/09/2014 13:00 26.98 26.95 26.89 728.46 819.60 ## 138 17/09/2014 14:00 26.88 26.62 26.76 735.89 825.91 ## 139 17/09/2014 15:00 26.91 26.94 26.71 665.33 745.07 ## 140 17/09/2014 16:00 26.92 26.92 26.58 623.32 715.09 ## 141 17/09/2014 17:00 26.98 26.58 26.52 717.85 802.15 ## 142 17/09/2014 18:00 26.94 26.47 26.52 796.81 857.71 ## 143 17/09/2014 19:00 26.97 26.73 26.48 694.49 769.67 ## 144 18/09/2014 9:00 24.82 25.74 26.32 348.52 465.42 ## 145 18/09/2014 10:00 25.43 26.02 26.42 502.31 648.71 ## 146 18/09/2014 11:00 26.01 26.40 26.68 532.70 694.31 ## 147 18/09/2014 12:00 26.36 26.70 26.86 547.32 721.19 ## 148 18/09/2014 13:00 26.71 27.11 27.00 612.97 717.79 ## 149 18/09/2014 14:00 26.84 27.19 26.96 595.86 716.53 ## 150 18/09/2014 15:00 26.80 27.11 26.85 585.52 725.60 ## 151 18/09/2014 16:00 26.86 27.00 26.77 626.76 730.58 ## 152 18/09/2014 17:00 27.03 26.89 26.88 630.56 779.37 ## 153 18/09/2014 18:00 26.93 26.48 26.84 736.73 842.66 ## 154 18/09/2014 19:00 26.85 26.33 26.84 709.84 806.25 ## 155 19/09/2014 9:00 24.31 25.09 25.68 357.56 484.00 ## 156 19/09/2014 10:00 25.04 25.59 25.89 511.01 667.43 ## 157 19/09/2014 11:00 25.79 26.13 26.28 636.47 745.70 ## 158 19/09/2014 12:00 26.34 26.44 26.49 674.80 690.83 ## 159 19/09/2014 13:00 26.67 26.50 26.50 625.84 643.13 ## 160 19/09/2014 14:00 26.75 26.44 26.50 624.29 631.82 ## 161 19/09/2014 15:00 26.69 26.43 26.51 495.41 571.61 ## 162 19/09/2014 16:00 26.89 26.62 26.71 625.07 709.74 ## 163 19/09/2014 17:00 26.86 26.32 26.39 666.98 722.08 ## 164 19/09/2014 18:00 26.89 26.10 26.42 657.63 737.15 ## 165 19/09/2014 19:00 26.79 26.42 26.74 588.73 676.90 ## 166 22/09/2014 9:00 24.62 25.49 25.84 412.75 475.98 ## 167 22/09/2014 10:00 25.30 25.86 26.07 413.80 538.63 ## 168 22/09/2014 11:00 25.81 25.94 26.12 395.81 539.77 ## 169 22/09/2014 12:00 26.25 26.50 26.49 435.69 595.82 ## 170 22/09/2014 13:00 26.78 26.89 26.78 423.03 597.77 ## 171 22/09/2014 14:00 26.91 26.95 26.78 435.33 546.56 ## 172 22/09/2014 15:00 26.94 26.73 26.46 373.30 472.68 ## 173 22/09/2014 16:00 26.98 26.25 26.27 381.78 472.60 ## 174 22/09/2014 17:00 26.87 26.20 26.36 395.72 490.51 ## 175 22/09/2014 18:00 26.91 25.91 26.19 399.61 488.45 ## 176 22/09/2014 19:00 26.86 25.90 26.31 420.42 501.58 ## 177 23/09/2014 9:00 24.61 25.43 25.92 355.83 454.01 ## 178 23/09/2014 10:00 25.14 25.40 25.86 402.49 509.85 ## 179 23/09/2014 11:00 25.55 25.45 25.88 404.51 525.27 ## 180 23/09/2014 12:00 25.93 25.76 26.10 406.23 531.28 ## 181 23/09/2014 13:00 26.11 26.07 26.27 409.60 521.62 ## 182 23/09/2014 14:00 26.43 26.41 26.63 483.39 610.05 ## 183 23/09/2014 15:00 26.57 26.65 26.76 471.12 592.27 ## 184 23/09/2014 16:00 26.79 26.88 26.74 477.49 589.84 ## 185 23/09/2014 17:00 26.90 26.73 26.58 482.34 613.83 ## 186 23/09/2014 18:00 26.88 26.24 26.39 454.90 565.48 ## 187 23/09/2014 19:00 26.83 26.34 26.43 456.11 534.54 ## 188 24/09/2014 9:00 23.52 24.37 24.95 468.99 537.96 ## 189 24/09/2014 10:00 24.00 24.67 25.17 667.48 805.79 ## 190 24/09/2014 11:00 24.54 25.05 25.08 752.67 849.45 ## 191 24/09/2014 12:00 24.95 25.46 25.31 718.32 809.54 ## 192 24/09/2014 13:00 25.31 25.54 25.51 410.66 583.93 ## 193 24/09/2014 14:00 25.61 25.74 25.39 387.04 517.33 ## 194 24/09/2014 15:00 26.15 26.61 25.93 395.38 548.63 ## 195 24/09/2014 16:00 26.82 27.16 26.36 403.43 544.33 ## 196 24/09/2014 17:00 27.07 27.32 26.52 424.95 537.22 ## 197 24/09/2014 18:00 26.93 26.99 26.21 436.21 535.74 ## 198 24/09/2014 19:00 26.91 27.19 26.41 462.83 550.27 ## 199 25/09/2014 9:00 23.21 24.55 24.89 447.34 536.64 ## 200 25/09/2014 10:00 23.52 24.78 24.81 688.21 764.32 ## 201 25/09/2014 11:00 24.00 25.13 25.01 744.57 809.96 ## 202 25/09/2014 12:00 24.49 25.52 25.31 768.32 879.65 ## 203 25/09/2014 13:00 24.96 25.89 25.45 746.00 818.49 ## 204 25/09/2014 14:00 25.46 26.18 25.61 521.79 655.51 ## 205 25/09/2014 15:00 26.02 26.87 25.91 446.45 646.74 ## 206 25/09/2014 16:00 26.77 27.77 26.41 643.33 808.80 ## 207 25/09/2014 17:00 26.92 27.82 26.59 540.22 667.95 ## 208 25/09/2014 18:00 27.00 27.16 26.16 530.23 582.84 ## 209 25/09/2014 19:00 26.88 26.16 25.48 409.65 482.58 ## 210 26/09/2014 9:00 23.21 24.48 24.77 408.91 503.04 ## 211 26/09/2014 10:00 23.62 24.90 25.04 567.52 692.96 ## 212 26/09/2014 11:00 24.15 25.30 25.29 642.82 763.08 ## 213 26/09/2014 12:00 24.65 25.76 25.55 611.95 742.91 ## 214 26/09/2014 13:00 25.70 26.75 26.24 622.49 763.37 ## 215 26/09/2014 14:00 26.44 27.18 26.56 555.11 662.53 ## 216 26/09/2014 15:00 26.88 27.39 26.61 417.21 518.22 ## 217 26/09/2014 16:00 27.45 27.92 27.04 424.69 463.06 ## 218 26/09/2014 17:00 26.82 27.66 26.69 667.21 555.24 ## 219 26/09/2014 18:00 26.50 27.31 26.40 660.01 570.07 ## 220 26/09/2014 19:00 26.86 27.40 26.60 459.07 505.60 ## 221 29/09/2014 9:00 23.57 24.62 24.69 445.08 529.72 ## 222 29/09/2014 10:00 24.17 25.15 24.92 696.60 790.57 ## 223 29/09/2014 11:00 24.81 25.60 25.48 701.06 804.22 ## 224 29/09/2014 12:00 25.12 25.72 25.49 700.99 754.36 ## 225 29/09/2014 13:00 25.54 26.07 25.77 716.45 745.54 ## 226 29/09/2014 14:00 25.88 26.45 25.92 700.18 720.52 ## 227 29/09/2014 15:00 25.91 26.71 25.93 618.18 669.80 ## 228 29/09/2014 16:00 26.00 26.95 26.00 603.54 684.47 ## 229 29/09/2014 17:00 25.98 26.45 25.80 759.27 757.98 ## 230 29/09/2014 18:00 26.02 26.65 25.94 795.22 763.14 ## 231 29/09/2014 19:00 25.98 26.38 25.81 840.45 802.63 ## 232 30/09/2014 9:00 23.46 24.64 24.88 492.39 538.25 ## 233 30/09/2014 10:00 23.89 25.00 25.05 666.35 704.79 ## 234 30/09/2014 11:00 24.34 25.43 25.40 714.81 781.27 ## 235 30/09/2014 12:00 24.82 25.79 25.50 715.07 776.53 ## 236 30/09/2014 13:00 25.34 26.11 25.64 728.49 771.66 ## 237 30/09/2014 14:00 25.88 26.49 26.00 532.66 664.55 ## 238 30/09/2014 15:00 25.91 26.82 25.87 551.24 619.00 ## 239 30/09/2014 16:00 25.93 26.98 25.77 618.94 610.72 ## 240 30/09/2014 17:00 25.93 27.04 25.84 702.94 715.24 ## 241 30/09/2014 18:00 25.99 26.82 25.96 786.66 747.95 ## 242 30/09/2014 19:00 25.92 26.51 25.91 682.04 670.89 ## 243 10/01/2014 9:00 23.93 24.95 24.70 744.16 814.27 ## 244 10/01/2014 10:00 24.40 25.34 25.08 737.65 863.61 ## 245 10/01/2014 11:00 24.92 25.71 25.50 792.33 895.48 ## 246 10/01/2014 12:00 25.48 26.01 25.73 779.67 866.63 ## 247 10/01/2014 13:00 25.90 26.44 25.86 750.83 806.07 ## 248 10/01/2014 14:00 25.92 26.96 25.89 622.20 699.21 ## 249 10/01/2014 15:00 26.07 27.11 25.93 720.24 732.66 ## 250 10/01/2014 16:00 25.95 26.86 25.64 625.87 633.75 ## 251 10/01/2014 17:00 26.23 27.09 26.08 523.47 510.53 ## 252 10/01/2014 18:00 26.45 26.92 26.08 430.88 467.99 ## 253 10/01/2014 19:00 27.41 27.36 26.56 387.61 453.31 ## 254 10/02/2014 9:00 24.45 25.38 25.61 652.09 767.06 ## 255 10/02/2014 10:00 24.91 25.91 26.03 643.10 768.55 ## 256 10/02/2014 11:00 25.30 26.45 26.22 559.84 722.13 ## 257 10/02/2014 12:00 25.84 26.78 26.35 620.44 713.97 ## 258 10/02/2014 13:00 25.95 26.54 26.04 544.60 580.42 ## 259 10/02/2014 14:00 25.93 26.75 25.92 474.85 494.86 ## 260 10/02/2014 15:00 26.09 27.06 26.10 543.17 502.94 ## 261 10/02/2014 16:00 26.14 27.10 26.09 664.82 530.26 ## 262 10/02/2014 17:00 26.39 27.21 26.16 726.85 570.75 ## 263 10/02/2014 18:00 26.38 27.08 26.21 585.38 545.06 ## 264 10/02/2014 19:00 26.41 27.08 26.29 470.64 480.15 ## 265 10/03/2014 9:00 24.94 25.88 26.16 644.37 802.34 ## 266 10/03/2014 10:00 25.54 26.41 26.26 777.52 878.68 ## 267 10/03/2014 11:00 25.98 26.93 26.52 741.85 880.97 ## 268 10/03/2014 12:00 25.92 26.55 26.29 849.57 835.74 ## 269 10/03/2014 13:00 25.93 26.61 26.04 705.21 729.57 ## 270 10/03/2014 14:00 26.02 26.97 26.13 592.21 631.99 ## 271 10/03/2014 15:00 26.10 27.07 26.25 666.00 652.38 ## 272 10/03/2014 16:00 26.21 27.12 26.26 804.34 787.18 ## 273 10/03/2014 17:00 26.39 27.02 26.18 881.72 882.16 ## 274 10/03/2014 18:00 26.02 26.47 25.94 705.07 750.46 ## 275 10/03/2014 19:00 25.93 26.46 26.08 496.97 571.05 ## 276 10/06/2014 9:00 23.10 23.75 23.53 668.53 709.99 ## 277 10/06/2014 10:00 23.72 24.11 23.81 713.79 738.28 ## 278 10/06/2014 11:00 24.15 24.40 24.01 700.82 721.22 ## 279 10/06/2014 12:00 24.44 24.62 24.17 655.26 697.64 ## 280 10/06/2014 13:00 24.75 24.83 24.47 649.95 715.72 ## 281 10/06/2014 14:00 24.83 24.95 24.69 566.41 664.44 ## 282 10/06/2014 15:00 24.82 24.60 24.47 578.71 644.75 ## 283 10/06/2014 16:00 24.98 24.46 24.50 563.11 667.39 ## 284 10/06/2014 17:00 25.08 24.64 24.60 585.62 631.30 ## 285 10/06/2014 18:00 25.18 25.03 24.89 588.46 632.13 ## 286 10/06/2014 19:00 24.84 25.05 24.90 468.85 536.71 ## 287 10/07/2014 9:00 22.68 23.16 22.94 638.99 702.64 ## 288 10/07/2014 10:00 23.25 23.55 23.18 693.25 765.72 ## 289 10/07/2014 11:00 23.79 23.95 23.59 708.52 805.71 ## 290 10/07/2014 12:00 24.41 24.43 24.15 773.01 862.70 ## 291 10/07/2014 13:00 24.78 24.64 24.38 780.81 876.63 ## 292 10/07/2014 14:00 24.79 24.57 24.12 593.88 601.25 ## 293 10/07/2014 15:00 24.94 24.80 24.38 599.35 690.57 ## 294 10/07/2014 16:00 25.26 25.09 24.70 676.27 749.77 ## 295 10/07/2014 17:00 25.61 25.20 25.02 735.54 824.16 ## 296 10/07/2014 18:00 25.67 25.23 25.16 745.34 787.08 ## 297 10/07/2014 19:00 25.18 25.14 25.04 605.12 676.59 ## 298 10/08/2014 9:00 23.51 23.80 24.01 597.84 691.58 ## 299 10/08/2014 10:00 24.16 24.11 24.16 769.70 847.23 ## 300 10/08/2014 11:00 24.63 24.39 24.39 732.68 842.39 ## 301 10/08/2014 12:00 24.86 24.54 24.55 708.09 794.89 ## 302 10/08/2014 13:00 25.05 24.69 24.86 725.24 830.83 ## 303 10/08/2014 14:00 24.91 24.67 24.55 640.60 775.60 ## 304 10/08/2014 15:00 24.86 24.68 24.42 610.54 740.51 ## 305 10/08/2014 16:00 25.05 24.94 24.74 691.26 812.93 ## 306 10/08/2014 17:00 25.20 25.08 25.04 731.54 784.25 ## 307 10/08/2014 18:00 25.08 24.98 24.95 659.93 708.77 ## 308 10/08/2014 19:00 24.52 24.71 24.78 493.39 593.23 ## 309 10/09/2014 9:00 22.14 22.64 22.57 656.68 723.25 ## 310 10/09/2014 10:00 22.81 23.08 23.18 722.59 780.44 ## 311 10/09/2014 11:00 23.18 23.30 23.30 737.91 824.48 ## 312 10/09/2014 12:00 23.66 23.70 23.72 810.26 866.82 ## 313 10/09/2014 13:00 23.91 23.84 23.77 768.27 792.81 ## 314 10/09/2014 14:00 23.84 23.91 23.71 673.50 759.85 ## 315 10/09/2014 15:00 24.31 24.68 24.04 740.71 786.78 ## 316 10/09/2014 16:00 24.86 25.48 24.71 564.47 734.21 ## 317 10/09/2014 17:00 24.97 25.18 24.68 624.03 790.39 ## 318 10/09/2014 18:00 24.66 24.82 24.54 609.89 689.93 ## 319 10/09/2014 19:00 24.22 24.54 24.30 491.05 567.70 ## 320 10/10/2014 9:00 21.51 22.31 22.44 581.57 681.56 ## 321 10/10/2014 10:00 22.02 22.83 22.87 727.97 829.87 ## 322 10/10/2014 11:00 22.68 23.21 23.07 832.81 886.63 ## 323 10/10/2014 12:00 23.37 23.79 22.94 821.65 953.03 ## 324 10/10/2014 13:00 24.06 24.38 22.75 851.89 962.75 ## 325 10/10/2014 14:00 24.25 24.41 22.76 637.77 778.18 ## 326 10/10/2014 15:00 24.34 24.47 22.85 543.51 684.75 ## 327 10/10/2014 16:00 25.03 25.23 23.49 780.19 919.88 ## 328 10/10/2014 17:00 25.40 25.18 23.80 771.33 848.91 ## 329 10/10/2014 18:00 25.08 24.85 23.80 634.76 667.28 ## 330 10/10/2014 19:00 24.53 24.55 23.46 561.90 600.03 ## 331 13/10/2014 9:00 21.65 22.04 21.21 636.87 832.73 ## 332 13/10/2014 10:00 22.29 22.51 21.62 840.42 1040.71 ## 333 13/10/2014 11:00 22.80 23.02 22.01 774.54 1004.19 ## 334 13/10/2014 12:00 23.18 23.20 22.06 925.70 982.69 ## 335 13/10/2014 13:00 23.58 23.47 22.33 763.66 929.14 ## 336 13/10/2014 14:00 23.56 23.62 22.41 673.66 844.20 ## 337 13/10/2014 15:00 23.70 23.66 22.43 763.69 953.32 ## 338 13/10/2014 16:00 24.08 23.82 22.68 801.92 1006.38 ## 339 13/10/2014 17:00 24.23 23.97 22.92 600.64 732.70 ## 340 13/10/2014 18:00 24.16 23.71 22.87 627.31 667.50 ## 341 13/10/2014 19:00 23.64 23.62 22.76 690.92 771.35 ## 342 14/10/2014 9:00 22.06 22.56 21.41 744.09 759.06 ## 343 14/10/2014 10:00 22.93 23.22 22.12 713.65 828.47 ## 344 14/10/2014 11:00 23.18 23.35 22.20 701.28 875.40 ## 345 14/10/2014 12:00 23.31 23.18 21.87 889.95 929.41 ## 346 14/10/2014 13:00 23.55 23.52 21.78 830.12 835.79 ## 347 14/10/2014 14:00 23.72 23.99 21.93 641.08 721.31 ## 348 14/10/2014 15:00 24.14 24.34 22.32 689.82 726.23 ## 349 14/10/2014 16:00 24.65 24.76 22.75 687.96 741.54 ## 350 14/10/2014 17:00 25.22 25.20 23.18 799.97 847.24 ## 351 14/10/2014 18:00 25.27 24.83 23.21 714.29 808.84 ## 352 14/10/2014 19:00 24.64 24.19 23.04 510.65 635.16 ## 353 15/10/2014 9:00 23.92 24.31 23.41 468.04 599.76 ## 354 15/10/2014 10:00 24.27 24.47 23.44 617.11 803.77 ## 355 15/10/2014 11:00 24.66 24.60 23.55 673.62 882.90 ## 356 15/10/2014 12:00 25.00 24.61 23.57 812.06 977.93 ## 357 15/10/2014 13:00 25.18 24.67 23.69 685.55 847.11 ## 358 15/10/2014 14:00 25.21 24.93 23.90 610.46 763.63 ## 359 15/10/2014 15:00 25.60 25.32 23.91 765.47 920.08 ## 360 15/10/2014 16:00 25.99 25.48 24.09 821.61 978.99 ## 361 15/10/2014 17:00 26.06 25.47 24.09 693.57 836.27 ## 362 15/10/2014 18:00 26.15 25.70 24.44 677.77 772.19 ## 363 15/10/2014 19:00 25.58 25.25 24.38 536.04 686.81 ## 364 16/10/2014 9:00 24.16 24.55 23.73 513.43 713.81 ## 365 16/10/2014 10:00 24.53 24.75 23.88 573.06 767.39 ## 366 16/10/2014 11:00 24.74 24.82 23.86 582.59 775.38 ## 367 16/10/2014 12:00 25.02 24.87 23.86 761.46 912.74 ## 368 16/10/2014 13:00 25.20 25.05 24.10 525.31 702.53 ## 369 16/10/2014 14:00 25.03 24.98 23.97 522.03 650.52 ## 370 16/10/2014 15:00 25.14 25.08 24.06 568.75 771.32 ## 371 16/10/2014 16:00 25.36 25.11 24.23 552.40 720.67 ## 372 16/10/2014 17:00 25.33 25.03 24.10 791.88 854.17 ## 373 16/10/2014 18:00 25.35 25.31 24.25 647.54 840.62 ## 374 16/10/2014 19:00 25.01 25.24 24.06 657.51 799.35 ## 375 17/10/2014 9:00 24.63 25.14 23.98 526.87 618.74 ## 376 17/10/2014 10:00 24.88 24.83 23.79 738.25 840.80 ## 377 17/10/2014 11:00 25.09 24.95 23.83 811.77 887.59 ## 378 17/10/2014 12:00 25.49 25.32 24.09 745.07 836.90 ## 379 17/10/2014 13:00 25.84 25.74 24.29 669.69 767.97 ## 380 17/10/2014 14:00 25.94 25.96 24.30 692.61 723.80 ## 381 17/10/2014 15:00 26.32 26.43 24.48 693.11 723.96 ## 382 17/10/2014 16:00 26.57 26.55 24.62 716.40 740.97 ## 383 17/10/2014 17:00 27.07 26.96 25.03 693.01 661.30 ## 384 17/10/2014 18:00 27.39 27.34 25.39 662.25 660.88 ## 385 17/10/2014 19:00 27.05 27.04 25.31 505.95 568.98 ## 386 20/10/2014 9:00 24.79 25.45 24.56 598.55 719.41 ## 387 20/10/2014 10:00 25.14 25.50 24.56 660.62 834.41 ## 388 20/10/2014 11:00 25.54 25.73 24.64 752.64 911.09 ## 389 20/10/2014 12:00 26.06 26.10 24.93 778.25 859.01 ## 390 20/10/2014 13:00 26.42 26.47 25.13 750.10 760.48 ## 391 20/10/2014 14:00 26.81 27.28 25.47 676.60 727.36 ## 392 20/10/2014 15:00 27.25 27.96 25.91 709.63 726.74 ## 393 20/10/2014 16:00 26.60 27.17 25.32 924.57 811.40 ## 394 20/10/2014 17:00 26.09 25.92 24.64 1066.50 1039.36 ## 395 20/10/2014 18:00 25.85 25.47 24.57 945.01 950.07 ## 396 20/10/2014 19:00 25.86 25.90 24.84 775.53 803.87 ## 397 21/10/2014 9:00 25.44 26.04 24.99 801.18 888.49 ## 398 21/10/2014 10:00 25.76 26.22 25.03 934.63 980.24 ## 399 21/10/2014 11:00 26.05 26.47 25.23 945.06 1010.10 ## 400 21/10/2014 12:00 26.21 26.71 25.32 942.55 1023.32 ## 401 21/10/2014 13:00 25.90 26.31 24.87 964.68 981.07 ## 402 21/10/2014 14:00 25.91 26.30 24.93 755.20 855.81 ## 403 21/10/2014 15:00 25.79 26.10 24.81 727.79 800.16 ## 404 21/10/2014 16:00 26.03 25.91 24.77 889.56 1036.29 ## 405 21/10/2014 17:00 26.62 26.56 25.32 924.02 1024.22 ## 406 21/10/2014 18:00 26.60 26.58 25.45 799.89 850.05 ## 407 21/10/2014 19:00 26.16 26.50 25.39 665.98 741.83 ## 408 22/10/2014 9:00 23.56 24.26 23.34 723.51 759.61 ## 409 22/10/2014 10:00 24.00 24.56 23.47 776.57 785.34 ## 410 22/10/2014 11:00 24.45 24.96 23.96 754.37 829.78 ## 411 22/10/2014 12:00 24.96 25.50 24.36 800.60 893.59 ## 412 22/10/2014 13:00 25.55 26.35 24.77 704.13 896.90 ## 413 22/10/2014 14:00 26.17 27.29 25.27 787.68 949.38 ## 414 22/10/2014 15:00 26.55 27.66 25.49 883.86 919.14 ## 415 22/10/2014 16:00 25.99 26.97 24.97 1027.58 875.94 ## 416 22/10/2014 17:00 25.89 26.81 24.85 877.08 749.78 ## 417 22/10/2014 18:00 25.85 26.43 24.66 863.15 803.70 ## 418 22/10/2014 19:00 25.38 25.41 24.33 760.16 794.23 ## 419 23/10/2014 9:00 24.59 25.66 24.44 718.43 757.25 ## 420 23/10/2014 10:00 24.74 25.76 24.57 736.28 824.72 ## 421 23/10/2014 11:00 25.06 26.01 24.63 816.13 913.29 ## 422 23/10/2014 12:00 25.50 26.47 24.90 773.04 920.98 ## 423 23/10/2014 13:00 25.91 27.06 25.20 727.23 924.83 ## 424 23/10/2014 14:00 25.09 26.49 24.67 834.21 848.58 ## 425 23/10/2014 15:00 24.97 26.50 24.52 859.75 796.44 ## 426 23/10/2014 16:00 25.02 26.42 24.43 884.69 797.61 ## 427 23/10/2014 17:00 25.17 26.24 24.31 1004.44 866.39 ## 428 23/10/2014 18:00 25.01 25.58 24.10 1062.64 1011.79 ## 429 23/10/2014 19:00 24.95 25.34 24.22 914.16 865.98 ## 430 24/10/2014 9:00 24.81 25.44 24.48 768.22 785.00 ## 431 24/10/2014 10:00 25.30 25.57 24.66 864.21 850.36 ## 432 24/10/2014 11:00 25.70 25.93 25.06 853.79 882.05 ## 433 24/10/2014 12:00 26.14 26.62 25.42 676.04 899.61 ## 434 24/10/2014 13:00 26.30 26.90 25.52 848.17 951.99 ## 435 24/10/2014 14:00 25.32 25.76 24.68 937.37 938.16 ## 436 24/10/2014 15:00 25.13 25.49 24.33 1028.93 994.33 ## 437 24/10/2014 16:00 24.94 24.69 24.08 1110.75 1087.90 ## 438 24/10/2014 17:00 24.86 24.59 24.05 939.68 942.31 ## 439 24/10/2014 18:00 24.97 25.20 24.28 664.25 640.04 ## 440 24/10/2014 19:00 25.20 25.50 24.58 532.03 549.08 ## 441 27/10/2014 9:00 23.82 25.11 23.88 622.65 706.11 ## 442 27/10/2014 10:00 24.50 25.54 24.12 731.27 783.43 ## 443 27/10/2014 11:00 25.01 26.05 24.40 769.85 766.12 ## 444 27/10/2014 12:00 25.71 26.72 24.82 681.68 741.17 ## 445 27/10/2014 13:00 26.48 27.24 25.10 692.85 605.22 ## 446 27/10/2014 14:00 26.99 27.72 25.42 528.84 559.89 ## 447 27/10/2014 15:00 26.51 27.17 24.69 698.27 761.72 ## 448 27/10/2014 16:00 26.30 26.84 24.73 784.44 767.96 ## 449 27/10/2014 17:00 26.21 26.22 24.73 863.56 810.90 ## 450 27/10/2014 18:00 26.56 26.61 25.13 836.23 826.02 ## 451 27/10/2014 19:00 26.50 26.80 25.38 604.66 662.92 ## 452 28/10/2014 9:00 25.58 26.36 25.23 615.95 689.41 ## 453 28/10/2014 10:00 25.96 26.57 25.45 708.54 697.75 ## 454 28/10/2014 11:00 26.47 27.08 25.83 628.43 711.67 ## 455 28/10/2014 12:00 26.99 27.58 26.06 752.10 846.48 ## 456 28/10/2014 13:00 27.64 28.39 26.57 664.05 815.05 ## 457 28/10/2014 14:00 26.72 27.98 26.08 819.27 805.78 ## 458 28/10/2014 15:00 26.20 27.42 25.59 868.70 841.85 ## 459 28/10/2014 16:00 26.09 27.10 25.51 952.77 895.25 ## 460 28/10/2014 17:00 26.06 26.81 25.32 986.21 994.19 ## 461 28/10/2014 18:00 25.74 25.66 24.92 827.47 864.26 ## 462 28/10/2014 19:00 25.01 24.90 24.56 677.21 684.16 ## 463 29/10/2014 9:00 24.87 25.92 24.83 690.98 807.93 ## 464 29/10/2014 10:00 24.93 25.93 24.70 835.00 870.31 ## 465 29/10/2014 11:00 24.89 25.78 24.58 761.79 795.12 ## 466 29/10/2014 12:00 24.86 25.80 24.54 681.34 734.59 ## 467 29/10/2014 13:00 24.94 25.76 24.37 779.30 770.72 ## 468 29/10/2014 14:00 25.37 26.27 24.65 548.35 646.09 ## 469 29/10/2014 15:00 25.94 27.17 25.09 760.11 736.29 ## 470 29/10/2014 16:00 25.96 27.01 24.99 1006.56 982.25 ## 471 29/10/2014 17:00 25.95 26.78 24.93 985.89 977.66 ## 472 29/10/2014 18:00 25.90 26.13 24.79 893.49 881.29 ## 473 29/10/2014 19:00 25.80 26.10 24.90 713.71 700.45 ## 474 30/10/2014 9:00 24.24 25.61 24.44 455.04 588.82 ## 475 30/10/2014 10:00 24.84 26.01 24.66 487.32 652.66 ## 476 30/10/2014 11:00 25.45 26.38 24.94 469.05 693.10 ## 477 30/10/2014 12:00 25.89 27.03 25.21 611.61 742.06 ## 478 30/10/2014 13:00 25.93 27.13 24.95 734.41 739.92 ## 479 30/10/2014 14:00 25.93 27.15 24.86 672.60 699.83 ## 480 30/10/2014 15:00 25.99 27.15 24.85 686.27 687.26 ## 481 30/10/2014 16:00 26.06 27.20 24.94 852.44 741.88 ## 482 30/10/2014 17:00 26.23 27.11 25.02 871.33 744.91 ## 483 30/10/2014 18:00 25.96 26.25 24.74 887.57 806.26 ## 484 30/10/2014 19:00 25.84 26.12 24.79 665.63 641.16 ## 485 31/10/2014 9:00 24.92 26.12 24.75 483.44 625.91 ## 486 31/10/2014 10:00 25.52 26.37 24.96 567.20 663.20 ## 487 31/10/2014 11:00 25.82 26.55 25.10 552.10 634.21 ## 488 31/10/2014 12:00 25.99 26.53 24.89 672.34 674.37 ## 489 31/10/2014 13:00 25.94 26.27 24.60 662.86 698.94 ## 490 31/10/2014 14:00 26.02 26.29 24.70 609.13 646.39 ## 491 31/10/2014 15:00 26.67 26.81 25.12 713.15 805.97 ## 492 31/10/2014 16:00 27.00 27.04 25.58 765.64 790.40 ## 493 31/10/2014 17:00 27.20 27.02 25.87 734.95 770.48 ## 494 31/10/2014 18:00 26.69 26.73 25.72 666.46 706.30 ## 495 31/10/2014 19:00 26.01 26.36 25.41 522.27 597.42 ## CO2Entrada HRFondo HRMedio HREntrada ConsumoUE03 Dia TipoDia ## 1 407.26 50.98 49.88 48.95 1.24 Lunes Laborable ## 2 577.23 46.53 47.41 47.34 3.56 Lunes Laborable ## 3 671.41 46.45 47.80 47.81 1.39 Lunes Laborable ## 4 675.12 50.53 51.00 50.29 0.30 Lunes Laborable ## 5 544.34 51.37 53.00 49.86 0.30 Lunes Laborable ## 6 497.89 47.95 53.52 48.44 3.39 Lunes Laborable ## 7 427.63 45.76 53.53 47.73 8.00 Lunes Laborable ## 8 583.40 43.22 48.71 45.02 4.40 Lunes Laborable ## 9 729.81 41.69 49.16 44.28 4.30 Lunes Laborable ## 10 612.39 42.45 53.15 45.83 4.24 Lunes Laborable ## 11 475.96 43.39 53.85 46.56 4.10 Lunes Laborable ## 12 408.26 51.34 50.48 49.26 1.27 Martes Laborable ## 13 556.32 44.82 47.23 46.44 3.82 Martes Laborable ## 14 671.53 43.21 48.30 45.65 3.24 Martes Laborable ## 15 652.39 43.30 50.68 46.17 4.80 Martes Laborable ## 16 591.06 45.54 52.83 47.58 9.00 Martes Laborable ## 17 441.74 51.70 55.51 50.38 4.35 Martes Laborable ## 18 380.49 48.81 58.80 51.29 4.41 Martes Laborable ## 19 365.28 50.59 59.87 52.59 4.80 Martes Laborable ## 20 421.10 46.40 57.97 50.23 4.90 Martes Laborable ## 21 624.45 40.13 48.72 43.96 4.45 Martes Laborable ## 22 661.43 40.57 47.90 44.49 4.39 Martes Laborable ## 23 410.21 50.22 50.19 49.24 1.26 Miércoles Laborable ## 24 559.16 44.94 47.16 46.68 3.14 Miércoles Laborable ## 25 579.81 47.35 48.90 49.12 2.54 Miércoles Laborable ## 26 625.11 49.94 50.98 50.40 1.95 Miércoles Laborable ## 27 684.38 47.22 49.29 48.65 2.12 Miércoles Laborable ## 28 657.95 46.98 49.56 48.80 2.60 Miércoles Laborable ## 29 614.13 47.04 49.74 48.88 2.51 Miércoles Laborable ## 30 606.81 46.71 49.33 48.04 2.88 Miércoles Laborable ## 31 708.67 45.51 49.17 48.10 2.00 Miércoles Laborable ## 32 718.64 44.83 49.96 47.68 2.75 Miércoles Laborable ## 33 805.66 45.11 49.38 48.32 2.38 Miércoles Laborable ## 34 406.35 55.81 53.67 53.09 0.13 Jueves Laborable ## 35 512.57 54.95 53.78 53.87 1.29 Jueves Laborable ## 36 602.93 55.45 54.46 54.30 1.19 Jueves Laborable ## 37 605.73 53.03 53.25 53.20 1.43 Jueves Laborable ## 38 601.98 52.21 53.28 52.80 1.57 Jueves Laborable ## 39 637.82 51.04 52.79 51.96 2.20 Jueves Laborable ## 40 547.41 49.41 52.39 52.20 1.28 Jueves Laborable ## 41 599.09 47.98 51.76 51.09 1.69 Jueves Laborable ## 42 634.11 48.02 51.98 51.07 1.17 Jueves Laborable ## 43 741.82 47.99 51.63 50.63 1.35 Jueves Laborable ## 44 774.29 44.51 48.50 48.12 3.82 Jueves Laborable ## 45 394.73 55.25 52.62 52.03 1.16 Viernes Laborable ## 46 673.91 53.20 52.37 52.44 5.00 Viernes Laborable ## 47 765.91 51.58 51.62 51.17 2.52 Viernes Laborable ## 48 832.10 51.35 51.61 51.02 2.51 Viernes Laborable ## 49 780.90 52.14 53.08 51.40 0.12 Viernes Laborable ## 50 585.53 49.26 53.88 51.55 0.30 Viernes Laborable ## 51 520.81 49.26 53.75 51.39 0.30 Viernes Laborable ## 52 479.30 48.74 53.15 49.67 1.15 Viernes Laborable ## 53 540.02 43.66 49.23 46.13 3.83 Viernes Laborable ## 54 540.41 42.74 49.17 46.04 3.94 Viernes Laborable ## 55 541.04 42.17 48.65 45.71 3.66 Viernes Laborable ## 56 395.08 61.71 56.72 55.50 0.14 Lunes Laborable ## 57 626.34 60.10 56.90 55.71 0.92 Lunes Laborable ## 58 715.17 58.87 56.19 55.89 1.60 Lunes Laborable ## 59 669.84 58.45 56.62 56.36 1.48 Lunes Laborable ## 60 663.02 60.73 59.43 58.35 0.27 Lunes Laborable ## 61 590.80 54.25 56.40 53.50 2.92 Lunes Laborable ## 62 368.06 60.92 61.64 57.89 1.88 Lunes Laborable ## 63 416.69 56.49 60.37 54.93 7.00 Lunes Laborable ## 64 756.17 48.97 53.91 49.39 3.86 Lunes Laborable ## 65 843.53 47.09 51.67 47.65 3.90 Lunes Laborable ## 66 802.39 44.95 51.38 47.18 3.93 Lunes Laborable ## 67 385.80 58.70 55.39 54.27 0.13 Martes Laborable ## 68 541.79 57.24 55.22 54.22 1.35 Martes Laborable ## 69 581.05 56.59 54.90 54.33 1.73 Martes Laborable ## 70 618.32 54.08 54.52 53.13 2.70 Martes Laborable ## 71 648.45 54.88 56.56 54.20 1.15 Martes Laborable ## 72 575.81 54.17 57.61 53.39 1.55 Martes Laborable ## 73 517.24 53.09 57.08 52.89 2.70 Martes Laborable ## 74 561.78 49.92 54.71 49.57 3.35 Martes Laborable ## 75 557.74 47.53 52.70 48.46 3.47 Martes Laborable ## 76 575.39 47.43 52.28 49.15 3.30 Martes Laborable ## 77 583.60 45.94 51.07 47.91 2.00 Martes Laborable ## 78 437.37 56.80 54.35 53.24 0.14 Miércoles Laborable ## 79 613.50 53.67 53.46 51.98 1.88 Miércoles Laborable ## 80 702.32 46.38 49.68 48.29 3.87 Miércoles Laborable ## 81 783.55 49.35 52.00 50.22 9.00 Miércoles Laborable ## 82 720.66 52.70 54.19 51.47 1.31 Miércoles Laborable ## 83 772.30 50.67 53.44 50.58 2.38 Miércoles Laborable ## 84 644.11 50.13 53.51 49.76 2.86 Miércoles Laborable ## 85 576.24 48.05 52.60 48.50 6.00 Miércoles Laborable ## 86 819.75 45.60 50.64 46.98 3.13 Miércoles Laborable ## 87 883.53 45.09 49.82 47.27 3.11 Miércoles Laborable ## 88 886.99 41.12 48.07 44.67 3.87 Miércoles Laborable ## 89 394.36 52.97 51.98 50.87 0.14 Jueves Laborable ## 90 549.60 53.44 52.48 51.33 1.39 Jueves Laborable ## 91 580.29 52.31 52.00 51.38 7.00 Jueves Laborable ## 92 625.26 53.47 53.50 52.60 1.60 Jueves Laborable ## 93 618.50 50.68 52.86 51.40 1.75 Jueves Laborable ## 94 637.23 49.43 51.80 49.70 3.00 Jueves Laborable ## 95 629.80 47.90 51.64 49.19 2.39 Jueves Laborable ## 96 617.70 47.40 51.06 48.27 2.85 Jueves Laborable ## 97 720.04 42.63 48.40 44.83 3.68 Jueves Laborable ## 98 682.88 42.03 49.06 45.57 3.90 Jueves Laborable ## 99 721.84 40.31 46.43 43.96 3.89 Jueves Laborable ## 100 372.81 55.48 52.74 51.59 0.13 Viernes Laborable ## 101 495.25 54.11 52.16 51.58 1.58 Viernes Laborable ## 102 549.76 51.74 52.12 51.22 1.39 Viernes Laborable ## 103 632.69 51.97 52.43 50.83 1.98 Viernes Laborable ## 104 542.71 51.48 52.53 51.11 1.76 Viernes Laborable ## 105 494.65 52.35 53.21 51.43 2.24 Viernes Laborable ## 106 420.88 53.72 53.84 51.78 1.68 Viernes Laborable ## 107 518.09 51.65 52.66 50.54 8.00 Viernes Laborable ## 108 649.98 48.06 50.76 49.15 2.88 Viernes Laborable ## 109 702.18 47.46 50.38 49.31 2.68 Viernes Laborable ## 110 651.65 49.22 51.10 50.62 2.30 Viernes Laborable ## 111 366.49 56.43 53.15 52.19 0.14 Lunes Laborable ## 112 528.31 53.49 52.81 51.63 0.27 Lunes Laborable ## 113 573.57 52.63 53.09 51.49 0.27 Lunes Laborable ## 114 589.93 53.02 53.50 51.35 0.85 Lunes Laborable ## 115 594.79 53.91 54.31 52.13 1.38 Lunes Laborable ## 116 527.53 54.06 54.94 52.27 1.23 Lunes Laborable ## 117 467.54 54.83 55.39 52.48 0.99 Lunes Laborable ## 118 557.75 52.74 54.17 51.59 1.65 Lunes Laborable ## 119 634.22 50.47 53.27 50.37 2.53 Lunes Laborable ## 120 566.73 49.90 53.02 50.05 2.00 Lunes Laborable ## 121 478.79 51.66 53.47 52.17 4.00 Lunes Laborable ## 122 334.74 60.89 56.33 55.39 0.13 Martes Laborable ## 123 528.25 60.66 57.45 56.63 0.26 Martes Laborable ## 124 753.87 59.39 57.64 55.76 0.26 Martes Laborable ## 125 755.98 56.55 57.46 54.52 0.83 Martes Laborable ## 126 684.83 54.79 57.64 53.93 1.24 Martes Laborable ## 127 733.74 53.40 56.19 52.45 2.90 Martes Laborable ## 128 650.60 52.27 54.69 51.30 1.88 Martes Laborable ## 129 615.06 51.32 53.87 50.94 1.96 Martes Laborable ## 130 643.33 49.04 52.75 49.60 2.60 Martes Laborable ## 131 748.73 48.71 52.46 49.97 2.50 Martes Laborable ## 132 676.35 50.65 53.44 51.59 1.82 Martes Laborable ## 133 337.68 60.26 56.11 54.88 0.14 Miércoles Laborable ## 134 355.96 59.66 57.23 55.29 0.26 Miércoles Laborable ## 135 422.06 59.00 57.52 55.59 6.00 Miércoles Laborable ## 136 579.11 57.95 57.59 55.14 0.26 Miércoles Laborable ## 137 647.93 55.34 55.99 53.61 1.26 Miércoles Laborable ## 138 675.17 56.58 57.17 55.19 0.83 Miércoles Laborable ## 139 582.26 55.79 57.06 54.25 1.21 Miércoles Laborable ## 140 544.73 55.01 56.51 53.52 1.45 Miércoles Laborable ## 141 649.62 53.64 55.88 53.22 1.35 Miércoles Laborable ## 142 711.69 53.76 55.77 53.45 1.83 Miércoles Laborable ## 143 579.75 50.74 54.07 51.03 1.95 Miércoles Laborable ## 144 341.95 58.79 55.19 54.16 0.14 Jueves Laborable ## 145 501.44 58.06 55.97 54.46 0.26 Jueves Laborable ## 146 541.73 56.13 55.51 53.61 0.27 Jueves Laborable ## 147 555.72 55.28 55.30 53.15 0.27 Jueves Laborable ## 148 542.58 54.59 55.07 52.14 7.00 Jueves Laborable ## 149 554.80 52.28 54.54 51.74 0.96 Jueves Laborable ## 150 593.54 52.28 54.67 51.86 0.62 Jueves Laborable ## 151 578.76 53.41 54.99 52.23 6.00 Jueves Laborable ## 152 618.93 54.98 56.16 53.85 0.56 Jueves Laborable ## 153 663.11 53.36 54.99 53.00 3.00 Jueves Laborable ## 154 642.12 56.52 56.68 55.31 0.86 Jueves Laborable ## 155 351.92 60.92 56.47 55.24 4.00 Viernes Laborable ## 156 550.39 60.10 57.45 55.77 0.27 Viernes Laborable ## 157 581.42 58.94 57.57 55.23 0.27 Viernes Laborable ## 158 504.73 57.51 57.09 54.43 0.27 Viernes Laborable ## 159 451.43 55.97 56.50 53.60 0.27 Viernes Laborable ## 160 414.75 55.32 56.22 53.57 0.44 Viernes Laborable ## 161 391.32 55.91 56.56 54.19 0.27 Viernes Laborable ## 162 512.99 56.17 57.09 54.67 0.68 Viernes Laborable ## 163 512.82 57.28 58.08 55.77 0.79 Viernes Laborable ## 164 551.45 57.57 58.33 56.57 0.44 Viernes Laborable ## 165 582.86 58.07 58.09 56.24 0.27 Viernes Laborable ## 166 348.87 62.47 57.73 56.00 4.00 Lunes Laborable ## 167 409.10 61.34 58.36 56.21 0.27 Lunes Laborable ## 168 392.46 59.82 58.41 55.88 0.27 Lunes Laborable ## 169 447.92 58.38 57.87 54.91 0.27 Lunes Laborable ## 170 443.52 55.36 56.89 53.56 0.45 Lunes Laborable ## 171 419.71 54.49 56.36 52.86 1.50 Lunes Laborable ## 172 340.18 56.88 58.34 54.09 1.49 Lunes Laborable ## 173 337.03 56.42 59.09 55.53 1.22 Lunes Laborable ## 174 353.91 56.47 59.25 56.26 1.44 Lunes Laborable ## 175 358.15 58.74 59.94 57.25 1.00 Lunes Laborable ## 176 386.02 60.11 60.46 58.57 0.84 Lunes Laborable ## 177 340.24 62.52 57.78 56.77 0.14 Martes Laborable ## 178 394.71 60.15 58.09 56.55 0.27 Martes Laborable ## 179 393.41 57.89 57.36 55.50 0.27 Martes Laborable ## 180 380.43 56.68 57.03 54.76 0.27 Martes Laborable ## 181 408.26 56.06 56.55 54.15 0.27 Martes Laborable ## 182 470.21 55.34 56.18 53.71 0.27 Martes Laborable ## 183 432.26 53.84 55.54 52.79 0.27 Martes Laborable ## 184 465.48 52.23 54.82 51.60 0.80 Martes Laborable ## 185 480.77 51.87 55.10 51.71 1.20 Martes Laborable ## 186 435.60 50.85 54.57 51.51 0.81 Martes Laborable ## 187 428.28 50.57 54.17 51.45 0.77 Martes Laborable ## 188 380.43 56.36 53.24 51.97 0.14 Miércoles Laborable ## 189 624.30 54.48 53.34 51.75 7.00 Miércoles Laborable ## 190 719.00 53.45 53.69 51.78 7.00 Miércoles Laborable ## 191 674.88 52.53 53.75 51.32 0.27 Miércoles Laborable ## 192 438.60 48.54 52.71 49.65 0.27 Miércoles Laborable ## 193 378.05 46.38 51.74 48.18 0.27 Miércoles Laborable ## 194 391.31 44.72 50.92 46.79 0.27 Miércoles Laborable ## 195 401.25 42.44 49.97 45.40 0.27 Miércoles Laborable ## 196 426.05 41.56 49.15 44.57 1.65 Miércoles Laborable ## 197 385.94 43.40 50.09 45.59 1.56 Miércoles Laborable ## 198 410.01 45.12 50.81 46.50 1.43 Miércoles Laborable ## 199 398.20 51.83 50.85 49.44 0.14 Jueves Laborable ## 200 613.11 50.67 50.74 48.79 0.27 Jueves Laborable ## 201 690.71 49.78 51.03 48.79 7.00 Jueves Laborable ## 202 709.13 49.27 51.45 48.79 0.27 Jueves Laborable ## 203 629.57 49.03 51.90 48.82 7.00 Jueves Laborable ## 204 463.65 48.73 52.04 48.22 0.27 Jueves Laborable ## 205 460.33 47.91 52.11 47.57 0.27 Jueves Laborable ## 206 616.19 47.73 52.44 47.33 0.55 Jueves Laborable ## 207 540.21 46.54 52.08 46.71 1.80 Jueves Laborable ## 208 446.61 45.19 51.80 46.44 3.00 Jueves Laborable ## 209 354.12 44.72 52.46 48.06 1.31 Jueves Laborable ## 210 387.09 51.37 50.75 49.10 0.14 Viernes Laborable ## 211 560.51 50.59 51.08 49.02 0.27 Viernes Laborable ## 212 631.41 50.21 51.43 49.17 0.27 Viernes Laborable ## 213 595.36 50.36 51.72 49.00 4.00 Viernes Laborable ## 214 542.70 49.51 51.94 48.12 2.48 Viernes Laborable ## 215 468.63 48.30 51.68 47.68 0.41 Viernes Laborable ## 216 384.68 49.12 52.87 48.13 0.30 Viernes Laborable ## 217 367.17 45.91 51.45 46.63 0.84 Viernes Laborable ## 218 561.11 40.79 50.12 44.09 3.67 Viernes Laborable ## 219 549.92 40.57 50.16 44.48 3.79 Viernes Laborable ## 220 414.32 43.84 50.36 45.26 1.15 Viernes Laborable ## 221 389.58 58.46 55.23 53.20 0.14 Lunes Laborable ## 222 644.48 56.85 55.50 52.75 0.27 Lunes Laborable ## 223 651.22 54.92 55.01 52.22 0.27 Lunes Laborable ## 224 534.48 54.71 55.12 52.02 0.27 Lunes Laborable ## 225 535.85 54.36 55.12 51.72 0.27 Lunes Laborable ## 226 510.42 53.20 54.81 50.69 0.91 Lunes Laborable ## 227 506.59 51.94 54.29 49.81 1.28 Lunes Laborable ## 228 554.25 49.76 53.73 48.61 8.00 Lunes Laborable ## 229 510.16 47.59 52.95 48.56 2.72 Lunes Laborable ## 230 677.55 43.67 50.91 45.72 3.43 Lunes Laborable ## 231 736.58 41.11 49.75 44.23 3.17 Lunes Laborable ## 232 379.67 53.38 52.03 50.22 0.14 Martes Laborable ## 233 593.50 51.15 51.39 49.53 7.00 Martes Laborable ## 234 636.84 49.91 51.28 48.99 0.27 Martes Laborable ## 235 606.00 49.75 51.82 49.06 7.00 Martes Laborable ## 236 525.91 50.21 52.72 49.69 0.27 Martes Laborable ## 237 494.20 49.65 52.91 49.10 8.00 Martes Laborable ## 238 487.16 50.68 53.97 49.43 3.00 Martes Laborable ## 239 476.29 51.41 54.48 49.51 1.81 Martes Laborable ## 240 559.83 50.01 53.67 48.69 2.72 Martes Laborable ## 241 671.27 44.11 51.62 45.35 3.00 Martes Laborable ## 242 584.79 50.58 53.48 49.16 0.97 Martes Laborable ## 243 636.48 52.21 52.42 49.94 0.27 Miércoles Laborable ## 244 682.76 50.81 52.36 49.73 0.27 Miércoles Laborable ## 245 670.18 50.71 52.71 49.80 0.27 Miércoles Laborable ## 246 579.91 50.77 53.29 50.16 0.27 Miércoles Laborable ## 247 608.75 51.09 54.28 50.38 1.70 Miércoles Laborable ## 248 538.49 52.20 55.28 50.17 0.91 Miércoles Laborable ## 249 561.61 52.08 55.45 50.02 2.74 Miércoles Laborable ## 250 459.75 50.42 54.20 49.93 3.25 Miércoles Laborable ## 251 416.79 48.47 54.82 48.53 3.83 Miércoles Laborable ## 252 368.39 54.32 56.70 51.00 5.00 Miércoles Laborable ## 253 334.54 52.81 56.28 51.09 0.30 Miércoles Laborable ## 254 580.15 54.33 53.73 51.52 0.26 Jueves Laborable ## 255 642.60 53.59 53.81 51.61 0.26 Jueves Laborable ## 256 581.43 54.61 54.30 51.42 0.26 Jueves Laborable ## 257 617.25 54.37 54.92 51.53 0.97 Jueves Laborable ## 258 515.18 54.23 56.13 51.68 2.20 Jueves Laborable ## 259 406.71 53.57 57.27 52.01 1.26 Jueves Laborable ## 260 432.73 51.40 56.30 49.62 3.21 Jueves Laborable ## 261 530.30 44.54 55.05 46.88 3.88 Jueves Laborable ## 262 601.47 42.37 55.00 46.85 7.00 Jueves Laborable ## 263 527.38 46.46 54.65 47.89 3.81 Jueves Laborable ## 264 413.18 49.09 55.57 49.17 0.85 Jueves Laborable ## 265 634.79 54.06 53.42 51.51 0.27 Viernes Laborable ## 266 670.63 53.11 53.80 51.07 0.27 Viernes Laborable ## 267 696.20 51.43 53.70 50.29 0.99 Viernes Laborable ## 268 663.89 52.87 54.40 51.36 1.57 Viernes Laborable ## 269 566.09 51.63 54.53 50.55 1.78 Viernes Laborable ## 270 452.31 50.28 55.01 50.24 2.18 Viernes Laborable ## 271 501.08 49.12 53.11 48.52 9.00 Viernes Laborable ## 272 686.46 44.08 51.59 45.63 3.81 Viernes Laborable ## 273 780.41 42.39 50.42 44.66 3.55 Viernes Laborable ## 274 601.89 45.35 50.27 46.16 2.42 Viernes Laborable ## 275 397.20 51.17 53.22 49.68 0.90 Viernes Laborable ## 276 614.66 57.29 56.31 53.58 0.27 Lunes Laborable ## 277 628.69 57.09 56.95 54.03 0.27 Lunes Laborable ## 278 593.73 57.50 57.54 54.52 0.27 Lunes Laborable ## 279 588.35 58.19 58.08 54.90 0.27 Lunes Laborable ## 280 583.13 58.80 58.72 55.47 0.27 Lunes Laborable ## 281 548.79 59.36 59.18 55.96 0.27 Lunes Laborable ## 282 459.40 60.17 59.72 56.49 0.27 Lunes Laborable ## 283 488.53 59.33 59.37 56.65 0.27 Lunes Laborable ## 284 460.45 58.35 58.79 55.97 0.27 Lunes Laborable ## 285 463.57 57.90 58.51 55.22 0.27 Lunes Laborable ## 286 410.95 58.38 58.10 54.74 0.14 Lunes Laborable ## 287 590.82 60.67 58.38 55.68 0.27 Martes Laborable ## 288 637.45 59.41 58.65 55.56 0.27 Martes Laborable ## 289 638.49 58.75 58.85 55.45 0.27 Martes Laborable ## 290 711.41 57.81 58.51 55.04 0.27 Martes Laborable ## 291 698.17 57.25 58.40 54.77 0.27 Martes Laborable ## 292 417.02 56.19 57.09 53.07 0.27 Martes Laborable ## 293 551.99 55.92 57.52 53.72 0.27 Martes Laborable ## 294 647.48 56.53 58.10 54.48 0.27 Martes Laborable ## 295 669.01 57.06 58.52 55.04 0.27 Martes Laborable ## 296 633.62 57.47 58.73 55.54 0.27 Martes Laborable ## 297 603.28 58.56 58.91 56.28 0.27 Martes Laborable ## 298 615.83 62.84 60.02 57.90 0.27 Miércoles Laborable ## 299 751.92 62.12 60.61 58.44 0.27 Miércoles Laborable ## 300 748.39 62.10 61.00 58.66 7.00 Miércoles Laborable ## 301 699.42 61.89 60.88 58.32 0.27 Miércoles Laborable ## 302 711.36 60.73 60.26 57.68 0.27 Miércoles Laborable ## 303 654.91 60.14 59.79 57.05 0.27 Miércoles Laborable ## 304 626.43 59.33 59.24 56.39 0.27 Miércoles Laborable ## 305 694.95 58.13 58.62 55.69 0.27 Miércoles Laborable ## 306 677.08 57.35 58.03 54.91 0.27 Miércoles Laborable ## 307 569.75 56.69 57.31 53.98 0.27 Miércoles Laborable ## 308 464.50 56.92 56.61 53.49 0.14 Miércoles Laborable ## 309 602.09 60.43 58.12 55.72 0.27 Jueves Laborable ## 310 706.51 58.86 57.99 55.69 0.27 Jueves Laborable ## 311 727.99 58.37 58.14 55.63 0.27 Jueves Laborable ## 312 752.69 57.77 58.23 55.48 0.27 Jueves Laborable ## 313 689.80 57.51 58.16 55.19 0.27 Jueves Laborable ## 314 635.31 57.62 58.45 55.29 0.27 Jueves Laborable ## 315 615.54 57.81 58.68 53.97 0.27 Jueves Laborable ## 316 589.30 55.31 57.56 52.69 0.27 Jueves Laborable ## 317 611.66 54.96 57.35 53.03 0.27 Jueves Laborable ## 318 546.46 55.77 57.01 53.30 0.27 Jueves Laborable ## 319 439.06 56.20 56.74 53.25 0.14 Jueves Laborable ## 320 558.48 59.97 57.09 54.95 0.27 Viernes Laborable ## 321 705.50 58.85 57.22 54.78 0.27 Viernes Laborable ## 322 781.35 58.31 57.57 54.70 0.26 Viernes Laborable ## 323 849.21 57.10 57.56 54.16 0.30 Viernes Laborable ## 324 762.80 56.12 57.58 53.19 0.30 Viernes Laborable ## 325 586.60 54.93 57.22 52.70 0.30 Viernes Laborable ## 326 484.28 54.02 56.71 52.14 0.30 Viernes Laborable ## 327 758.54 53.90 57.05 52.22 0.30 Viernes Laborable ## 328 732.24 53.20 56.52 52.38 0.30 Viernes Laborable ## 329 609.47 54.03 56.36 52.87 0.30 Viernes Laborable ## 330 593.78 55.47 56.72 53.62 0.30 Viernes Laborable ## 331 712.58 61.98 59.72 57.66 0.30 Lunes Laborable ## 332 888.70 61.25 59.91 57.33 0.30 Lunes Laborable ## 333 956.70 59.82 59.56 56.82 0.30 Lunes Laborable ## 334 795.17 59.68 59.43 56.24 0.30 Lunes Laborable ## 335 834.98 57.95 59.10 56.08 0.30 Lunes Laborable ## 336 878.81 57.34 58.64 55.89 0.30 Lunes Laborable ## 337 923.51 57.01 58.82 55.87 0.30 Lunes Laborable ## 338 1000.10 55.92 58.46 55.68 0.30 Lunes Laborable ## 339 758.59 52.78 56.63 54.26 0.30 Lunes Laborable ## 340 704.81 51.45 55.09 53.53 0.30 Lunes Laborable ## 341 882.19 53.99 55.71 54.91 0.30 Lunes Laborable ## 342 511.50 55.02 55.00 51.60 4.00 Martes Laborable ## 343 610.08 51.46 54.00 50.52 6.00 Martes Laborable ## 344 717.98 50.09 53.74 50.35 0.27 Martes Laborable ## 345 717.68 51.16 54.56 51.08 0.27 Martes Laborable ## 346 591.65 51.31 55.06 50.76 0.27 Martes Laborable ## 347 491.16 51.64 55.32 50.33 0.27 Martes Laborable ## 348 487.36 51.84 55.46 50.27 0.27 Martes Laborable ## 349 475.22 51.55 55.37 50.06 0.27 Martes Laborable ## 350 586.78 51.48 55.74 50.31 0.27 Martes Laborable ## 351 523.72 51.56 55.81 51.00 7.00 Martes Laborable ## 352 436.85 53.05 55.81 52.54 0.14 Martes Laborable ## 353 459.65 60.98 58.07 54.85 0.27 Miércoles Laborable ## 354 677.34 60.68 58.97 55.83 0.27 Miércoles Laborable ## 355 724.78 62.27 60.05 56.68 0.27 Miércoles Laborable ## 356 787.58 61.81 60.88 57.69 7.00 Miércoles Laborable ## 357 663.40 62.08 61.33 58.29 0.27 Miércoles Laborable ## 358 597.07 62.74 61.56 58.42 0.27 Miércoles Laborable ## 359 700.54 62.46 62.66 58.41 0.27 Miércoles Laborable ## 360 727.31 61.94 62.63 58.22 0.27 Miércoles Laborable ## 361 642.56 61.65 62.24 58.23 0.27 Miércoles Laborable ## 362 535.38 60.00 60.85 57.11 7.00 Miércoles Laborable ## 363 458.15 60.93 60.04 56.95 0.14 Miércoles Laborable ## 364 645.56 59.93 58.59 56.56 0.27 Jueves Laborable ## 365 711.42 58.82 58.43 56.52 0.27 Jueves Laborable ## 366 701.98 59.10 58.88 56.65 0.27 Jueves Laborable ## 367 791.58 60.05 59.87 57.30 0.27 Jueves Laborable ## 368 663.33 59.44 59.61 57.21 0.27 Jueves Laborable ## 369 597.63 60.36 60.05 57.48 0.27 Jueves Laborable ## 370 697.49 60.32 60.26 57.57 0.27 Jueves Laborable ## 371 647.74 59.38 59.91 57.43 0.27 Jueves Laborable ## 372 656.86 60.21 60.18 57.36 0.26 Jueves Laborable ## 373 772.27 57.70 58.96 56.67 0.29 Jueves Laborable ## 374 727.85 58.54 58.76 55.81 0.15 Jueves Laborable ## 375 516.99 62.32 59.98 56.20 0.27 Viernes Laborable ## 376 732.65 61.14 60.19 56.82 0.27 Viernes Laborable ## 377 753.76 60.48 60.07 56.67 0.27 Viernes Laborable ## 378 679.47 59.54 59.88 56.12 0.27 Viernes Laborable ## 379 633.56 58.97 59.81 55.62 0.27 Viernes Laborable ## 380 482.79 59.38 59.97 55.12 0.27 Viernes Laborable ## 381 499.22 59.49 60.22 54.70 0.27 Viernes Laborable ## 382 563.78 60.39 60.87 55.64 0.27 Viernes Laborable ## 383 434.19 59.20 60.20 54.60 0.27 Viernes Laborable ## 384 466.61 58.08 59.38 53.99 0.27 Viernes Laborable ## 385 384.93 57.74 58.76 53.97 0.14 Viernes Laborable ## 386 633.65 58.22 56.98 54.49 0.27 Lunes Laborable ## 387 727.76 57.87 57.25 54.86 0.27 Lunes Laborable ## 388 755.43 58.31 58.15 55.28 0.27 Lunes Laborable ## 389 619.17 57.76 58.36 54.75 0.26 Lunes Laborable ## 390 538.02 57.49 58.54 54.59 0.26 Lunes Laborable ## 391 543.81 57.67 58.75 53.72 0.26 Lunes Laborable ## 392 572.79 53.43 57.15 50.88 2.19 Lunes Laborable ## 393 769.99 45.03 54.88 46.68 3.92 Lunes Laborable ## 394 892.91 45.10 51.67 47.12 3.15 Lunes Laborable ## 395 808.22 52.77 54.83 52.56 1.12 Lunes Laborable ## 396 660.10 56.48 57.24 53.72 0.70 Lunes Laborable ## 397 744.90 58.87 57.15 54.14 0.27 Martes Laborable ## 398 868.99 58.19 57.35 54.42 0.27 Martes Laborable ## 399 882.90 57.67 57.45 54.34 0.27 Martes Laborable ## 400 885.75 55.07 56.08 52.60 1.26 Martes Laborable ## 401 846.12 56.75 57.55 53.79 1.28 Martes Laborable ## 402 719.68 59.05 59.43 55.81 0.73 Martes Laborable ## 403 662.27 57.42 57.85 54.24 1.46 Martes Laborable ## 404 909.47 55.73 56.87 53.79 0.11 Martes Laborable ## 405 886.03 57.00 59.07 55.96 0.30 Martes Laborable ## 406 729.28 53.53 57.00 54.19 1.00 Martes Laborable ## 407 666.58 54.93 56.81 53.45 0.16 Martes Laborable ## 408 671.51 59.20 56.38 54.34 0.31 Miércoles Laborable ## 409 679.19 57.37 56.12 53.74 1.00 Miércoles Laborable ## 410 704.51 56.24 56.04 53.49 0.31 Miércoles Laborable ## 411 737.93 55.76 56.08 53.03 0.31 Miércoles Laborable ## 412 781.10 54.74 56.13 52.21 0.31 Miércoles Laborable ## 413 801.63 54.36 56.17 51.30 0.30 Miércoles Laborable ## 414 849.83 50.28 55.03 48.69 2.49 Miércoles Laborable ## 415 908.99 44.71 53.27 45.64 3.87 Miércoles Laborable ## 416 725.35 44.78 53.57 46.75 3.58 Miércoles Laborable ## 417 727.23 44.69 52.49 46.04 3.58 Miércoles Laborable ## 418 635.59 47.39 51.91 47.85 1.56 Miércoles Laborable ## 419 603.52 52.04 52.56 49.35 0.27 Jueves Laborable ## 420 707.95 47.68 50.63 47.83 0.27 Jueves Laborable ## 421 765.15 48.63 51.55 48.43 0.27 Jueves Laborable ## 422 780.99 47.00 51.05 47.67 7.00 Jueves Laborable ## 423 780.42 45.82 51.08 47.10 0.89 Jueves Laborable ## 424 718.95 44.56 49.49 44.94 3.70 Jueves Laborable ## 425 773.90 44.91 49.95 45.24 2.76 Jueves Laborable ## 426 805.46 43.01 49.74 44.35 3.64 Jueves Laborable ## 427 906.52 43.26 50.98 44.93 3.60 Jueves Laborable ## 428 962.82 43.93 51.43 45.74 2.97 Jueves Laborable ## 429 795.83 50.78 53.50 50.11 0.61 Jueves Laborable ## 430 613.61 56.82 55.60 52.97 7.00 Viernes Laborable ## 431 680.95 55.87 55.65 53.06 0.26 Viernes Laborable ## 432 718.08 54.52 55.27 52.76 0.26 Viernes Laborable ## 433 816.80 52.82 54.87 51.89 0.26 Viernes Laborable ## 434 829.26 50.21 53.67 49.59 2.40 Viernes Laborable ## 435 814.48 45.47 51.49 46.83 3.61 Viernes Laborable ## 436 898.68 44.58 50.19 46.34 3.41 Viernes Laborable ## 437 940.98 45.34 49.55 47.89 2.54 Viernes Laborable ## 438 765.53 49.76 51.87 50.52 1.36 Viernes Laborable ## 439 426.93 53.62 54.21 51.71 0.30 Viernes Laborable ## 440 359.19 53.28 53.92 51.44 0.16 Viernes Laborable ## 441 603.84 56.62 55.17 52.69 0.30 Lunes Laborable ## 442 545.27 55.82 55.23 51.52 0.30 Lunes Laborable ## 443 518.15 55.36 55.43 51.09 0.30 Lunes Laborable ## 444 603.38 54.80 55.61 50.93 0.30 Lunes Laborable ## 445 445.82 53.13 54.55 49.48 0.30 Lunes Laborable ## 446 427.70 49.58 53.22 48.08 0.65 Lunes Laborable ## 447 613.35 45.18 50.39 45.64 3.59 Lunes Laborable ## 448 655.26 43.09 49.36 44.67 3.60 Lunes Laborable ## 449 739.30 44.42 50.09 46.18 1.20 Lunes Laborable ## 450 654.90 48.26 52.42 48.59 0.30 Lunes Laborable ## 451 449.12 50.12 53.09 49.54 0.30 Lunes Laborable ## 452 494.61 51.85 53.12 49.46 0.30 Martes Laborable ## 453 477.23 51.18 52.58 48.93 0.30 Martes Laborable ## 454 683.74 49.53 52.55 49.67 0.30 Martes Laborable ## 455 822.24 49.27 52.91 49.59 0.30 Martes Laborable ## 456 804.33 47.59 52.56 48.55 0.50 Martes Laborable ## 457 740.65 42.29 49.10 44.04 3.83 Martes Laborable ## 458 765.04 41.62 47.85 43.39 3.64 Martes Laborable ## 459 852.35 41.02 47.96 43.67 3.60 Martes Laborable ## 460 824.50 40.92 46.92 43.57 3.62 Martes Laborable ## 461 676.28 40.62 46.42 44.30 3.55 Martes Laborable ## 462 522.54 43.01 47.74 46.26 1.26 Martes Laborable ## 463 689.64 51.98 52.84 50.34 0.30 Miércoles Laborable ## 464 711.56 51.57 52.89 49.92 5.00 Miércoles Laborable ## 465 603.02 51.85 52.94 50.16 1.23 Miércoles Laborable ## 466 580.39 52.19 53.57 50.59 1.13 Miércoles Laborable ## 467 675.07 50.59 53.34 49.58 2.33 Miércoles Laborable ## 468 609.43 53.52 54.69 51.68 0.39 Miércoles Laborable ## 469 664.57 50.72 53.83 48.87 2.25 Miércoles Laborable ## 470 856.66 46.34 50.81 46.33 2.83 Miércoles Laborable ## 471 868.54 45.01 50.09 45.91 2.71 Miércoles Laborable ## 472 770.60 48.35 51.37 48.77 1.44 Miércoles Laborable ## 473 568.85 52.14 53.49 50.88 0.15 Miércoles Laborable ## 474 539.45 51.50 52.50 50.30 0.30 Jueves Laborable ## 475 623.78 50.22 52.39 49.96 0.31 Jueves Laborable ## 476 614.45 50.01 52.59 49.50 0.31 Jueves Laborable ## 477 665.27 50.09 52.87 48.90 1.13 Jueves Laborable ## 478 631.00 50.51 53.46 48.76 2.00 Jueves Laborable ## 479 562.98 48.83 52.53 47.47 2.49 Jueves Laborable ## 480 581.37 45.12 50.93 45.59 3.80 Jueves Laborable ## 481 738.87 42.55 50.11 44.17 3.39 Jueves Laborable ## 482 766.61 42.44 50.35 44.71 3.50 Jueves Laborable ## 483 786.66 44.95 51.69 46.85 2.40 Jueves Laborable ## 484 546.18 52.68 54.62 51.81 0.34 Jueves Laborable ## 485 564.34 46.36 50.15 47.96 0.31 Viernes Laborable ## 486 579.97 46.29 50.26 47.65 0.31 Viernes Laborable ## 487 537.38 46.67 50.52 47.66 0.54 Viernes Laborable ## 488 546.00 47.87 51.60 48.31 7.00 Viernes Laborable ## 489 548.43 49.04 52.92 49.51 1.31 Viernes Laborable ## 490 504.87 50.18 53.59 50.10 0.33 Viernes Laborable ## 491 588.26 50.19 53.92 50.03 0.30 Viernes Laborable ## 492 629.26 50.66 54.02 50.63 0.30 Viernes Laborable ## 493 703.61 51.72 54.95 52.74 0.30 Viernes Laborable ## 494 580.59 53.59 55.32 52.85 0.30 Viernes Laborable ## 495 475.66 54.92 54.95 52.42 0.30 Viernes Laborable 5.1.2.2 Ajuste de series de tiempo y gráfico de residuos. Estudio de la humedad relativa en el fondo de la oficina ¿Normalidad, autocorrelación de la humedad relativa? lillie.test(MultivarianteOCUP[1:418,9]) # No normal ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: MultivarianteOCUP[1:418, 9] ## D = 0.063037, p-value = 0.0004167 Box.test(MultivarianteOCUP[1:418,9]) # Dependencia, Xn+1 depende de Xn ## ## Box-Pierce test ## ## data: MultivarianteOCUP[1:418, 9] ## X-squared = 283.28, df = 1, p-value &lt; 2.2e-16 Estos gráficos no son fiables (indican + muestras fuera de control que las que en realidad son). Váse la variable Humedad Relativa (HR) del fondo de la oficina: qcc(MultivarianteOCUP[1:418,9],type=&quot;xbar.one&quot;) # Hay una cierta dependencia ## List of 11 ## $ call : language qcc(data = MultivarianteOCUP[1:418, 9], type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;MultivarianteOCUP[1:418, 9]&quot; ## $ data : num [1:418, 1] 51 46.5 46.5 50.5 51.4 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:418] 51 46.5 46.5 50.5 51.4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:418] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:418] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 53.3 ## $ std.dev : num 1.76 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 48 58.6 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; PROCEDIMIENTO: se ajusta un modelo de series de tiempo (ARIMA) y, una vez ajustada la autocorrelación, se controlan los residuos.Se pretende “extraer” la autocorrelación y poder aplicar de forma fiable los gráficos estándar. Se utiliza la librería “forecast”, que permite un ajuste automático del modelo de series de tiempo: library(forecast) ## Registered S3 method overwritten by &#39;xts&#39;: ## method from ## as.zoo.xts zoo ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ## Registered S3 methods overwritten by &#39;forecast&#39;: ## method from ## fitted.fracdiff fracdiff ## residuals.fracdiff fracdiff ## ## Attaching package: &#39;forecast&#39; ## The following object is masked from &#39;package:nlme&#39;: ## ## getResponse ## The following object is masked from &#39;package:fda&#39;: ## ## fourier # Se crea objeto serie de tiempo de la HR con periodo 11 (11 medidas por día) myts &lt;- ts(MultivarianteOCUP[,9], start=c(1, 1), frequency=11) plot(myts) fit &lt;- auto.arima(myts,stepwise=TRUE) summary(fit) # El modelo obtenido es un ARIMA(0,1,0)(2,0,0)[11] ## Series: myts ## ARIMA(3,0,2)(2,1,1)[11] ## ## Coefficients: ## ar1 ar2 ar3 ma1 ma2 sar1 sar2 sma1 ## -0.5605 0.6093 0.5449 1.5233 0.7137 0.1153 0.0494 -0.8433 ## s.e. 0.2631 0.1233 0.1996 0.2438 0.2057 0.0637 0.0567 0.0365 ## ## sigma^2 estimated as 4.65: log likelihood=-1060.59 ## AIC=2139.18 AICc=2139.56 BIC=2176.82 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.06109758 2.114536 1.452118 -0.01140915 2.805903 0.4053785 ## ACF1 ## Training set 0.0008242158 plot(forecast(fit, 20)) # Una vez asjustado el modelo de series de tiempo, se obtienen y estudian los residuos: lillie.test(fit$residuals) # No son normales ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: fit$residuals ## D = 0.10128, p-value = 3.387e-13 Box.test(fit$residuals) # Parece que Xn+1 no depende de Xn ## ## Box-Pierce test ## ## data: fit$residuals ## X-squared = 0.00033627, df = 1, p-value = 0.9854 tsdiag(fit, gof.lag=50) # No hay autocorrelación qcc(fit$residuals,type=&quot;xbar.one&quot;) # No normales: Este gráfico no es fiable ## List of 11 ## $ call : language qcc(data = fit$residuals, type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;fit$residuals&quot; ## $ data : num [1:495, 1] 0.051 0.0465 0.0464 0.0505 0.0514 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:495] 0.051 0.0465 0.0464 0.0505 0.0514 ... ## ..- attr(*, &quot;names&quot;)= chr [1:495] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:495] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 0.0611 ## $ std.dev : num 1.79 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -5.3 5.42 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; # Se aconseja la aplicación del gráfico EWMA, pues los residuos no son normales: ew=ewma(fit$residuals[1:418],type=&quot;xbar.one&quot;) Eliminamos las muestras fuera de control por deberse a picos y valles atípicos de humedad, correspondientes a condiciones especiales. Se incluyen los residuos de la muestra de monitorizado:: ewma(fit$residuals[-c(ew[15]$violations,419:495)],newdata=fit$residuals[419:495],type=&quot;xbar.one&quot;) ## List of 19 ## $ call : language ewma(data = fit$residuals[-c(ew[15]$violations, 419:495)], newdata = fit$residuals[419:495], type = &quot;xbar.one&quot;) ## $ type : chr &quot;ewma&quot; ## $ data.name : chr &quot;fit$residuals[-c(ew[15]$violations, 419:495)]&quot; ## $ data : num [1:411, 1] 0.051 0.0465 0.0464 0.0505 0.0514 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:411] 0.051 0.0465 0.0464 0.0505 0.0514 ... ## ..- attr(*, &quot;names&quot;)= chr [1:411] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:411] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 0.137 ## $ std.dev : num 1.69 ## $ newstats : Named num [1:77] -0.0601 -4.0652 0.562 -2.4572 -1.8076 ... ## ..- attr(*, &quot;names&quot;)= chr [1:77] &quot;412&quot; &quot;413&quot; &quot;414&quot; &quot;415&quot; ... ## $ newdata : num [1:77, 1] -0.0601 -4.0652 0.562 -2.4572 -1.8076 ... ## $ newsizes : int [1:77] 1 1 1 1 1 1 1 1 1 1 ... ## $ newdata.name: chr &quot;fit$residuals[419:495]&quot; ## $ x : int [1:488] 1 2 3 4 5 6 7 8 9 10 ... ## $ y : Named num [1:488] 0.1199 0.1052 0.0935 0.0849 0.0782 ... ## ..- attr(*, &quot;names&quot;)= chr [1:488] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sigma : num [1:488] 0.338 0.433 0.484 0.514 0.532 ... ## $ lambda : num 0.2 ## $ nsigmas : num 3 ## $ limits : num [1:488, 1:2] -0.877 -1.162 -1.315 -1.405 -1.46 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations : Named int 417 ## ..- attr(*, &quot;names&quot;)= chr &quot;417&quot; ## - attr(*, &quot;class&quot;)= chr &quot;ewma.qcc&quot; Conclusión: una vez eliminadas las observaciones fuera de control, no aparecen más, SE SUPONE QUE LA HUMEDAD ESTA BAJO CONTROL, no se han observado fueras de control ni causa asignable. NOTA: podría haberse estudiado la humedad mediante gráficos de medias. Se agrupan los datos de a dos (no tendría sentido incluir en un mismo grupo la humedad a las 9:00 y la humedad a las 12:00, pues se supone que pueden ser muy diferentes) Se estudia el consumo energético de las instalaciones de climatización ¿Normalidad, autocorrelación del consumo de las instalaciones de climatización? lillie.test(MultivarianteOCUP[1:418,12]) # No normal ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: MultivarianteOCUP[1:418, 12] ## D = 0.22047, p-value &lt; 2.2e-16 Box.test(MultivarianteOCUP[1:418,12]) # Dependencia, Xn+1 depende de Xn ## ## Box-Pierce test ## ## data: MultivarianteOCUP[1:418, 12] ## X-squared = 39.678, df = 1, p-value = 2.995e-10 # Estos gráficos no son fiables (dan + fuera de control que los que en realidad son): qcc(MultivarianteOCUP[1:418,12],type=&quot;xbar.one&quot;) # Hay una cierta dependencia ## List of 11 ## $ call : language qcc(data = MultivarianteOCUP[1:418, 12], type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;MultivarianteOCUP[1:418, 12]&quot; ## $ data : num [1:418, 1] 1.24 3.56 1.39 0.3 0.3 3.39 8 4.4 4.3 4.24 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:418] 1.24 3.56 1.39 0.3 0.3 3.39 8 4.4 4.3 4.24 ... ## ..- attr(*, &quot;names&quot;)= chr [1:418] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:418] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 1.63 ## $ std.dev : num 1.07 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -1.59 4.85 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; 5.1.2.3 Ejemplo práctico ARIMA PROCEDIMIENTO: se ajusta un modelo de series de tiempo (ARIMA) y, una vez ajustada la autocorrelación, se controlan los residuos: library(forecast) myts &lt;- ts(MultivarianteOCUP[,12], start=c(1, 1), frequency=11) plot(myts) fit &lt;- auto.arima(myts,stepwise=TRUE) summary(fit) ## Series: myts ## ARIMA(2,1,1)(2,0,0)[11] ## ## Coefficients: ## ar1 ar2 ma1 sar1 sar2 ## 0.1759 0.1215 -0.9743 0.1383 0.0690 ## s.e. 0.0470 0.0469 0.0142 0.0468 0.0468 ## ## sigma^2 estimated as 3.036: log likelihood=-973.96 ## AIC=1959.91 AICc=1960.08 BIC=1985.13 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -0.06116899 1.731823 1.194253 -192.565 217.0451 0.9423808 ## ACF1 ## Training set 0.005098083 plot(forecast(fit, 20)) # Vamos con los residuos: lillie.test(fit$residuals) # No son normales ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: fit$residuals ## D = 0.20988, p-value &lt; 2.2e-16 Box.test(fit$residuals) # Parece que Xn+1 no depende de Xn ## ## Box-Pierce test ## ## data: fit$residuals ## X-squared = 0.012865, df = 1, p-value = 0.9097 tsdiag(fit, gof.lag=100) # No hay autocorrelación qcc(fit$residuals[1:418],type=&quot;xbar.one&quot;) # No normales: Este gráfico no es fiable ## List of 11 ## $ call : language qcc(data = fit$residuals[1:418], type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;fit$residuals[1:418]&quot; ## $ data : num [1:418, 1] 0.00124 1.78266 -0.93614 -1.62227 -0.91689 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:418] 0.00124 1.78266 -0.93614 -1.62227 -0.91689 ... ## ..- attr(*, &quot;names&quot;)= chr [1:418] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:418] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num -0.0904 ## $ std.dev : num 1.25 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -3.84 3.66 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; # Se aplica el gráfico EWMA, pues los resíduos no son normales: ew=ewma(fit$residuals[1:418],type=&quot;xbar.one&quot;) ew[15]$violations ## 7 16 17 81 190 203 233 235 237 238 271 343 351 356 ## 7 16 17 81 190 203 233 235 237 238 271 343 351 356 Eliminamos los puntos fuera de control por deberse a picos y valles atípicos de consumo, correspondientes a condiciones especiales (horas punta de días especiales: reuniones, alta ocupación, encendido de ventilación…). Se muestra la muestra de monitorizado: ewma(fit$residuals[-c(ew[15]$violations,419:490)],newdata=fit$residuals[419:490], type=&quot;xbar.one&quot;) ## List of 19 ## $ call : language ewma(data = fit$residuals[-c(ew[15]$violations, 419:490)], newdata = fit$residuals[419:490], type = &quot;xbar.one&quot;) ## $ type : chr &quot;ewma&quot; ## $ data.name : chr &quot;fit$residuals[-c(ew[15]$violations, 419:490)]&quot; ## $ data : num [1:409, 1] 0.00124 1.78266 -0.93614 -1.62227 -0.91689 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:409] 0.00124 1.78266 -0.93614 -1.62227 -0.91689 ... ## ..- attr(*, &quot;names&quot;)= chr [1:409] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:409] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num -0.272 ## $ std.dev : num 1.01 ## $ newstats : Named num [1:72] -1.071 -0.685 -0.4 6.267 -1.189 ... ## ..- attr(*, &quot;names&quot;)= chr [1:72] &quot;410&quot; &quot;411&quot; &quot;412&quot; &quot;413&quot; ... ## $ newdata : num [1:72, 1] -1.071 -0.685 -0.4 6.267 -1.189 ... ## $ newsizes : int [1:72] 1 1 1 1 1 1 1 1 1 1 ... ## $ newdata.name: chr &quot;fit$residuals[419:490]&quot; ## $ x : int [1:481] 1 2 3 4 5 6 7 8 9 10 ... ## $ y : Named num [1:481] -0.2176 0.1825 -0.0412 -0.3574 -0.4693 ... ## ..- attr(*, &quot;names&quot;)= chr [1:481] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sigma : num [1:481] 0.203 0.26 0.291 0.309 0.32 ... ## $ lambda : num 0.2 ## $ nsigmas : num 3 ## $ limits : num [1:481, 1:2] -0.881 -1.052 -1.144 -1.198 -1.231 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations : Named int [1:24] 60 185 222 223 225 252 253 379 380 402 ... ## ..- attr(*, &quot;names&quot;)= chr [1:24] &quot;60&quot; &quot;185&quot; &quot;222&quot; &quot;223&quot; ... ## - attr(*, &quot;class&quot;)= chr &quot;ewma.qcc&quot; Conclusión: una vez eliminados las observaciones fuera de control, aparecen más, es decir, el sistema no está bajo control. Parece que continuamente los operarios están actuando sobre el sistema. Puede ser debido a que también haya dos poblaciones. Por ejemplo, no estamos teniendo en cuenta las horas donde la instalación esta apagada (con un consumo residual sólo debido al mantenimiento del sistema informático y al encendido, &lt;=0.3 KW) Utilizando todos los datos como muestra de calibrado: Consumo_ON=MultivarianteOCUP$ConsumoUE03[MultivarianteOCUP$ConsumoUE03&gt;0.3] ewma(Consumo_ON,type=&quot;xbar.one&quot;) ## List of 15 ## $ call : language ewma(data = Consumo_ON, type = &quot;xbar.one&quot;) ## $ type : chr &quot;ewma&quot; ## $ data.name : chr &quot;Consumo_ON&quot; ## $ data : num [1:277, 1] 1.24 3.56 1.39 3.39 8 4.4 4.3 4.24 4.1 1.27 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:277] 1.24 3.56 1.39 3.39 8 4.4 4.3 4.24 4.1 1.27 ... ## ..- attr(*, &quot;names&quot;)= chr [1:277] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:277] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 2.73 ## $ std.dev : num 1.39 ## $ x : int [1:277] 1 2 3 4 5 6 7 8 9 10 ... ## $ y : Named num [1:277] 2.43 2.66 2.4 2.6 3.68 ... ## ..- attr(*, &quot;names&quot;)= chr [1:277] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sigma : num [1:277] 0.279 0.357 0.399 0.424 0.439 ... ## $ lambda : num 0.2 ## $ nsigmas : num 3 ## $ limits : num [1:277, 1:2] 1.89 1.65 1.53 1.45 1.41 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations: Named int [1:28] 14 15 16 17 18 19 20 142 143 144 ... ## ..- attr(*, &quot;names&quot;)= chr [1:28] &quot;14&quot; &quot;15&quot; &quot;16&quot; &quot;17&quot; ... ## - attr(*, &quot;class&quot;)= chr &quot;ewma.qcc&quot; qcc(Consumo_ON,type=&quot;xbar.one&quot;) ## List of 11 ## $ call : language qcc(data = Consumo_ON, type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;Consumo_ON&quot; ## $ data : num [1:277, 1] 1.24 3.56 1.39 3.39 8 4.4 4.3 4.24 4.1 1.27 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:277] 1.24 3.56 1.39 3.39 8 4.4 4.3 4.24 4.1 1.27 ... ## ..- attr(*, &quot;names&quot;)= chr [1:277] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:277] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 2.73 ## $ std.dev : num 1.39 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -1.46 6.91 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Box.test(Consumo_ON) # Hay autocorrelación ## ## Box-Pierce test ## ## data: Consumo_ON ## X-squared = 15.616, df = 1, p-value = 7.761e-05 myts &lt;- ts(Consumo_ON, start=c(1, 1), frequency=11) plot(myts) fit &lt;- auto.arima(myts,stepwise=TRUE) summary(fit) # ARIMA(3,0,0)(1,0,0)[11] ## Series: myts ## ARIMA(3,0,0)(1,0,0)[11] with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 sar1 mean ## 0.2147 0.0776 0.0283 -0.0208 2.7194 ## s.e. 0.0603 0.0614 0.0608 0.0620 0.1610 ## ## sigma^2 estimated as 3.527: log likelihood=-565.13 ## AIC=1142.26 AICc=1142.57 BIC=1164 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.002245643 1.860957 1.407624 -72.65197 98.70123 0.6910303 ## ACF1 ## Training set -0.000846751 plot(forecast(fit, 2)) # Se estudian las hipótesis sobre los residuos: lillie.test(fit$residuals[1:20]) # Son normales ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: fit$residuals[1:20] ## D = 0.23888, p-value = 0.004004 Box.test(fit$residuals[1:20]) # Parece que Xn+1 no depende de Xn ## ## Box-Pierce test ## ## data: fit$residuals[1:20] ## X-squared = 0.064604, df = 1, p-value = 0.7994 windows() tsdiag(fit, gof.lag=7) # No hay autocorrelación El consumo diario no está bajo control. Existen picos de consumo excesivos comparados con las demás observaciones. qcc(fit$residuals,type=&quot;xbar.one&quot;) ## List of 11 ## $ call : language qcc(data = fit$residuals, type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;fit$residuals&quot; ## $ data : num [1:277, 1] -1.431 1.186 -1.387 0.932 5.215 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:277] -1.431 1.186 -1.387 0.932 5.215 ... ## ..- attr(*, &quot;names&quot;)= chr [1:277] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:277] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 0.00225 ## $ std.dev : num 1.58 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -4.73 4.73 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Otra posible causa: puede ser que no haya eliminado toda la dependencia. Por tanto, agrupanos en medidas diarias (gran inconveniente: se pierde mucha información) ConsumoDiario=apply(matrix(MultivarianteOCUP$ConsumoUE03,ncol=11,byrow=TRUE),1,mean) lillie.test(ConsumoDiario) # Son normales ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: ConsumoDiario ## D = 0.078898, p-value = 0.6878 Box.test(ConsumoDiario) # Hay dependencia ## ## Box-Pierce test ## ## data: ConsumoDiario ## X-squared = 14.024, df = 1, p-value = 0.0001805 myts &lt;- ts(ConsumoDiario, start=c(1, 1), frequency=5) plot(myts) fit &lt;- auto.arima(myts,stepwise=TRUE) summary(fit) ## Series: myts ## ARIMA(0,1,2)(0,0,1)[5] ## ## Coefficients: ## ma1 ma2 sma1 ## -0.2862 -0.3108 -0.3601 ## s.e. 0.1508 0.1496 0.1500 ## ## sigma^2 estimated as 0.5713: log likelihood=-49.17 ## AIC=106.34 AICc=107.37 BIC=113.48 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set -0.1417365 0.7214492 0.5599873 -54.06407 73.7874 0.5657476 ## ACF1 ## Training set -0.0724909 plot(forecast(fit, 2)) # Vamos con los residuos: lillie.test(fit$residuals[1:20]) # Son normales ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: fit$residuals[1:20] ## D = 0.13775, p-value = 0.4098 Box.test(fit$residuals[1:20]) # Parece que Xn+1 no depende de Xn ## ## Box-Pierce test ## ## data: fit$residuals[1:20] ## X-squared = 0.52562, df = 1, p-value = 0.4685 tsdiag(fit, gof.lag=100) # No hay autocorrelación # El consumo diario está bajo control: qcc(fit$residuals[1:20],newdata=fit$residuals[20:45],type=&quot;xbar.one&quot;) ## List of 15 ## $ call : language qcc(data = fit$residuals[1:20], type = &quot;xbar.one&quot;, newdata = fit$residuals[20:45]) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;fit$residuals[1:20]&quot; ## $ data : num [1:20, 1] 0.0032 1.1196 -1.672 -0.8223 -0.1184 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics : Named num [1:20] 0.0032 1.1196 -1.672 -0.8223 -0.1184 ... ## ..- attr(*, &quot;names&quot;)= chr [1:20] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:20] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num -0.264 ## $ std.dev : num 0.778 ## $ newstats : Named num [1:26] -0.487 0.251 0.914 -0.544 0.657 ... ## ..- attr(*, &quot;names&quot;)= chr [1:26] &quot;21&quot; &quot;22&quot; &quot;23&quot; &quot;24&quot; ... ## $ newdata : num [1:26, 1] -0.487 0.251 0.914 -0.544 0.657 ... ## $ newsizes : int [1:26] 1 1 1 1 1 1 1 1 1 1 ... ## $ newdata.name: chr &quot;fit$residuals[20:45]&quot; ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] -2.6 2.07 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations :List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; 5.1.2.4 Gráfico EWMA para datos dependientes (dependencia tipo AR(1)). Función diseñada por Javier Rivero de Aguilar. Se pretende hacer un control de la humedad relativa: qcc(ConTempHRco2[,9],type=&quot;xbar.one&quot;) ## List of 11 ## $ call : language qcc(data = ConTempHRco2[, 9], type = &quot;xbar.one&quot;) ## $ type : chr &quot;xbar.one&quot; ## $ data.name : chr &quot;ConTempHRco2[, 9]&quot; ## $ data : num [1:45, 1] 42.5 40.1 44.8 48 42.7 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ statistics: Named num [1:45] 42.5 40.1 44.8 48 42.7 ... ## ..- attr(*, &quot;names&quot;)= chr [1:45] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ sizes : int [1:45] 1 1 1 1 1 1 1 1 1 1 ... ## $ center : num 49.5 ## $ std.dev : num 3.59 ## $ nsigmas : num 3 ## $ limits : num [1, 1:2] 38.7 60.3 ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## $ violations:List of 2 ## - attr(*, &quot;class&quot;)= chr &quot;qcc&quot; Se observa que el sistema está aparentemente fuera de control. Esto puede ser debido a la existencia de autocorrelación en los datos. Si no se tiene en cuenta la autocorrelación al estimar la variablilidad del proceso se obtiene un gran número de falsas alarmas. Se crea una función llamada EWMAcorrelatedData para aplicar una modificación del gráfico EWMA para variables autocorreladas. Funciona muy bien con procesos AR(1), autorregresivos de orden uno. EWMAcorrelatedData&lt;-function(x) { #x es la variable a controlar (consumo eléctrico en este caso) # Valores posibles del parámetro lambda (relacionado con la &quot;memoria&quot;) del gráfico EWMA lambda=c(seq(0,1,0.001)) z=numeric() # Se inicializa el vector de las medias ponderadas exponencialmente z[1]=mean(x) # Se iguala la primera componente a la media de la variable a controlar (cosumo) dim=length(x) # Dimensión de la variable a controlar e=numeric() # Diferencias entre el valor de la variable y la media ponderada para cada lamda eop=numeric() # Diferencias entre el valor de la variable y la media ponderada para lamda OPT. o=numeric() # Suma de los cuadrados de las diferencias entre variable y media ponderada for (i in 1:length(lambda)) { for (k in 2:(dim+1)){ # Cálculo de medias ponderadas para cada lambda. Se elige un parámetro de memoria (1-lambda) z[k]=lambda[i]*x[k-1]+((1-lambda[i])*z[k-1]) e[k-1]=x[k-1]-z[k-1] # Cálculo de las diferencias entre variable y media ponderada } o[i]=sum(e^2) # Cálculo de la suma de diferencias al cuadrado } # Se elige el lambda que produce el menor valor para las diferencias al cuadrado (o): lambdaopt=lambda[which.min(o)] for (k in 2:(dim+1)){ # Cálculo de las medias ponderadas para lamda óptimo z[k]=lambdaopt*x[k-1]+((1-lambdaopt)*z[k-1]) eop[k-1]=x[k-1]-z[k-1] # Diferencias entre variable a controlar y medias ponderadas } # Se calculan los límites de control para los residuos o diferencias, # asumiendo que son normales UCL=z+3*sd(eop) LCL=z-3*sd(eop) outl=0 outu=0 for (i in 1:(dim)){ if (x[i]&lt;LCL[i]) outl=c(outl,i) # Marcador de las observaciones por debajo lím inferior } for (i in 1:(dim)){ if (x[i]&gt;UCL[i]) outu=c(outu,i) # Marcador de las observaciones por encima lím superior } # Salidas de la función: lambda óptimo, test de normalidad de los residuos, # suma de cuadrados de los residuos para lambda óptimo, # gráficos de control con valores de la variable, valores de las medias ponderadas y # límites de control naturales, # Valores fuera de los límites de control: return(list(LambdaOptimo=lambdaopt,TestNormal=shapiro.test(eop), Resid=sum(eop^2), plot=plot(x,type=&quot;l&quot;,ylim=c(min(LCL),max(UCL)),pch=21,main=&quot;Approximate ewma procedure for correlated data&quot;) ,lines(z,col=&quot;green&quot;,type=&quot;p&quot;,pch=22) ,lines(UCL,type=&quot;l&quot;,col=&quot;red&quot;,pch=23) ,lines(LCL,type=&quot;l&quot;,col=&quot;blue&quot;,pch=24) ,outup=outu ,outlow=outl ,c(length(outu)-1,length(outl)-1) )) } Se observa que el consumo estudiado en las fechas indicadas está realmente bajo control: EWMAcorrelatedData(ConTempHRco2[,9]) ## $LambdaOptimo ## [1] 0.644 ## ## $TestNormal ## ## Shapiro-Wilk normality test ## ## data: eop ## W = 0.9862, p-value = 0.8624 ## ## ## $Resid ## [1] 1141.021 ## ## $plot ## NULL ## ## [[5]] ## NULL ## ## [[6]] ## NULL ## ## [[7]] ## NULL ## ## $outup ## [1] 0 ## ## $outlow ## [1] 0 ## ## [[10]] ## [1] 0 0 5.1.3 Análisis de capacidad con datos autocorrelados. Se ensaya una versión de los índices de capacidad cuando cuando la característica crítica de calidad está autocorrelada según un proceso AR(1), autorregresivo de orden 1. Se ajusta un modelo AR(1) a los datos del consumo horario en horas de ocupación library(forecast) myts=ts(MultivarianteOCUP[,12], start=c(1,1),frequency=11) library(TSA) ## Warning: package &#39;TSA&#39; was built under R version 3.6.1 ## Registered S3 methods overwritten by &#39;TSA&#39;: ## method from ## fitted.Arima forecast ## plot.Arima forecast ## ## Attaching package: &#39;TSA&#39; ## The following object is masked from &#39;package:readr&#39;: ## ## spec ## The following objects are masked from &#39;package:stats&#39;: ## ## acf, arima ## The following object is masked from &#39;package:utils&#39;: ## ## tar fit=arimax(myts, order=c(1,0,0)) Para estimar los índices de capacidad de proceso, previamente tendría que estudiarse si el proceso está bajo control. En este caso no lo está, por lo que los índices de estimados se denominan índices de rendimiento del proceso. #--Media del proceso mu=mean(myts) #-Varianza de los residuos: sigma_a=sd(fit$residuals) #-Parámetro del proceso autorregresivo: parametro=fit$coef[1] # La igualdad Var(proceso)=sigma_a^2/(1-parametro^2) se dará con procesos AR(1) # Sigma_r: sigma_r=sqrt((sigma_a^2)/(1-parametro^2)) # Límites de especificación: USL=6; LSL=2.2 #-- 1. Índice de rendimiento calculado : C_pmr=(USL-LSL)/(6*sqrt(sigma_r^2+(mu-T)^2)) #--2. Índice de rendimiento calculado : C_pkr=min((USL-mu)/(3*sigma_r),(USL-LSL)/(3*sigma_r)) ResultadoD=data.frame(c(C_pmr,C_pkr)) colnames(ResultadoD)=c(&quot;Índices de rendimiento datos dependientes&quot;);rownames(ResultadoD)=c(&quot;C_pmr&quot;,&quot;C_pkr&quot;) ResultadoD ## Índices de rendimiento datos dependientes ## C_pmr 0.3171492 ## C_pkr 0.6695514 # Índices de rendimiento datos dependientes # C_pmr 0.3171492 # C_pkr 0.6695514 # La instalación de clima no es capaz de cumplir con las especificaciones # Cpkr y Cpmr &lt; 1.33 "],
["practica-5.html", "Capítulo 6 Práctica 5 6.1 Introducción al diseño de experimentos con R", " Capítulo 6 Práctica 5 6.1 Introducción al diseño de experimentos con R 6.1.1 Ejemplos de Pruebas ANOVA 6.1.1.1 Ejemplo de la resistencia a la tracción de aceros traccion=c(39, 33, 39, 35, 32, 36, 40, 35, 30, 29, 33, 33, 36, 26, 35) Hormigon=as.factor(c(rep(&quot;A&quot;,5),rep(&quot;B&quot;,5),rep(&quot;C&quot;,5))) boxplot(split(traccion,Hormigon),xlab=&#39;Tipo de hormigón&#39;, ylab=&#39;Resistencia a la tracción&#39;,col=terrain.colors(3)) anovatraccion&lt;-aov(traccion~Hormigon) summary(aov(anovatraccion)) # Construye la tabla ANOVA ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Hormigon 2 22.53 11.27 0.725 0.504 ## Residuals 12 186.40 15.53 Diagnósis de las hipótesis del modelo: Independencia, normalidad, homocedasticidad res&lt;-residuals(anovatraccion) # Se calculan los residuos. yh&lt;-fitted(anovatraccion) plot(yh,res) abline(h=0,col=2,lty=2) shapiro.test(res) # Prueba de normalidad, los residuos son normales ## ## Shapiro-Wilk normality test ## ## data: res ## W = 0.95736, p-value = 0.6466 qqnorm(res) qqline(res) library(car) #Para poder hacer la prueba de LEVENE se necesita leveneTest(traccion,Hormigon) # Prueba de Levene para homogeneidad de varianzas ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.2283 0.7993 ## 12 # Residuos homocedásticos. bartlett.test(traccion,Hormigon) # Prueba de Bartlett para homogeneidad de varianzas ## ## Bartlett test of homogeneity of variances ## ## data: traccion and Hormigon ## Bartlett&#39;s K-squared = 0.36411, df = 2, p-value = 0.8336 # Residuos homocedásticos. # Diagnósis gráfica del modelo: par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) plot(anovatraccion) se cumplen las hipótesis del modelo ANOVA, por lo que es factible la aplicación del test F 6.1.1.2 Ejemplo de los laboratorios que miden el peso de muestras de estaño. Respuesta: peso Se presenta el caso práctico en el que se pretende medir la cantidad de recubrimiento de estaño que tienen las latas de un determinado fabricante. Para ellos de hace un pequeño diseño de experimentos por lo que 4 laboratorios, mediante en tratamiento químico, miden el contenido en estaño de 12 muestras, cada uno. ¿Habra que descartar los resultados de alguno de los laboratorios? Esta es una primera aproximación a los estudios interlaboratorio. Primeramente se cargan los datos laboratorio&lt;-c(rep(1,12),rep(2,12),rep(3,12),rep(4,12)) laboratorio&lt;-as.factor(laboratorio) peso&lt;-c(0.25, 0.27, 0.22, 0.30, 0.27, 0.28, 0.32, 0.24, 0.31, 0.26, 0.21, 0.28, 0.19, 0.25, 0.27, 0.24, 0.18, 0.26, 0.28, 0.24, 0.25, 0.20, 0.21, 0.19, 0.18, 0.28, 0.21, 0.23, 0.25, 0.20, 0.27, 0.19, 0.24, 0.22, 0.29, 0.16, 0.23, 0.30, 0.28, 0.28, 0.24, 0.34, 0.20, 0.18, 0.24, 0.28, 0.22, 0.21) Se Realiza un ANOVA gráfico boxplot(split(peso,laboratorio),xlab=&#39;Laboratorios&#39;,ylab=&#39;Peso de estado&#39;) Se contruye la tabla ANOVA y se realiza el test de la F: anovapeso&lt;-aov(peso~ laboratorio) summary(aov(peso~laboratorio)) # Construye la tabla ANOVA ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## laboratorio 3 0.01301 0.004335 2.81 0.0504 ## Residuals 44 0.06789 0.001543 Diagnosis del modelo ¿Son los residuos independientes? res&lt;-residuals(anovapeso) # Se calculan los residuals. yh&lt;-fitted(anovapeso) plot(yh,res) abline(h=0) ¿Son los residuos normales? shapiro.test(res) # Prueba de normalidad ## ## Shapiro-Wilk normality test ## ## data: res ## W = 0.97947, p-value = 0.5566 qqnorm(res) qqline(res) ¿Son los residuos homocedásticos? library(car) #Para poder hacer la prueba de LEVENE se necesita #la librerÃ?a CAR que se descarga de la pÃ¡gina del R. leveneTest(peso,laboratorio) # Prueba de Levene para homogeneidad de varianzas ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 0.5392 0.658 ## 44 bartlett.test(peso,laboratorio) # Prueba de Bartlett para homogeneidad de varianzas ## ## Bartlett test of homogeneity of variances ## ## data: peso and laboratorio ## Bartlett&#39;s K-squared = 1.4859, df = 3, p-value = 0.6855 Se cumplen las hipótesis del modelo. 6.1.1.3 Exprerimento para medir la velocidad de la luz ideado por Morley Datos clásicos de Michelson sobre mediciones hechas en 1879 para estimar la velocidad de la luz. Los datos constan de cinco experimentos, cada uno de los cuales consta de 20 réplicas consecutivas. La respuesta es la velocidad de medición de la luz, adecuadamente codificada (medida en km/s, habiendo sustraído 299000 km/h en todas las mediciones). Los datos se ven aquí como un experimento de bloques aleatorizados con “Experimento” y “Réplica” como los factores. “Réplica” también se puede considerar una variable cuantitativa para tener en cuenta los cambios lineales (o polinomiales) en la medición en el transcurso de un solo experimento. Se tiene, por tanto, una variable respuesta, velocidad de la luz, y dos factores tratamiento, el experimento realizado, con cinco niveles (se realizan 5 experimentos), y la réplica (con 20 niveles). Se cargan los datos: luz&lt;-morley luz$Expt &lt;- factor(luz$Expt) luz$Run &lt;- factor(luz$Run) summary(luz) ## Expt Run Speed ## 1:20 1 : 5 Min. : 620.0 ## 2:20 2 : 5 1st Qu.: 807.5 ## 3:20 3 : 5 Median : 850.0 ## 4:20 4 : 5 Mean : 852.4 ## 5:20 5 : 5 3rd Qu.: 892.5 ## 6 : 5 Max. :1070.0 ## (Other):70 attach(luz) ANOVA gráfico: plot(Expt, Speed, main=&quot;Velocidad de la luz&quot;, xlab=&quot;Experimento NÃºmero&quot;) Tabla ANOVA y test F: fm &lt;- aov(Speed ~ Run + Expt, data=luz) summary(fm) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Run 19 113344 5965 1.105 0.36321 ## Expt 4 94514 23629 4.378 0.00307 ## Residuals 76 410166 5397 names(fm) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;contrasts&quot; &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; ## [13] &quot;model&quot; fm$coef ## (Intercept) Run2 Run3 Run4 Run5 ## 9.506000e+02 -5.200000e+01 -2.800000e+01 6.000000e+00 -7.600000e+01 ## Run6 Run7 Run8 Run9 Run10 ## -1.040000e+02 -1.000000e+02 -4.000000e+01 -1.000000e+01 -3.800000e+01 ## Run11 Run12 Run13 Run14 Run15 ## 4.000000e+00 -1.222579e-13 -3.600000e+01 -9.400000e+01 -6.000000e+01 ## Run16 Run17 Run18 Run19 Run20 ## -6.600000e+01 -6.000000e+00 -3.800000e+01 -5.000000e+01 -4.400000e+01 ## Expt2 Expt3 Expt4 Expt5 ## -5.300000e+01 -6.400000e+01 -8.850000e+01 -7.750000e+01 summary(fm) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Run 19 113344 5965 1.105 0.36321 ## Expt 4 94514 23629 4.378 0.00307 ## Residuals 76 410166 5397 names(fm) ## [1] &quot;coefficients&quot; &quot;residuals&quot; &quot;effects&quot; &quot;rank&quot; ## [5] &quot;fitted.values&quot; &quot;assign&quot; &quot;qr&quot; &quot;df.residual&quot; ## [9] &quot;contrasts&quot; &quot;xlevels&quot; &quot;call&quot; &quot;terms&quot; ## [13] &quot;model&quot; fm$coef ## (Intercept) Run2 Run3 Run4 Run5 ## 9.506000e+02 -5.200000e+01 -2.800000e+01 6.000000e+00 -7.600000e+01 ## Run6 Run7 Run8 Run9 Run10 ## -1.040000e+02 -1.000000e+02 -4.000000e+01 -1.000000e+01 -3.800000e+01 ## Run11 Run12 Run13 Run14 Run15 ## 4.000000e+00 -1.222579e-13 -3.600000e+01 -9.400000e+01 -6.000000e+01 ## Run16 Run17 Run18 Run19 Run20 ## -6.600000e+01 -6.000000e+00 -3.800000e+01 -5.000000e+01 -4.400000e+01 ## Expt2 Expt3 Expt4 Expt5 ## -5.300000e+01 -6.400000e+01 -8.850000e+01 -7.750000e+01 Se observa que el factor Experimento afecta significativamente (0.00307&lt;0.05) a la respuesta (velocidad de la luz) en al menos un nivel. Viendo el ANOVA gráfico, bien podría ser el Experimento 1 el diferente. Habría que ver cuál es la razón a tales diferencias. En todo caso, la velocidad debería estimarse con el resto de experimentos. Diagnosis del modelo: par(mfrow=c(2,2)) plot(fm) windows() rm(fm) 6.1.1.4 Diseño que incluye el test de Tuckey para la resistencia a la rotura de la lana (con dos tipos diferentes) en un telar Este conjunto de datos proporciona el número de roturas de urdimbre por telar, donde un telar corresponde a una longitud fija de hilo. Se tienen 54 observaciones correspondientes a 3 telares, con dos tipos de lana (medida de roturas) Variable respuesta: número de roturas de las fibras de lana. Factores tratamiento: tipo de lana (A o B) y tensión que soporta (Low, Medium, High). Por tanto, hay \\(2*3=6\\) tratamientos. data(warpbreaks) Tabla ANOVA y test de la F: summary(fm1 &lt;- aov(breaks ~ wool + tension, data = warpbreaks)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## wool 1 451 450.7 3.339 0.07361 ## tension 2 2034 1017.1 7.537 0.00138 ## Residuals 50 6748 135.0 Si sólo se suponen efectos aditivos, variaciones en el factor tensión originan cambios significativamente distintos de cero (0.00138&lt;0.05) en el número de roturas (variable respuesta). Además, el test de Tukey puede indicar qué niveles de tensión producen cambios significativos en el número de roturas. TukeyHSD(fm1, &quot;tension&quot;, ordered = TRUE) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## factor levels have been ordered ## ## Fit: aov(formula = breaks ~ wool + tension, data = warpbreaks) ## ## $tension ## diff lwr upr p adj ## M-H 4.722222 -4.6311985 14.07564 0.4474210 ## L-H 14.722222 5.3688015 24.07564 0.0011218 ## L-M 10.000000 0.6465793 19.35342 0.0336262 plot(TukeyHSD(fm1, &quot;tension&quot;)) La alta (H) y media (M) tensión inducen un número de roturas similar y signficativamente más bajo que el correspondiente a un nivel de tensión bajo (L). Si se analiza un modelo con interacción, se ve, al igual que se intuía en el ANOVA gráfico (diferente efecto de la tensión según el tipo de lana), que la interacción entre tensión y tipo de lana es significativa \\((0.021044&lt;0.05)\\). 6.1.2 DISEÑOS FACTORIALES 6.1.2.1 Fiabilidad de una resina epoxy (polímero) con fibras de carbono Base de datos y construcción del esquema: Inclinacion=factor(c(0,1,0,1,0,1,0,1)) Grosor=factor(c(0,0,1,1,0,0,1,1)) Postcurado=factor(c(0,0,0,0,1,1,1,1)) Compresiones=c(79,97,75,92,64,84,73,90) El esquema del diseño factorial se define usando la librería qualityTools, asignando \\(-1\\) a los niveles \\(0\\) y \\(+1\\) a los niveles \\(1\\). library(qualityTools) diseno.frac = fracDesign(k = 3) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated names(diseno.frac)=c(&quot;Inclinacion&quot;,&quot;Grosor&quot;,&quot;Postcurado&quot;) diseno.frac ## StandOrder RunOrder Block A B C y ## 7 7 1 1 -1 1 1 NA ## 3 3 2 1 -1 1 -1 NA ## 8 8 3 1 1 1 1 NA ## 6 6 4 1 1 -1 1 NA ## 4 4 5 1 1 1 -1 NA ## 2 2 6 1 1 -1 -1 NA ## 5 5 7 1 -1 -1 1 NA ## 1 1 8 1 -1 -1 -1 NA Compresiones_b=c(92,75,97,64,84,73,90,79) response(diseno.frac)= data.frame(Compresiones=Compresiones_b) summary(diseno.frac) ## Information about the factors: ## ## A B C ## low -1 -1 -1 ## high 1 1 1 ## name Inclinacion Grosor Postcurado ## unit ## type numeric numeric numeric ## ----------- ## StandOrder RunOrder Block A B C Compresiones ## 7 7 1 1 -1 1 1 92 ## 3 3 2 1 -1 1 -1 75 ## 8 8 3 1 1 1 1 97 ## 6 6 4 1 1 -1 1 64 ## 4 4 5 1 1 1 -1 84 ## 2 2 6 1 1 -1 -1 73 ## 5 5 7 1 -1 -1 1 90 ## 1 1 8 1 -1 -1 -1 79 Efectos principales: effectPlot(diseno.frac, classic = TRUE) Alternativa: par(mfrow=c(1,3)) Efecto.I=data.frame(Inclinacion,Compresiones) plot.design(Efecto.I,fun=&quot;mean&quot;,main=&quot;Inclinacion&quot;,xlab=&quot;&quot;, ylab=list(&quot;Compresiones&quot;,cex=1.4)) Efecto.G=data.frame(Grosor,Compresiones) plot.design(Efecto.G,fun=&quot;mean&quot;,main=&quot;Grosor&quot;,xlab=&quot;&quot;, ylab=list(&quot;Compresiones&quot;,cex=1.4)) Efecto.P=data.frame(Postcurado,Compresiones) plot.design(Efecto.P,fun=&quot;mean&quot;,main=&quot;Postcuarado&quot;,xlab=&quot;&quot;, ylab=list(&quot;Compresiones&quot;,cex=1.4)) Efectos de las interacciones: windows() interactionPlot(diseno.frac) Alternativa par(mfrow=c(2,2)) interaction.plot(Inclinacion,Grosor,Compresiones,main=&quot;Interacci?n I - G&quot;, xlab=list(&quot;I&quot;,cex=1.4)) interaction.plot(Inclinacion,Postcurado,Compresiones,main=&quot;Interacci?n I - P&quot;, xlab=list(&quot;I&quot;,cex=1.4)) interaction.plot(Grosor,Postcurado,Compresiones,main=&quot;Interacci?n G - P&quot;, xlab=list(&quot;G&quot;,cex=1.4)) par(mfrow=c(1,1)) Hay interacción entre el grosor y el postcurado Gráfico de Pareto: [El gráfico de Pareto muestra los valores absolutos de los efectos estandarizados desde el efecto más grande hasta el efecto más pequeño. Los efectos estandarizados son estadísticos que se distribuyen como una t-student. Así se contrasta la hipótesis nula de que el efecto es 0. El gráfico también traza una línea de referencia para indicar qué efectos son estadísticamente significativos.] windows() paretoPlot(diseno.frac,main=&quot;Diagrama de Pareto de los efectos&quot;,abs=T, xlab=list(&quot;Factores&quot;,cex=1.4), las=1,col=2:6,alpha=0.05) Interpretación: Se usa el diagrama de Pareto para determinar la magnitud y la importancia de los efectos. En el gráfico de Pareto, las barras que cruzan la línea de referencia hacen referencia a efectos estadísticamente significativos. Los efectos de inclinación, postcurado e interacción grosor postcurado son susceptibles de ser significativos, si atendemos al ME (margin error) del método de Lenth. Análisis del diseño factorial mediante la tabla ANOVA Esta es otra alternativa para detectar aquellos factores que inducen cambios significativamente distintos de cero en la respuesta (efectos significativos sobre la respuesta, resistencia a la rotura del material). analisis.disen=aov(Compresiones~(Inclinacion + Grosor + Postcurado)) summary(analisis.disen) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Inclinacion 1 648.0 648.0 34.560 0.00418 ## Grosor 1 4.5 4.5 0.240 0.64986 ## Postcurado 1 128.0 128.0 6.827 0.05925 ## Residuals 4 75.0 18.7 Inclinación es el factor significativo cuando sólo se tienen en cuenta efectos principales. Si se incluye la interacción de grosos y postcurado, se observa que es significativa. analisis.disen=aov(Compresiones~Inclinacion + Grosor * Postcurado) summary(analisis.disen) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Inclinacion 1 648.0 648.0 648.0 0.000133 ## Grosor 1 4.5 4.5 4.5 0.124027 ## Postcurado 1 128.0 128.0 128.0 0.001481 ## Grosor:Postcurado 1 72.0 72.0 72.0 0.003437 ## Residuals 3 3.0 1.0 Gráfica de probabilidad normal: Debido a que el gráfico de Pareto muestra el valor absoluto de los efectos, puede determinar qué efectos son grandes, pero no puede determinar qué efectos aumentan o disminuyen la respuesta. Úsese la gráfica de probabilidad normal de los efectos estandarizados para examinar la magnitud y dirección de los efectos. # *La gráfica de probabilidad normal de los efectos muestra # los efectos estandarizados relativos a una línea de # ajuste de distribución para el caso en el que todos los # efectos son 0. Los efectos estandarizados son # t-estadísticos que contrastan la hipótesis nula de que # el efecto es 0. # *Los efectos positivos aumentan la respuesta cuando la # configuración cambia del valor bajo del factor al valor # alto. # *Los efectos negativos disminuyen la respuesta cuando su # configuración cambia del valor bajo del factor al alto # *Los efectos más allá de 0 en el eje x tienen mayor # magnitud. Los efectos más allá de 0 son estadísticamente # más significativos. normalPlot(diseno.frac) ## A B C A:B A:C B:C A:B:C ## NaN NaN NaN NaN NaN NaN NaN Inclinación y la interacción Inclinación:Postcurado tienen efecto positivo sobre la respuesta. El postcurado tiene efecto negativo. Superficie de respuesta para ver la relación entre inclinación y postcurado Visualización con un mapa de contorno y una superficie de respuesta: par(mfrow = c(1,2)) wirePlot(A, C, Compresiones, data = diseno.frac) contourPlot(A, C, Compresiones, data = diseno.frac) 6.1.3 DISEÑOS DE EXPERIMENTOS FACTORIALES FRACCIONADOS Se ajusta el modelo paramétrico de Paris, dependiente de los parámetros C y m para estimar la longitud de grietas en un material en función del número de ciclos de esfuerzos a fatiga. Se trataría de ver si unos parámetros de un modelo de fiabilidad (prueba de fatiga tipo Paris) son significativos a la par que se analiza el posible efecto de la interacción. 6.1.3.1 EJEMPLO de DISEÑO FRACCIONADO 1/4 library(qualityTools) MATRIZ DE BASE DE DATOS: valores ajustados S2m=c(0.1,0.5,0.1,0.5,0.1,0.5,0.1,0.5) SCm=c(-0.09,-0.09,-0.02,-0.02,-0.09,-0.09,-0.02,-0.02) S2C=c(0.1,0.1,0.1,0.1,0.5,0.5,0.5,0.5) m=c(4,3,3,4,4,3,3,4) C=c(6,5,6,5,5,6,5,6) S2_m=factor(S2m); S_Cm=factor(SCm);S2_C=factor(S2C);m=factor(m);C=factor(C) RESPUESTA DE LAS DISTANCIAS L2 DE LAS OCHO COMBINACIONES resp.lme.L2=c(0.001326,0.001648,0.000626,0.002624,0.005023,0.002590,0.003786, 0.003949) DIAGRAMA DE PARETO DE LOS EFECTOS SIGNIFICATIVOS diseno.frac = fracDesign(k = 5, gen = c(&quot;D=AB&quot;,&quot;E=AC&quot;)) ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated ## Warning in `[&lt;-`(`*tmp*`, i, value = new(&quot;doeFactor&quot;)): implicit list ## embedding of S4 objects is deprecated names(diseno.frac)=c(&quot;var(m)&quot;,&quot;cov(C,m)&quot;,&quot;var(C)&quot;,&quot;m&quot;,&quot;C&quot;) response(diseno.frac)=data.frame(resp.L2=c(0.002624,0.000626,0.001648,0.005023, 0.002590, 0.003786,0.003949,0.001326)) Gráfico de pareto del los efectos estadarizados de los factores paretoPlot(diseno.frac,main=&quot;Diagrama de Pareto de los efectos&quot;,abs=T, xlab=list(&quot;Efectos&quot;,cex=1.4),ylab=list(expression(L[2]),cex=1.2), las=1,col=2:6) ANALISIS DEL DISEÃO CON LA TABLA ANOVA analisis.disen=aov(resp.lme.L2~(S2_m + S_Cm + S2_C + m + C)) summary(analisis.disen) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## S2_m 1 0.000e+00 0.000e+00 0.006 0.94647 ## S_Cm 1 2.000e-08 2.000e-08 0.364 0.60756 ## S2_C 1 1.041e-05 1.041e-05 191.348 0.00519 ## m 1 2.281e-06 2.281e-06 41.948 0.02302 ## C 1 2.634e-06 2.634e-06 48.426 0.02003 ## Residuals 2 1.090e-07 5.400e-08 ESTRUCTURA DE ALIAS A=S2_m ; B=S_Cm ; C=S2_C ; D=m ; E= C I + ABD + ACE + BCDE A + BD + CE + ABCDE B + AD + CDE + ABCE C + AE + BDE + ABCD * EFECTO SIGNIFICATIVO C D + AB + BCE + ACDE * EFECTO SIGNIFICATIVO D E + AC + BCD + ABDE * EFECTO SIGNIFICATIVO E BC + DE + ABE + ACD BE + CD + ABC + ADE GRÁFICOS DE EFECTOS PRINCIPALES SIGNIFICATIVOS par(mfrow=c(2,2)) interaction.plot(S2_m,C,resp.lme.L2,main=&quot;Interacci?n var(m) - C&quot;, ylab=expression(L[2]),xlab=list(&quot;var(m)&quot;,cex=1.4)) interaction.plot(S2_m,S_Cm,resp.lme.L2,main=&quot;Interacci?n var(m) - cov(C,m)&quot;, ylab=expression(L[2]),xlab=list(&quot;var(m)&quot;,cex=1.4)) interaction.plot(S2_m,S2_C,resp.lme.L2,main=&quot;Interacci?n var(m) - var(C)&quot;, ylab=expression(L[2]),xlab=list(&quot;var(m)&quot;,cex=1.4)) par(mfrow=c(1,1)) MODELO LINEAL model.lm=lm(resp.lme.L2~(S2_m +S_Cm +S2_C +m + C)) anova(model.lm) # Es el mismo resumen de la tabla ANOVA ## Analysis of Variance Table ## ## Response: resp.lme.L2 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## S2_m 1 3.0000e-10 3.0000e-10 0.0057 0.946475 ## S_Cm 1 1.9800e-08 1.9800e-08 0.3641 0.607557 ## S2_C 1 1.0406e-05 1.0406e-05 191.3478 0.005185 ## m 1 2.2812e-06 2.2812e-06 41.9484 0.023019 ## C 1 2.6335e-06 2.6335e-06 48.4260 0.020032 ## Residuals 2 1.0880e-07 5.4400e-08 summary(model.lm) ## ## Call: ## lm(formula = resp.lme.L2 ~ (S2_m + S_Cm + S2_C + m + C)) ## ## Residuals: ## 1 2 3 4 5 6 ## -1.343e-04 9.575e-05 1.343e-04 -9.575e-05 1.343e-04 -9.575e-05 ## 7 8 ## -1.343e-04 9.575e-05 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.0015398 0.0002020 7.624 0.01677 ## S2_m0.5 0.0000125 0.0001649 0.076 0.94647 ## S_Cm-0.02 0.0000995 0.0001649 0.603 0.60756 ## S2_C0.5 0.0022810 0.0001649 13.833 0.00519 ## m4 0.0010680 0.0001649 6.477 0.02302 ## C6 -0.0011475 0.0001649 -6.959 0.02003 ## ## Residual standard error: 0.0002332 on 2 degrees of freedom ## Multiple R-squared: 0.993, Adjusted R-squared: 0.9754 ## F-statistic: 56.42 on 5 and 2 DF, p-value: 0.01751 \\(p-value=0.01751\\) es significativo el modelo al \\(95\\%\\) y los coeficientes significativos del modelo coinciden con los de latabla ANOVA RESIDUOS DEL MODELO plot(rstandard(model.lm),main=&quot;Comportamiento de los residuos estÃ¡ndar&quot;, ylab=list(&quot;Residuos est?ndar&quot;,cex=1.2),xlab=&quot;?ndice&quot;,ylim=c(-2,2),pch=20, cex=2,col=4) Están dentro del intervalo de -2 a 2 PREDICCIONES DEL MODELO PARA IDENTIFICAR EL NIVEL ÓPTIMO DE \\(var(m)\\) factorA=factor(c(0.1,0.5)) ; factorB=factor(c(-0.02,-0.02)) factorC=factor(c(0.1,0.1)) ; factorD=factor(c(3,3)) factorE=factor(c(6,6)) pred.model=predict(model.lm,newdata=data.frame(S2_m=factorA,S_Cm=factorB, S2_C=factorC, m=factorD, C=factorE),level=0.95, interval=&quot;confidence&quot;) pred.model ## fit lwr upr ## 1 0.00049175 -0.0003772015 0.001360701 ## 2 0.00050425 -0.0003647015 0.001373201 6.1.4 ESTUDIOS INTERLABORATORIO (CASO PARTICULAR DE DOE Y ESTUDIOS R&amp;R) Conjunto de datos de grucosa. El contenido de glucosa se mide en diferentes 5 muestras diferentes de sangre (5 tipos de material diferentes) por 8 diferentes laboratorios. Gráficos para el estadístico h de Mandel: library(ILS) data(Glucose) Glucose.qcdata &lt;- lab.qcdata(Glucose) str(Glucose.qcdata) ## Classes &#39;lab.qcdata&#39; and &#39;data.frame&#39;: 120 obs. of 4 variables: ## $ x : num 41 41.5 41.4 41.2 42 ... ## $ replicate : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ material : Factor w/ 5 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ laboratory: Factor w/ 8 levels &quot;Lab1&quot;,&quot;Lab2&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... ## - attr(*, &quot;data.name&quot;)= chr &quot;Glucose&quot; h&lt;- h.qcs(Glucose.qcdata, alpha = 0.005) summary(h) ## ## Number of laboratories: 8 ## Number of materials: 5 ## Number of replicate: 3 ## Critical value: 2.152492 ## Beyond limits of control: ## A B C D E ## Lab1 TRUE TRUE TRUE TRUE TRUE ## Lab2 TRUE TRUE TRUE TRUE TRUE ## Lab3 TRUE TRUE TRUE TRUE TRUE ## Lab4 TRUE TRUE FALSE TRUE TRUE ## Lab5 TRUE TRUE TRUE TRUE TRUE ## Lab6 TRUE TRUE TRUE TRUE TRUE ## Lab7 TRUE TRUE TRUE FALSE TRUE ## Lab8 TRUE TRUE TRUE FALSE TRUE plot(h) Gráficos para el estadístico k de Mandel: library(ILS) data(Glucose) Glucose.qcdata &lt;- lab.qcdata(Glucose) str(Glucose.qcdata) ## Classes &#39;lab.qcdata&#39; and &#39;data.frame&#39;: 120 obs. of 4 variables: ## $ x : num 41 41.5 41.4 41.2 42 ... ## $ replicate : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ material : Factor w/ 5 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... ## $ laboratory: Factor w/ 8 levels &quot;Lab1&quot;,&quot;Lab2&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... ## - attr(*, &quot;data.name&quot;)= chr &quot;Glucose&quot; k&lt;- k.qcs(Glucose.qcdata, alpha = 0.005) summary(k) ## ## Number of laboratories: 8 ## Number of materials: 5 ## Number of replicate: 3 ## Critical value: 2.06084 ## Beyond limits of control: ## A B C D E ## Lab1 TRUE TRUE TRUE TRUE TRUE ## Lab2 TRUE TRUE TRUE TRUE FALSE ## Lab3 TRUE TRUE TRUE TRUE TRUE ## Lab4 TRUE TRUE FALSE TRUE TRUE ## Lab5 TRUE TRUE TRUE TRUE TRUE ## Lab6 TRUE TRUE TRUE TRUE TRUE ## Lab7 TRUE TRUE TRUE TRUE TRUE ## Lab8 TRUE TRUE TRUE TRUE TRUE plot(k) "]
]
